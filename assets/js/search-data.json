{
  
    
        "post0": {
            "title": "초급자를 위한 손에 잡히는 딥러닝",
            "content": "&#49688;&#44053; &#45824;&#49345; . 인공지능, 머신러닝, 딥러닝에 대한 이해가 전혀 없으나 배워보고 싶으신 분 | 데이터 분석에 대한 이해가 전혀 없으신 분 | Python에 대한 이해가 없으신 분 | 빠른 시간 내 훑어보시길 원하시는 분 | 해당 강의자료는 생활코딩의 머신러닝 야학의 후속편으로 보시면 좋습니다. | . &#44208;&#47200; . Python은 무진장 좋다! 난이도 | 커뮤니티 | 확장성 | . | 딥러닝도 무진장 좋다! 심층 학습(Deep learning) &gt; 표현 학습 &gt; 기계 학습 &gt; 인공 지능 | 학습이란 &quot;한 컴퓨터 프로그램이 어떤 과제류 T에 속하는 과제들을 수행하며 그 수행의 성과를 측정한 측도가 P라고 할 때. 만일 어떤 경험 E 때문에 T의 어떤 과제에 대한 성과 측도 P가 개선되었다면, 그 컴퓨터 프로그램은 경험 E로부터 학습한다고 말할 수 있다&quot; - mitchell, 1997 | . | 만능은 아니다! 개리 마르커스 교수의 에세이(https://arxiv.org/ftp/arxiv/papers/1801/1801.00631.pdf)에서 몇 가지 발췌 많은 데이터 필요(데이터는 신뢰할 수 있는 데이터인가?) | 재활용 힘듬 | 충분히 투명하지 않음 | 인과관계와 상관관계의 구분이 어려움 | 신뢰성있는 엔지니어링의 어려움 | | . | . &#50689;&#49345;&#44053;&#51032; &#44277;&#48512; &#48169;&#48277; . Python을 조금 해보신 분이라면 따라서 타이핑을 쳐보세요. | Python을 해보시지 않으신 분은 자료를 다운로드 받아 colab에서 Ctrl + Enter만 해보세요. | 자료 링크 : www.paullab.co.kr/deep_learning.zip | 영상은 제주코딩베이스캠프 유튜브 채널에 올려두겠습니다. | . . . &#44536;&#47000;&#54532;&#51032; &#54620;&#44544; &#54256;&#53944; . !sudo apt install -y fonts-nanum* !sudo fc-cache -fv !rm ~/.cache/matplotlib -rf . Reading package lists... Done Building dependency tree Reading state information... Done Note, selecting &#39;fonts-nanum-eco&#39; for glob &#39;fonts-nanum*&#39; Note, selecting &#39;fonts-nanum&#39; for glob &#39;fonts-nanum*&#39; Note, selecting &#39;fonts-nanum-gothic-light&#39; for glob &#39;fonts-nanum*&#39; Note, selecting &#39;fonts-nanum-coding&#39; for glob &#39;fonts-nanum*&#39; Note, selecting &#39;fonts-nanum-extra&#39; for glob &#39;fonts-nanum*&#39; The following NEW packages will be installed: fonts-nanum fonts-nanum-coding fonts-nanum-eco fonts-nanum-extra 0 upgraded, 4 newly installed, 0 to remove and 37 not upgraded. Need to get 37.0 MB of archives. After this operation, 145 MB of additional disk space will be used. Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB] Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum-eco all 1.000-6 [14.0 MB] Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum-extra all 20170925-1 [12.2 MB] Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum-coding all 2.5-1 [1,083 kB] Fetched 37.0 MB in 3s (11.7 MB/s) debconf: unable to initialize frontend: Dialog debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, &lt;&gt; line 4.) debconf: falling back to frontend: Readline debconf: unable to initialize frontend: Readline debconf: (This frontend requires a controlling tty.) debconf: falling back to frontend: Teletype dpkg-preconfigure: unable to re-open stdin: Selecting previously unselected package fonts-nanum. (Reading database ... 155013 files and directories currently installed.) Preparing to unpack .../fonts-nanum_20170925-1_all.deb ... Unpacking fonts-nanum (20170925-1) ... Selecting previously unselected package fonts-nanum-eco. Preparing to unpack .../fonts-nanum-eco_1.000-6_all.deb ... Unpacking fonts-nanum-eco (1.000-6) ... Selecting previously unselected package fonts-nanum-extra. Preparing to unpack .../fonts-nanum-extra_20170925-1_all.deb ... Unpacking fonts-nanum-extra (20170925-1) ... Selecting previously unselected package fonts-nanum-coding. Preparing to unpack .../fonts-nanum-coding_2.5-1_all.deb ... Unpacking fonts-nanum-coding (2.5-1) ... Setting up fonts-nanum-extra (20170925-1) ... Setting up fonts-nanum (20170925-1) ... Setting up fonts-nanum-coding (2.5-1) ... Setting up fonts-nanum-eco (1.000-6) ... Processing triggers for fontconfig (2.12.6-0ubuntu2) ... /usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs /usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs /usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs /usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs /usr/share/fonts/truetype/nanum: caching, new cache contents: 31 fonts, 0 dirs /usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs /root/.local/share/fonts: skipping, no such directory /root/.fonts: skipping, no such directory /var/cache/fontconfig: cleaning cache directory /root/.cache/fontconfig: not cleaning non-existent cache directory /root/.fontconfig: not cleaning non-existent cache directory fc-cache: succeeded . import matplotlib.pyplot as plt plt.rc(&#39;font&#39;, family=&#39;NanumBarunGothic&#39;) . &#45936;&#51060;&#53552; &#49373;&#49457; . import pandas as pd # 데이터 분석을 위한 모듈 import numpy as np # 대규모 다차원 배열 연산을 위한 모듈 . 주가 = [ np.random.randint(10, 50) + i*2 for i in range(100) ] . import matplotlib.pyplot as plt # 시각화 모듈 plt.plot(np.arange(1, 101), 주가) plt.show() . findfont: Font family [&#39;NanumBarunGothic&#39;] not found. Falling back to DejaVu Sans. . &#46373;&#47084;&#45789; . . 독립 = pd.DataFrame(np.arange(1, 101)) 종속 = pd.DataFrame(주가) 독립.shape, 종속.shape . ((100, 1), (100, 1)) . import tensorflow as tf # 구글이 2015년 오픈소스로 공개한 딥러닝 라이브러리 . X = tf.keras.layers.Input(shape=[1]) # 독립변수의 col Y = tf.keras.layers.Dense(1)(X) # 종속변수의 col(뉴런의 개수) model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) # MSE(Mean squared error) . model.fit(독립, 종속, epochs=10000, verbose=0) model.fit(독립, 종속, epochs=10) . Epoch 1/10 4/4 [==============================] - 0s 4ms/step - loss: 119.1895 Epoch 2/10 4/4 [==============================] - 0s 3ms/step - loss: 119.1703 Epoch 3/10 4/4 [==============================] - 0s 5ms/step - loss: 119.1476 Epoch 4/10 4/4 [==============================] - 0s 4ms/step - loss: 119.1375 Epoch 5/10 4/4 [==============================] - 0s 3ms/step - loss: 119.0755 Epoch 6/10 4/4 [==============================] - 0s 4ms/step - loss: 119.0557 Epoch 7/10 4/4 [==============================] - 0s 4ms/step - loss: 119.0058 Epoch 8/10 4/4 [==============================] - 0s 4ms/step - loss: 119.0227 Epoch 9/10 4/4 [==============================] - 0s 3ms/step - loss: 118.9778 Epoch 10/10 4/4 [==============================] - 0s 3ms/step - loss: 119.1360 . &lt;keras.callbacks.History at 0x7f132efb9390&gt; . model.predict([50]) model.predict([40]) . array([[104.36363]], dtype=float32) . model.predict(독립) . array([[ 22.904667], [ 24.993359], [ 27.082048], [ 29.17074 ], [ 31.259432], [ 33.34812 ], [ 35.436813], [ 37.525505], [ 39.614197], [ 41.70289 ], [ 43.79158 ], [ 45.880272], [ 47.968964], [ 50.05765 ], [ 52.146343], [ 54.235035], [ 56.323727], [ 58.41242 ], [ 60.50111 ], [ 62.5898 ], [ 64.67849 ], [ 66.76718 ], [ 68.85587 ], [ 70.944565], [ 73.03326 ], [ 75.12195 ], [ 77.21064 ], [ 79.29933 ], [ 81.388016], [ 83.476715], [ 85.5654 ], [ 87.6541 ], [ 89.74278 ], [ 91.83148 ], [ 93.920166], [ 96.008865], [ 98.09755 ], [100.18625 ], [102.27493 ], [104.36363 ], [106.45232 ], [108.541 ], [110.6297 ], [112.71838 ], [114.80708 ], [116.89577 ], [118.98447 ], [121.07315 ], [123.16185 ], [125.250534], [127.33923 ], [129.42792 ], [131.51662 ], [133.6053 ], [135.694 ], [137.78268 ], [139.87137 ], [141.96007 ], [144.04875 ], [146.13745 ], [148.22614 ], [150.31483 ], [152.40353 ], [154.49222 ], [156.5809 ], [158.6696 ], [160.75829 ], [162.84698 ], [164.93567 ], [167.02437 ], [169.11305 ], [171.20175 ], [173.29044 ], [175.37914 ], [177.46782 ], [179.55652 ], [181.6452 ], [183.7339 ], [185.82259 ], [187.91129 ], [189.99997 ], [192.08865 ], [194.17735 ], [196.26604 ], [198.35474 ], [200.44342 ], [202.53212 ], [204.6208 ], [206.7095 ], [208.79819 ], [210.88689 ], [212.97557 ], [215.06427 ], [217.15295 ], [219.24165 ], [221.33034 ], [223.41902 ], [225.50772 ], [227.5964 ], [229.6851 ]], dtype=float32) . model.get_weights() . [array([[2.0886912]], dtype=float32), array([20.815975], dtype=float32)] . 2.072317 * 50 + 22.033388 . 125.649238 . model.predict([50]) . array([[125.250534]], dtype=float32) . plt.plot(np.arange(1, 101), 주가) plt.plot(np.arange(1, 101), 2.07 * np.arange(1, 101) + 22.03) plt.show() . 오차값 = 종속 - model.predict(독립) 오차값 . 0 . 0 -6.904667 | . 1 -8.993359 | . 2 7.917952 | . 3 9.829260 | . 4 -7.259432 | . ... ... | . 95 -10.330338 | . 96 -8.419022 | . 97 -2.507721 | . 98 -20.596405 | . 99 12.314896 | . 100 rows × 1 columns . 오차값의제곱 = 오차값 ** 2 오차값의제곱 . 0 . 0 47.674425 | . 1 80.880499 | . 2 62.693957 | . 3 96.614350 | . 4 52.699351 | . ... ... | . 95 106.715873 | . 96 70.879925 | . 97 6.288664 | . 98 424.211900 | . 99 151.656654 | . 100 rows × 1 columns . (오차값의제곱.sum())/100 ## MSE . 0 119.005107 dtype: float64 . &#52572;&#49548; &#51228;&#44273;&#48277; . y = ax + b | 참고자료 : https://ko.wikipedia.org/wiki/%EC%B5%9C%EC%86%8C%EC%A0%9C%EA%B3%B1%EB%B2%95 | 구하고자 하는 방정식은 y = ax + b이다. 상수 a, b값을 안다면, a, b는 다음으로 계산할 수 있다. | a : $${ displaystyle a={ frac {n Sigma XY- Sigma X Sigma Y}{n Sigma X^{2}- Sigma X Sigma X}}}$$ . | b : $${ displaystyle b={ frac { Sigma X^{2} Sigma Y- Sigma X Sigma XY}{n Sigma X^{2}- Sigma X Sigma X}}}$$ . | . 두수의곱 = 독립*종속 int(100 * 두수의곱.sum()) . 81342700 . int(독립.sum() * 종속.sum()) . 64135000 . int(100 * (독립 ** 2).sum()) . 33835000 . int(독립.sum() * 독립.sum()) . 25502500 . 분자 = int(100 * 두수의곱.sum()) - int(독립.sum() * 종속.sum()) 분모 = int(100 * (독립 ** 2).sum()) - int(독립.sum() * 독립.sum()) . 분자 / 분모 . 2.0651305130513053 . model.get_weights() . [array([[2.0886912]], dtype=float32), array([20.815975], dtype=float32)] . ${ displaystyle b={ frac { Sigma X^{2} Sigma Y- Sigma X Sigma XY}{n Sigma X^{2}- Sigma X Sigma X}}}$ . 분자 = ((독립**2).sum() * 종속.sum()) - (독립.sum() * (독립*종속).sum()) 분모 = (100 * (독립**2).sum()) - (독립.sum() * 독립.sum()) . 분자 / 분모 . 0 22.710909 dtype: float64 . &#45800;&#49692;&#45936;&#51060;&#53552;&#51032; &#55176;&#46304;&#47112;&#51060;&#50612; . . 매출액 = [2, 5, 10, 20, 40, 80] 광고액 = [1, 2, 4, 6, 8, 10] 순익 = [1, 1.5, 3, 10, 20, 60] . plt.plot(np.arange(1, 7), 매출액, label=&#39;매출액&#39;) plt.plot(np.arange(1, 7), 광고액, label=&#39;광고액&#39;) plt.plot(np.arange(1, 7), 순익, label=&#39;순익&#39;) plt.legend() plt.show() . /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47588 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52636 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50529 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44305 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44256 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49692 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51061 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47588 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52636 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50529 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44305 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44256 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49692 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51061 missing from current font. font.set_text(s, 0, flags=flags) . 독립 = pd.DataFrame({ &#39;매출액&#39; : 매출액, &#39;광고액&#39; : 광고액 }) 종속 = pd.DataFrame({ &#39;순익&#39; : 순익 }) 독립.shape, 종속.shape . ((6, 2), (6, 1)) . 독립 . 매출액 광고액 . 0 2 | 1 | . 1 5 | 2 | . 2 10 | 4 | . 3 20 | 6 | . 4 40 | 8 | . 5 80 | 10 | . X = tf.keras.layers.Input(shape=[2]) # 독립변수의 col ## 1. 히든 레이어의 노드(뉴런) 수는 2개부터 5개까지 점차 늘려보고 그래프를 확인해보세요. H = tf.keras.layers.Dense(2, activation=&#39;swish&#39;)(X) # activation은 뉴런 출력에 적용할 함수(대표적으로 swish, sigmoid, softmax) ## 2. 히든 레이어의 수를 2개, 3개로 점차 늘려보고 그래프를 확인해보세요. # H = tf.keras.layers.Dense(2, activation=&#39;swish&#39;)(H) Y = tf.keras.layers.Dense(1)(H) # 종속변수의 col model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) # MSE(Mean squared error) . model.fit(독립, 종속, epochs=10000, verbose=0) model.fit(독립, 종속, epochs=10) . Epoch 1/10 1/1 [==============================] - 0s 5ms/step - loss: 0.0982 Epoch 2/10 1/1 [==============================] - 0s 9ms/step - loss: 0.0981 Epoch 3/10 1/1 [==============================] - 0s 6ms/step - loss: 0.0982 Epoch 4/10 1/1 [==============================] - 0s 5ms/step - loss: 0.0981 Epoch 5/10 1/1 [==============================] - 0s 6ms/step - loss: 0.0981 Epoch 6/10 1/1 [==============================] - 0s 6ms/step - loss: 0.0981 Epoch 7/10 1/1 [==============================] - 0s 12ms/step - loss: 0.0981 Epoch 8/10 1/1 [==============================] - 0s 6ms/step - loss: 0.0981 Epoch 9/10 1/1 [==============================] - 0s 6ms/step - loss: 0.0981 Epoch 10/10 1/1 [==============================] - 0s 9ms/step - loss: 0.0980 . &lt;keras.callbacks.History at 0x7f133061b210&gt; . model.get_weights() . [array([[-0.40000844, 0.7816885 ], [ 1.5398669 , -1.2308433 ]], dtype=float32), array([ 3.6804793, -2.7696192], dtype=float32), array([[1.5450304], [1.3788965]], dtype=float32), array([-5.561009], dtype=float32)] . model.predict([[10, 4]]) . array([[3.5262856]], dtype=float32) . model.predict(독립) . array([[ 0.9172058], [ 1.3474641], [ 3.5262856], [ 9.508385 ], [20.156319 ], [59.87727 ]], dtype=float32) . 종속 . 순익 . 0 1.0 | . 1 1.5 | . 2 3.0 | . 3 10.0 | . 4 20.0 | . 5 60.0 | . plt.plot(np.arange(1, 7), model.predict(독립), label=&#39;예측값&#39;) plt.plot(np.arange(1, 7), 종속, label=&#39;실제값&#39;) plt.legend() plt.show() . /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50696 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52769 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44050 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51228 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50696 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52769 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44050 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51228 missing from current font. font.set_text(s, 0, flags=flags) . &#48373;&#51105; &#45936;&#51060;&#53552;&#51032; &#55176;&#46304;&#47112;&#51060;&#50612; . 그럼 주가는 잘 맞출까? (곡선 형태) | . import numpy as np import pandas as pd import matplotlib.pyplot as plt 광고액 = [ np.random.randint(10, 50) + np.log(i*5) * 50 for i in range(1, 101) ] 계절성 = [ np.sin(i/3)*100 + i*3 + j*2 for i, j in zip(np.arange(1, 101), 광고액) ] 매출액 = [i**(np.log(np.log(i))) + j for i, j in zip(np.arange(1, 101), 계절성) ] plt.plot(np.arange(1, 101), 광고액, label=&#39;a&#39;) plt.plot(np.arange(1, 101), 계절성, label=&#39;b&#39;) plt.plot(np.arange(1, 101), 매출액, label=&#39;c&#39;) plt.legend() plt.show() . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log import sys . 독립 = pd.DataFrame({ &#39;계절성&#39; : 계절성, &#39;광고액&#39; : 광고액 }) 종속 = pd.DataFrame({ &#39;매출액&#39; : 매출액 }) 독립.shape, 종속.shape . ((100, 2), (100, 1)) . import tensorflow as tf #모델 준비 X = tf.keras.layers.Input(shape=[2]) # 독립변수의 col H = tf.keras.layers.Dense(200, activation=&#39;swish&#39;)(X) # 노드의 수는 천천히 늘려감! (2 ~ 200) # H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 처음에는 주석처리! Y = tf.keras.layers.Dense(1)(H) # 종속변수의 col model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) # MSE(Mean squared error) . model.fit(독립, 종속, epochs=10000, verbose=0) model.fit(독립, 종속, epochs=10) . Epoch 1/10 4/4 [==============================] - 0s 3ms/step - loss: 34673.1094 Epoch 2/10 4/4 [==============================] - 0s 3ms/step - loss: 34818.7422 Epoch 3/10 4/4 [==============================] - 0s 3ms/step - loss: 37403.0078 Epoch 4/10 4/4 [==============================] - 0s 2ms/step - loss: 58460.4766 Epoch 5/10 4/4 [==============================] - 0s 3ms/step - loss: 35651.8125 Epoch 6/10 4/4 [==============================] - 0s 4ms/step - loss: 38424.7188 Epoch 7/10 4/4 [==============================] - 0s 3ms/step - loss: 37497.7656 Epoch 8/10 4/4 [==============================] - 0s 54ms/step - loss: 38993.0820 Epoch 9/10 4/4 [==============================] - 0s 3ms/step - loss: 39837.9961 Epoch 10/10 4/4 [==============================] - 0s 4ms/step - loss: 43657.0000 . &lt;keras.callbacks.History at 0x7f13321834d0&gt; . plt.plot(np.arange(1, 101), model.predict(독립), label=&#39;예측값&#39;) plt.plot(np.arange(1, 101), 종속, label=&#39;실제값&#39;) plt.legend() plt.show() . /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50696 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52769 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44050 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51228 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50696 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52769 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44050 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51228 missing from current font. font.set_text(s, 0, flags=flags) . plt.plot(np.arange(1, 101), model.predict(독립), label=&#39;예측값&#39;) plt.plot(np.arange(1, 101), 종속, label=&#39;실제값&#39;) plt.legend() plt.show() . /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50696 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52769 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44050 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51228 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50696 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52769 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44050 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51228 missing from current font. font.set_text(s, 0, flags=flags) . import tensorflow as tf #모델 준비 X = tf.keras.layers.Input(shape=[2]) # 독립변수의 col H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(X) # 노드의 수는 천천히 늘려감! (2 ~ 5) H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 천천히 늘려감! (2 ~ 5) H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 천천히 늘려감! (2 ~ 5) H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 천천히 늘려감! (2 ~ 5) H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 천천히 늘려감! (2 ~ 5) Y = tf.keras.layers.Dense(1)(H) # 종속변수의 col model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) # MSE(Mean squared error) . model.fit(독립, 종속, epochs=10000, verbose=0) model.fit(독립, 종속, epochs=10) . Epoch 1/10 4/4 [==============================] - 0s 3ms/step - loss: 33637.1914 Epoch 2/10 4/4 [==============================] - 0s 4ms/step - loss: 32272.7559 Epoch 3/10 4/4 [==============================] - 0s 4ms/step - loss: 35613.3984 Epoch 4/10 4/4 [==============================] - 0s 4ms/step - loss: 36397.0469 Epoch 5/10 4/4 [==============================] - 0s 3ms/step - loss: 33294.0039 Epoch 6/10 4/4 [==============================] - 0s 4ms/step - loss: 31867.3379 Epoch 7/10 4/4 [==============================] - 0s 4ms/step - loss: 32319.9434 Epoch 8/10 4/4 [==============================] - 0s 3ms/step - loss: 33304.1719 Epoch 9/10 4/4 [==============================] - 0s 5ms/step - loss: 37012.2227 Epoch 10/10 4/4 [==============================] - 0s 3ms/step - loss: 31852.8457 . &lt;keras.callbacks.History at 0x7f1331efc990&gt; . plt.plot(np.arange(1, 101), model.predict(독립), label=&#39;예측값&#39;) plt.plot(np.arange(1, 101), 종속, label=&#39;실제값&#39;) plt.legend() plt.show() . /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50696 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52769 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44050 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51228 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50696 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52769 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44050 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51228 missing from current font. font.set_text(s, 0, flags=flags) . import tensorflow as tf #모델 준비 X = tf.keras.layers.Input(shape=[2]) # 독립변수의 col H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(X) # 노드의 수는 천천히 늘려감! (2 ~ 5) for _ in range(10): H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 천천히 늘려감! (2 ~ 5) Y = tf.keras.layers.Dense(1)(H) # 종속변수의 col model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) # MSE(Mean squared error) . model.fit(독립, 종속, epochs=10000, verbose=0) model.fit(독립, 종속, epochs=10) . Epoch 1/10 4/4 [==============================] - 0s 3ms/step - loss: 29421.2344 Epoch 2/10 4/4 [==============================] - 0s 3ms/step - loss: 25886.2969 Epoch 3/10 4/4 [==============================] - 0s 5ms/step - loss: 25001.6250 Epoch 4/10 4/4 [==============================] - 0s 4ms/step - loss: 22642.9609 Epoch 5/10 4/4 [==============================] - 0s 4ms/step - loss: 24440.7344 Epoch 6/10 4/4 [==============================] - 0s 4ms/step - loss: 26648.9941 Epoch 7/10 4/4 [==============================] - 0s 4ms/step - loss: 22765.5352 Epoch 8/10 4/4 [==============================] - 0s 3ms/step - loss: 23219.0391 Epoch 9/10 4/4 [==============================] - 0s 4ms/step - loss: 37749.2188 Epoch 10/10 4/4 [==============================] - 0s 4ms/step - loss: 25314.1348 . &lt;keras.callbacks.History at 0x7f1331a28890&gt; . plt.plot(np.arange(1, 101), model.predict(독립), label=&#39;예측값&#39;) plt.plot(np.arange(1, 101), 종속, label=&#39;실제값&#39;) plt.legend() plt.show() . /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50696 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52769 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44050 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51228 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50696 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52769 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44050 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font. font.set_text(s, 0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51228 missing from current font. font.set_text(s, 0, flags=flags) . 히든레이어는 1개 ~ 4개를 쌓아보고 정확도 측정하는 것이 보통. | 노드는 100개 ~ 200개를 쌓아보고 정확도 측정. | 은닉 단위의 설계는 실무 지침이 될만한 결정적인 이론이 나오지 않음(심층학습, 제이펍, 211page) | CNN이나 RNN 으로 넘어가기 전 좀 더 단순한 데이터로 신경망에 대해 학습할 것을 권함. | . . .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/tensorflow/deep%20learning/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80/2021/09/20/_09_20_%EC%B4%88%EA%B8%89%EC%9E%90%EB%A5%BC_%EC%9C%84%ED%95%9C_%EC%86%90%EC%97%90_%EC%9E%A1%ED%9E%88%EB%8A%94_%EB%94%A5%EB%9F%AC%EB%8B%9D.html",
            "relUrl": "/tensorflow/deep%20learning/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80/2021/09/20/_09_20_%EC%B4%88%EA%B8%89%EC%9E%90%EB%A5%BC_%EC%9C%84%ED%95%9C_%EC%86%90%EC%97%90_%EC%9E%A1%ED%9E%88%EB%8A%94_%EB%94%A5%EB%9F%AC%EB%8B%9D.html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Python으로 알아보는 블록체인 기본 개념",
            "content": "강의자료 : https://paullabkorea.github.io/jupyternotebookblog/ | 비전공자를 위한 넓고 얇은 IT 지식 &amp; 나의 개발 유형 알아보기! &lt;M.B.I.T&gt; 강의 : https://inf.run/b82R | 블록체인의 기본적인 설명과 나만의 코인 만들기는 앞 챕터에서 진행 | . &#50948;&#45768;&#48652;&#53076;&#51064; &#44396;&#54788; . &#53076;&#51064;&#51060;&#47492; : WenivCoin . &#53944;&#47116;&#51229;&#49496; . * t1 : 호준 -&gt; 길동, 1 위니브코인 * t2 : 길동 -&gt; 춘향, 2 위니브코인 * t3 : 춘향 -&gt; 준호, 3 위니브코인 * t4 : 호준 -&gt; 길동, 1 위니브코인 * t5 : 길동 -&gt; 춘향, 2 위니브코인 * t6 : 춘향 -&gt; 준호, 3 위니브코인 . &#54644;&#49772;(sha256) . B1(&quot;hello world&quot;, t1, t2), B1.hash -&gt; | B2(B1.hash, t3, t4), B2.hash -&gt; | B3(B2.hash, t5, t6). B3.hash -&gt; ... | . . . &#48660;&#47197;&#50640; &#45812;&#44592;&#45716; Data(&#48708;&#53944;&#53076;&#51064; &#50696;) . 코인의 발송자 | 수신자 | 금액 | import hashlib class WenivCoin: def __init__(self, 앞블록해쉬, 트렌젝션리스트): self.앞블록해쉬 = 앞블록해쉬 self.트렌젝션리스트 = 트렌젝션리스트 self.데이터 = &#39; - 트렌젝션 : &#39; + &#39; n - 트렌젝션 : &#39;.join(트렌젝션리스트) + &#39; n - 앞 블록 해쉬 &#39; + 앞블록해쉬 self.블록해쉬 = hashlib.sha256(self.데이터.encode()).hexdigest() . t1 = &#39;호준 -&gt; 길동, 1 위니브코인&#39; t2 = &#39;길동 -&gt; 춘향, 2 위니브코인&#39; t3 = &#39;춘향 -&gt; 준호, 3 위니브코인&#39; t4 = &#39;길동 -&gt; 호준, 1 위니브코인&#39; t5 = &#39;길동 -&gt; 준호, 2 위니브코인&#39; t6 = &#39;길동 -&gt; 준호, 3 위니브코인&#39; . 블록1 = WenivCoin(&#39;Initial_Text&#39;, [t1, t2]) . print(블록1.데이터) . - 트렌젝션 : 호준 -&gt; 길동, 1 위니브코인 - 트렌젝션 : 길동 -&gt; 춘향, 2 위니브코인 - 앞 블록 해쉬 Initial_Text . 블록1.블록해쉬 . &#39;c5a8aafb10091ec3dbdc4a69fd37d159e5655a844eb02bf06b4677c77943bd3a&#39; . 블록2 = WenivCoin(블록1.블록해쉬, [t3, t4]) . print(블록2.데이터) . - 트렌젝션 : 춘향 -&gt; 준호, 3 위니브코인 - 트렌젝션 : 길동 -&gt; 호준, 1 위니브코인 - 앞 블록 해쉬 c5a8aafb10091ec3dbdc4a69fd37d159e5655a844eb02bf06b4677c77943bd3a . 블록2.블록해쉬 . &#39;d4625b49036ac2934243cbe72f3ac5b49fad18520fdaad106657941ceadaaf4e&#39; . 블록3 = WenivCoin(블록2.블록해쉬, [t5, t6]) . print(블록3.데이터) . - 트렌젝션 : 길동 -&gt; 준호, 2 위니브코인 - 트렌젝션 : 길동 -&gt; 준호, 3 위니브코인 - 앞 블록 해쉬 d4625b49036ac2934243cbe72f3ac5b49fad18520fdaad106657941ceadaaf4e . 블록3.블록해쉬 . &#39;f029d6f425343f3307df5aa3bdcfc8e14bab27ae2f4cb70a1db53357322a6368&#39; . &#45936;&#51060;&#53552; &#48320;&#51312; . . . t3 = &#39;춘향 -&gt; 준호, 1 위니브코인&#39; . 블록2 = WenivCoin(블록1.블록해쉬, [t3, t4]) . 블록2.블록해쉬 . &#39;bf58d50d76194b193e7b659ed5d90c50ea20b1b63c4bf8749f7cb822a9fc498b&#39; . 블록3 = WenivCoin(블록2.블록해쉬, [t5, t6]) . print(블록3.데이터) . - 트렌젝션 : 길동 -&gt; 준호, 2 위니브코인 - 트렌젝션 : 길동 -&gt; 준호, 3 위니브코인 - 앞 블록 해쉬 bf58d50d76194b193e7b659ed5d90c50ea20b1b63c4bf8749f7cb822a9fc498b . 블록3.블록해쉬 . &#39;f803da32db04e11d60dc44901a374d46843effa8b7882f045ec05f984ae6176c&#39; .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/blockchain/python/2021/09/20/_09_20_blockchain_in_python.html",
            "relUrl": "/blockchain/python/2021/09/20/_09_20_blockchain_in_python.html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "엑셀라이터 xlsxwriter",
            "content": "xlsxwriter . 해당 강의는 인프런의 Python 엑셀 프로그래밍 - with xlsxwriter(https://inf.run/Vqew) 강의에 공개용 요약강좌입니다. | github(https://github.com/paullabkorea/xlsxwriter) 에서 모든 소스코드를 다운로드 받으실 수 있습니다. | 엑셀 차트, 이미지 삽입, 한글파일 -&gt; DataFrame 변환을 통한 데이터 분석 등은 요약강좌에서 다루지 않습니다. | 무료책인 인공지능을 활용한 업무자동화 책(2021 Version Notion)을 활용하면 좀 더 활용성이 극대화된 코딩이 가능합니다.(크롤링, 워드파일 크롤링, PDF크롤링, 문자 보내기 등) | 업무자동화 Notion 링크 : https://paullabworkspace.notion.site/2021-6192ed4219fc4e7a96e10b22cfa27c80 | . !pip3 install xlsxwriter . Collecting xlsxwriter Downloading XlsxWriter-1.4.4-py2.py3-none-any.whl (149 kB) |████████████████████████████████| 149 kB 7.0 MB/s Installing collected packages: xlsxwriter Successfully installed xlsxwriter-1.4.4 . workbook | worksheet | cell | . import xlsxwriter . workbook = xlsxwriter.Workbook(&#39;test.xlsx&#39;) #파일 안에 워크 시트 생성하기(test이름으로 생성, 여러개의 워크시트 만들 수 있음) worksheet = workbook.add_worksheet(&#39;test&#39;) #워크 시트 안에 문자열 값을 넣습니다. worksheet.write(&#39;A1&#39;, &#39;A&#39;) worksheet.write(&#39;B1&#39;, &#39;B&#39;) worksheet.write(&#39;C1&#39;, &#39;C&#39;) worksheet.write(&#39;D1&#39;, &#39;D&#39;) worksheet.write(&#39;E1&#39;, &#39;E&#39;) #워크 시트 안에 숫자 값을 넣습니다. worksheet.write(&#39;A2&#39;, 1) worksheet.write(&#39;B2&#39;, 2) worksheet.write(&#39;C2&#39;, 3) worksheet.write(&#39;D2&#39;, 4) worksheet.write(&#39;E2&#39;, 5) #워크 시트 안에 숫자 값을 넣습니다. worksheet.write(2, 0, 1) worksheet.write(2, 1, 2) worksheet.write(2, 2, 3) worksheet.write(2, 3, 4) worksheet.write(2, 4, 5) workbook.close() . workbook = xlsxwriter.Workbook(&#39;test.xlsx&#39;) #파일 안에 워크 시트 생성하기(test이름으로 생성, 여러개의 워크시트 만들 수 있음) worksheet = workbook.add_worksheet(&#39;test&#39;) #워크 시트 안에 숫자 값을 넣습니다. for i in range(10): # worksheet.write(행, 열, 값) worksheet.write(i, 0, i + 1) worksheet.write(i, 1, 60) workbook.close() . workbook = xlsxwriter.Workbook(&#39;test.xlsx&#39;) #파일 안에 워크 시트 생성하기(test이름으로 생성, 여러개의 워크시트 만들 수 있음) worksheet = workbook.add_worksheet(&#39;test&#39;) #워크 시트 안에 숫자 값을 넣습니다. # worksheet.write(행, 열, 값) worksheet.write(&#39;A1&#39;, 1) worksheet.write(&#39;B1&#39;, 2) worksheet.write(&#39;A2&#39;, &#39;=A1+B1&#39;) worksheet.write(&#39;B2&#39;, &#39;=A1-B1&#39;) worksheet.write(&#39;C2&#39;, &#39;=A1/B1&#39;) worksheet.write(&#39;D2&#39;, &#39;=A1*B1&#39;) workbook.close() . workbook = xlsxwriter.Workbook(&#39;test.xlsx&#39;) #파일 안에 워크 시트 생성하기(test이름으로 생성, 여러개의 워크시트 만들 수 있음) worksheet = workbook.add_worksheet(&#39;test&#39;) #워크 시트 안에 숫자 값을 넣습니다. # worksheet.write(행, 열, 값) worksheet.write(&#39;A1&#39;, 1) worksheet.write(&#39;B1&#39;, 2) worksheet.write(&#39;C1&#39;, 3) worksheet.write(&#39;D1&#39;, 4) worksheet.write(&#39;E1&#39;, 5) worksheet.write(&#39;A2&#39;, &#39;=SUM(A1:E1)&#39;) worksheet.write(&#39;B2&#39;, &#39;=AVERAGE(A1:E1)&#39;) workbook.close() . &#51060;&#47141;&#49436; &#48516;&#49437; . # https://olefile.readthedocs.io/en/latest/Howto.html # 우리 수업에서는 사용하지 않습니다. !pip install olefile . Collecting olefile Downloading olefile-0.46.zip (112 kB) |████████████████████████████████| 112 kB 36.9 MB/s Building wheels for collected packages: olefile Building wheel for olefile (setup.py) ... done Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35431 sha256=2ff2ed6a863189da0f3466dcbaa6822dc1394883808091af3bd58c58669bae25 Stored in directory: /root/.cache/pip/wheels/84/53/e6/37d90ccb3ad1a3ca98d2b17107e9fda401a7c541ea1eb6a65a Successfully built olefile Installing collected packages: olefile Successfully installed olefile-0.46 . !pip install ole-py . Collecting ole-py Downloading ole_py-1.1.2-py3-none-any.whl (7.5 kB) Installing collected packages: ole-py Successfully installed ole-py-1.1.2 . import ole . with ole.open(&#39;이력서_1.hwp&#39;) as f: print(f.list_streams()) print(&#39;=&#39; * 10) data = f.get_stream(&#39;PrvText&#39;).read().decode(&#39;utf-16le&#39;) print(data) . (&#39;FileHeader&#39;, &#39;DocInfo&#39;, &#39; x05HwpSummaryInformation&#39;, &#39;PrvImage&#39;, &#39;PrvText&#39;, &#39;Scripts/JScriptVersion&#39;, &#39;Scripts/DefaultJScript&#39;, &#39;DocOptions/_LinkDoc&#39;, &#39;BodyText/Section0&#39;) ========== 이 력 서 &lt;인적사항&gt;&lt;성 명&gt;&lt;홍길동&gt;&lt;생 년 월 일&gt;&lt;1993년 8월 13일&gt;&lt;현 주 소&gt;&lt;제주특별자치도 제주시&gt;&lt;연 락 처&gt;&lt;010-2233-1478&gt;&lt;이 메 일&gt;&lt;ab8ab@naver.com&gt; &lt;학력사항&gt;&lt;학교명&gt;&lt;전공&gt;&lt;성적&gt;&lt;졸업구분&gt;&lt;소재지&gt;&lt;건국대학교&gt;&lt;컴퓨터공학과&gt;&lt;4.1/4.5&gt;&lt;졸업&gt;&lt;서울&gt; &lt;자격면허&gt;&lt;자격면허증명&gt;&lt;시행기관&gt;&lt;취득년월&gt;&lt;TOEIC&gt;&lt;점수&gt;&lt;정보처리기사&gt;&lt;한국산업인력공단&gt;&lt;19.05.22&gt;&lt;725점&gt;&lt;한국사능력검정 1급&gt;&lt;국사편찬위원회&gt;&lt;19.08.23&gt; &lt;교육 / 활동 / 수상&gt;&lt;기간&gt;&lt;활동 내용&gt;&lt;병역사항&gt;&lt;군필여부&gt;&lt;군필&gt;&lt;19.11 ~ 20.03&gt;&lt;빅데이터 전략 마에스트로&gt;&lt;군별&gt;&lt;육군&gt;&lt;&gt;&lt;&gt;&lt;계급&gt;&lt;병장&gt;&lt;&gt;&lt;&gt;&lt;복무기간&gt;&lt;15.02~16.11&gt; &lt;컴퓨터 언어 능력 (상/중/하)&gt;&lt;R&gt;&lt;Python&gt;&lt;Javascript&gt;&lt;SQL&gt;&lt;HTML/CSS&gt;&lt;상&gt;&lt;중&gt;&lt;중&gt;&lt;하&gt;&lt;하&gt; 위의 내용은 사실과 틀림없음을 확인합니다. 2020년 5월 11일 성명 : 홍길동 . text = &#39;lee!ho!jun&#39; text.split(&#39;!&#39;) . [&#39;lee!h&#39;, &#39;o!jun&#39;] . data.split(&#39;&gt;&lt;&#39;) . [&#39;이 력 서 r n&lt;인적사항&#39;, &#39;성 명&#39;, &#39;홍길동&#39;, &#39;생 년 월 일&#39;, &#39;1993년 8월 13일&#39;, &#39;현 주 소&#39;, &#39;제주특별자치도 제주시&#39;, &#39;연 락 처&#39;, &#39;010-2233-1478&#39;, &#39;이 메 일&#39;, &#39;ab8ab@naver.com&gt; r n r n&lt;학력사항&#39;, &#39;학교명&#39;, &#39;전공&#39;, &#39;성적&#39;, &#39;졸업구분&#39;, &#39;소재지&#39;, &#39;건국대학교&#39;, &#39;컴퓨터공학과&#39;, &#39;4.1/4.5&#39;, &#39;졸업&#39;, &#39;서울&gt; r n r n&lt;자격면허&#39;, &#39;자격면허증명&#39;, &#39;시행기관&#39;, &#39;취득년월&#39;, &#39;TOEIC&#39;, &#39;점수&#39;, &#39;정보처리기사&#39;, &#39;한국산업인력공단&#39;, &#39;19.05.22&#39;, &#39;725점&#39;, &#39;한국사능력검정 1급&#39;, &#39;국사편찬위원회&#39;, &#39;19.08.23&gt; r n r n&lt;교육 / 활동 / 수상&#39;, &#39;기간&#39;, &#39;활동 내용&#39;, &#39;병역사항&#39;, &#39;군필여부&#39;, &#39;군필&#39;, &#39;19.11 ~ 20.03&#39;, &#39;빅데이터 전략 마에스트로&#39;, &#39;군별&#39;, &#39;육군&#39;, &#39;&#39;, &#39;&#39;, &#39;계급&#39;, &#39;병장&#39;, &#39;&#39;, &#39;&#39;, &#39;복무기간&#39;, &#39;15.02~16.11&gt; r n r n&lt;컴퓨터 언어 능력 (상/중/하)&#39;, &#39;R&#39;, &#39;Python&#39;, &#39;Javascript&#39;, &#39;SQL&#39;, &#39;HTML/CSS&#39;, &#39;상&#39;, &#39;중&#39;, &#39;중&#39;, &#39;하&#39;, &#39;하&gt; r n r n위의 내용은 사실과 틀림없음을 확인합니다. r n r n2020년 5월 11일 성명 : 홍길동 r n&#39;] . splitdata = data.split(&#39;&gt;&lt;&#39;) splitdata . [&#39;이 력 서 r n&lt;인적사항&#39;, &#39;성 명&#39;, &#39;홍길동&#39;, &#39;생 년 월 일&#39;, &#39;1993년 8월 13일&#39;, &#39;현 주 소&#39;, &#39;제주특별자치도 제주시&#39;, &#39;연 락 처&#39;, &#39;010-2233-1478&#39;, &#39;이 메 일&#39;, &#39;ab8ab@naver.com&gt; r n r n&lt;학력사항&#39;, &#39;학교명&#39;, &#39;전공&#39;, &#39;성적&#39;, &#39;졸업구분&#39;, &#39;소재지&#39;, &#39;건국대학교&#39;, &#39;컴퓨터공학과&#39;, &#39;4.1/4.5&#39;, &#39;졸업&#39;, &#39;서울&gt; r n r n&lt;자격면허&#39;, &#39;자격면허증명&#39;, &#39;시행기관&#39;, &#39;취득년월&#39;, &#39;TOEIC&#39;, &#39;점수&#39;, &#39;정보처리기사&#39;, &#39;한국산업인력공단&#39;, &#39;19.05.22&#39;, &#39;725점&#39;, &#39;한국사능력검정 1급&#39;, &#39;국사편찬위원회&#39;, &#39;19.08.23&gt; r n r n&lt;교육 / 활동 / 수상&#39;, &#39;기간&#39;, &#39;활동 내용&#39;, &#39;병역사항&#39;, &#39;군필여부&#39;, &#39;군필&#39;, &#39;19.11 ~ 20.03&#39;, &#39;빅데이터 전략 마에스트로&#39;, &#39;군별&#39;, &#39;육군&#39;, &#39;&#39;, &#39;&#39;, &#39;계급&#39;, &#39;병장&#39;, &#39;&#39;, &#39;&#39;, &#39;복무기간&#39;, &#39;15.02~16.11&gt; r n r n&lt;컴퓨터 언어 능력 (상/중/하)&#39;, &#39;R&#39;, &#39;Python&#39;, &#39;Javascript&#39;, &#39;SQL&#39;, &#39;HTML/CSS&#39;, &#39;상&#39;, &#39;중&#39;, &#39;중&#39;, &#39;하&#39;, &#39;하&gt; r n r n위의 내용은 사실과 틀림없음을 확인합니다. r n r n2020년 5월 11일 성명 : 홍길동 r n&#39;] . splitdata[2] . &#39;홍길동&#39; . splitdata[1] . &#39;성 명&#39; . splitdata.index(&#39;성 명&#39;) . 1 . splitdata . [&#39;이 력 서 r n&lt;인적사항&#39;, &#39;성 명&#39;, &#39;홍길동&#39;, &#39;생 년 월 일&#39;, &#39;1993년 8월 13일&#39;, &#39;현 주 소&#39;, &#39;제주특별자치도 제주시&#39;, &#39;연 락 처&#39;, &#39;010-2233-1478&#39;, &#39;이 메 일&#39;, &#39;ab8ab@naver.com&gt; r n r n&lt;학력사항&#39;, &#39;학교명&#39;, &#39;전공&#39;, &#39;성적&#39;, &#39;졸업구분&#39;, &#39;소재지&#39;, &#39;건국대학교&#39;, &#39;컴퓨터공학과&#39;, &#39;4.1/4.5&#39;, &#39;졸업&#39;, &#39;서울&gt; r n r n&lt;자격면허&#39;, &#39;자격면허증명&#39;, &#39;시행기관&#39;, &#39;취득년월&#39;, &#39;TOEIC&#39;, &#39;점수&#39;, &#39;정보처리기사&#39;, &#39;한국산업인력공단&#39;, &#39;19.05.22&#39;, &#39;725점&#39;, &#39;한국사능력검정 1급&#39;, &#39;국사편찬위원회&#39;, &#39;19.08.23&gt; r n r n&lt;교육 / 활동 / 수상&#39;, &#39;기간&#39;, &#39;활동 내용&#39;, &#39;병역사항&#39;, &#39;군필여부&#39;, &#39;군필&#39;, &#39;19.11 ~ 20.03&#39;, &#39;빅데이터 전략 마에스트로&#39;, &#39;군별&#39;, &#39;육군&#39;, &#39;&#39;, &#39;&#39;, &#39;계급&#39;, &#39;병장&#39;, &#39;&#39;, &#39;&#39;, &#39;복무기간&#39;, &#39;15.02~16.11&gt; r n r n&lt;컴퓨터 언어 능력 (상/중/하)&#39;, &#39;R&#39;, &#39;Python&#39;, &#39;Javascript&#39;, &#39;SQL&#39;, &#39;HTML/CSS&#39;, &#39;상&#39;, &#39;중&#39;, &#39;중&#39;, &#39;하&#39;, &#39;하&gt; r n r n위의 내용은 사실과 틀림없음을 확인합니다. r n r n2020년 5월 11일 성명 : 홍길동 r n&#39;] . 개인정보 = [ &#39;성 명&#39;, &#39;생 년 월 일&#39;, &#39;현 주 소&#39;, &#39;연 락 처&#39;, &#39;이 메 일&#39; ] . 결과 = [] for i in range(len(splitdata)): for j in range(len(개인정보)): if splitdata[i] == 개인정보[j]: 결과.append(splitdata[i + 1]) 결과 . [&#39;홍길동&#39;, &#39;1993년 8월 13일&#39;, &#39;제주특별자치도 제주시&#39;, &#39;010-2233-1478&#39;, &#39;ab8ab@naver.com&gt; r n r n&lt;학력사항&#39;] . 결과[-1] = 결과[-1].split(&#39;&gt;&#39;)[0] 결과 . [&#39;홍길동&#39;, &#39;1993년 8월 13일&#39;, &#39;제주특별자치도 제주시&#39;, &#39;010-2233-1478&#39;, &#39;ab8ab@naver.com&#39;] . 학력사항 = [ &#39;학교명&#39;, &#39;전공&#39;, &#39;성적&#39;, &#39;졸업구분&#39;, &#39;소재지&#39; ] . 학력사항결과 = [] for i in range(len(splitdata)): for j in range(len(학력사항)): if splitdata[i] == 학력사항[j]: 학력사항결과.append(splitdata[i + 5]) 학력사항결과 . [&#39;건국대학교&#39;, &#39;컴퓨터공학과&#39;, &#39;4.1/4.5&#39;, &#39;졸업&#39;, &#39;서울&gt; r n r n&lt;자격면허&#39;] . 학력사항결과[-1] = 학력사항결과[-1].split(&#39;&gt;&#39;)[0] 학력사항결과 . [&#39;건국대학교&#39;, &#39;컴퓨터공학과&#39;, &#39;4.1/4.5&#39;, &#39;졸업&#39;, &#39;서울&#39;] . index = 개인정보 + 학력사항 index . [&#39;성 명&#39;, &#39;생 년 월 일&#39;, &#39;현 주 소&#39;, &#39;연 락 처&#39;, &#39;이 메 일&#39;, &#39;학교명&#39;, &#39;전공&#39;, &#39;성적&#39;, &#39;졸업구분&#39;, &#39;소재지&#39;] . result = 결과 + 학력사항결과 result . [&#39;홍길동&#39;, &#39;1993년 8월 13일&#39;, &#39;제주특별자치도 제주시&#39;, &#39;010-2233-1478&#39;, &#39;ab8ab@naver.com&#39;, &#39;건국대학교&#39;, &#39;컴퓨터공학과&#39;, &#39;4.1/4.5&#39;, &#39;졸업&#39;, &#39;서울&#39;] . !pip install xlsxwriter . import xlsxwriter #엑셀 파일 생성하기(test.xlsx로 생성) workbook = xlsxwriter.Workbook(&#39;test.xlsx&#39;) #파일 안에 워크 시트 생성하기 worksheet = workbook.add_worksheet(&#39;test&#39;) # worksheet.write(2, 0, 1) worksheet.write(0, 0, index[0]) worksheet.write(0, 1, index[1]) worksheet.write(0, 2, index[2]) worksheet.write(0, 3, index[3]) workbook.close() . import xlsxwriter #엑셀 파일 생성하기(test.xlsx로 생성) workbook = xlsxwriter.Workbook(&#39;test.xlsx&#39;) #파일 안에 워크 시트 생성하기 worksheet = workbook.add_worksheet(&#39;test&#39;) for i in range(10): worksheet.write(0, i, index[i].replace(&#39; &#39;, &#39;&#39;)) for j in range(10): worksheet.write(1, j, result[j]) workbook.close() . &#39;he!!llo wor!!!ld&#39;.replace(&#39;!&#39;, &#39;@&#39;) . &#39;he@@llo wor@@@ld&#39; . glob . import glob path = (&#39;./*.hwp&#39;) for filename in glob.glob(path): print(filename) . ./이력서_51.hwp ./이력서_90.hwp ./이력서_12.hwp ./이력서_70.hwp ./이력서_13.hwp ./이력서_47.hwp ./이력서_48.hwp ./이력서_45.hwp ./이력서_5.hwp ./이력서_34.hwp ./이력서_40.hwp ./이력서_84.hwp ./이력서_18.hwp ./이력서_10.hwp ./이력서_71.hwp ./이력서_43.hwp ./이력서_42.hwp ./이력서_20.hwp ./이력서_73.hwp ./이력서_46.hwp ./이력서_11.hwp ./이력서_60.hwp ./이력서_23.hwp ./이력서_94.hwp ./이력서_37.hwp ./이력서_83.hwp ./이력서_92.hwp ./이력서_97.hwp ./이력서_36.hwp ./이력서_19.hwp ./이력서_39.hwp ./이력서_22.hwp ./이력서_85.hwp ./이력서_76.hwp ./이력서_32.hwp ./이력서_28.hwp ./이력서_44.hwp ./이력서_99.hwp ./이력서_68.hwp ./이력서_82.hwp ./이력서_53.hwp ./이력서_33.hwp ./이력서_31.hwp ./이력서_24.hwp ./이력서_26.hwp ./이력서_80.hwp ./이력서_67.hwp ./이력서_1.hwp ./이력서_16.hwp ./이력서_75.hwp ./이력서_17.hwp ./이력서_87.hwp ./이력서_30.hwp ./이력서_65.hwp ./이력서_54.hwp ./이력서_79.hwp ./이력서_49.hwp ./이력서_57.hwp ./이력서_61.hwp ./이력서_3.hwp ./이력서_58.hwp ./이력서_93.hwp ./이력서_27.hwp ./이력서_89.hwp ./이력서_52.hwp ./이력서_72.hwp ./이력서_25.hwp ./이력서_55.hwp ./이력서_50.hwp ./이력서_9.hwp ./이력서_64.hwp ./이력서_2.hwp ./이력서_98.hwp ./이력서_7.hwp ./이력서_81.hwp ./이력서_4.hwp ./이력서_95.hwp ./이력서_86.hwp ./이력서_14.hwp ./이력서_6.hwp ./이력서_8.hwp ./이력서_100.hwp ./이력서_15.hwp ./이력서_59.hwp ./이력서_62.hwp ./이력서_35.hwp ./이력서_88.hwp ./이력서_69.hwp ./이력서_21.hwp ./이력서_77.hwp ./이력서_74.hwp ./이력서_38.hwp ./이력서_96.hwp ./이력서_63.hwp ./이력서_66.hwp ./이력서_29.hwp ./이력서_56.hwp ./이력서_78.hwp ./이력서_41.hwp ./이력서_91.hwp . filelist = !ls . filelist . [&#39;sample_data&#39;] .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/python/xlsxwriter/2021/09/20/_08_07_%EC%97%91%EC%85%80%EB%9D%BC%EC%9D%B4%ED%84%B0(xlsxwriter).html",
            "relUrl": "/python/xlsxwriter/2021/09/20/_08_07_%EC%97%91%EC%85%80%EB%9D%BC%EC%9D%B4%ED%84%B0(xlsxwriter).html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "fastpages test",
            "content": "inline . Inline math: $f(x)$ . Inline math: $f(x)$ . Full line: . $$ f(x) $$ . $$f(x)$$test line . github.dev에서 수정 .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/etc/2021/09/20/_08_05_LaTex_Test.html",
            "relUrl": "/etc/2021/09/20/_08_05_LaTex_Test.html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "2021년 보스턴 집값 예측 Study blog",
            "content": "&#46972;&#51060;&#48652;&#47084;&#47532; &#49324;&#50857; . import tensorflow as tf import pandas as pd . &#45936;&#51060;&#53552; &#51456;&#48708; . row : 506 | col : 14 | 보스턴 주택 가격 데이터(1000달러 기준)와 주택 가격에 영향을 미칠만한 데이터 | CRIM : 범죄율 | ZN : 25,000 평방피트를 초과하는 거주지역의 비율 | INDUS : 비소매상업지역이 점유하고 있는 토지의 비율 | CHAS : 찰스강에 대한 더미변수(강의 경계에 위치한 경우는 1, 아니면 0) | NOX : 10ppm 당 농축 일산화질소 | RM : 주택 1가구당 평균 방의 개수 | AGE : 1940년 이전에 건축된 소유주택의 비율 | DIS : 5개의 보스턴 직업센터까지의 접근성 지수 | RAD : 방사형 도로까지의 접근성 지수 | TAX : 10,000 달러 당 재산세율 | PTRATIO : 자치시(town)별 학생/교사 비율 | B : 1000(Bk-0.63)^2, 여기서 Bk는 자치시별 흑인의 비율을 말함. | LSTAT : 모집단의 하위계층의 비율(%) | MEDV : 본인 소유의 주택가격(중앙값) (단위: $1,000) | . 출처: https://ai-times.tistory.com/431 [ai-times] . 파일경로 = &#39;https://raw.githubusercontent.com/blackdew/tensorflow1/master/csv/boston.csv&#39; 보스턴 = pd.read_csv(파일경로) print(보스턴.columns) 보스턴.head() . Index([&#39;crim&#39;, &#39;zn&#39;, &#39;indus&#39;, &#39;chas&#39;, &#39;nox&#39;, &#39;rm&#39;, &#39;age&#39;, &#39;dis&#39;, &#39;rad&#39;, &#39;tax&#39;, &#39;ptratio&#39;, &#39;b&#39;, &#39;lstat&#39;, &#39;medv&#39;], dtype=&#39;object&#39;) . crim zn indus chas nox rm age dis rad tax ptratio b lstat medv . 0 0.00632 | 18.0 | 2.31 | 0 | 0.538 | 6.575 | 65.2 | 4.0900 | 1 | 296 | 15.3 | 396.90 | 4.98 | 24.0 | . 1 0.02731 | 0.0 | 7.07 | 0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2 | 242 | 17.8 | 396.90 | 9.14 | 21.6 | . 2 0.02729 | 0.0 | 7.07 | 0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2 | 242 | 17.8 | 392.83 | 4.03 | 34.7 | . 3 0.03237 | 0.0 | 2.18 | 0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3 | 222 | 18.7 | 394.63 | 2.94 | 33.4 | . 4 0.06905 | 0.0 | 2.18 | 0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3 | 222 | 18.7 | 396.90 | 5.33 | 36.2 | . 보스턴.tail() . crim zn indus chas nox rm age dis rad tax ptratio b lstat medv . 501 0.06263 | 0.0 | 11.93 | 0 | 0.573 | 6.593 | 69.1 | 2.4786 | 1 | 273 | 21.0 | 391.99 | 9.67 | 22.4 | . 502 0.04527 | 0.0 | 11.93 | 0 | 0.573 | 6.120 | 76.7 | 2.2875 | 1 | 273 | 21.0 | 396.90 | 9.08 | 20.6 | . 503 0.06076 | 0.0 | 11.93 | 0 | 0.573 | 6.976 | 91.0 | 2.1675 | 1 | 273 | 21.0 | 396.90 | 5.64 | 23.9 | . 504 0.10959 | 0.0 | 11.93 | 0 | 0.573 | 6.794 | 89.3 | 2.3889 | 1 | 273 | 21.0 | 393.45 | 6.48 | 22.0 | . 505 0.04741 | 0.0 | 11.93 | 0 | 0.573 | 6.030 | 80.8 | 2.5050 | 1 | 273 | 21.0 | 396.90 | 7.88 | 11.9 | . 보스턴.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 506 entries, 0 to 505 Data columns (total 14 columns): # Column Non-Null Count Dtype -- -- 0 crim 506 non-null float64 1 zn 506 non-null float64 2 indus 506 non-null float64 3 chas 506 non-null int64 4 nox 506 non-null float64 5 rm 506 non-null float64 6 age 506 non-null float64 7 dis 506 non-null float64 8 rad 506 non-null int64 9 tax 506 non-null int64 10 ptratio 506 non-null float64 11 b 506 non-null float64 12 lstat 506 non-null float64 13 medv 506 non-null float64 dtypes: float64(11), int64(3) memory usage: 55.5 KB . 보스턴.age.mean() # 1940년 이전에 건축된 소유주택의 비율 . 68.57490118577078 . 보스턴[[&#39;crim&#39;]].mean() . crim 3.613524 dtype: float64 . 보스턴[[&#39;crim&#39;]].max() . crim 88.9762 dtype: float64 . 보스턴[[&#39;crim&#39;]].min() . crim 0.00632 dtype: float64 . 보스턴.boxplot(column=[&#39;crim&#39;]) # 이상치 제거 필요 . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f63e3ad5ad0&gt; . &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . . &#47784;&#45944;&#47553; . 독립 = 보스턴[[&#39;crim&#39;, &#39;zn&#39;, &#39;indus&#39;, &#39;chas&#39;, &#39;nox&#39;, &#39;rm&#39;, &#39;age&#39;, &#39;dis&#39;, &#39;rad&#39;, &#39;tax&#39;, &#39;ptratio&#39;, &#39;b&#39;, &#39;lstat&#39;]] 종속 = 보스턴[[&#39;medv&#39;]] print(독립.shape, 종속.shape) . (506, 13) (506, 1) . X = tf.keras.layers.Input(shape=[13]) # 독립에서의 col Y = tf.keras.layers.Dense(1)(X) # 종속에서의 col model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) . model.fit(독립, 종속, epochs=10000, verbose=0) model.fit(독립, 종속, epochs=10) . Epoch 1/10 16/16 [==============================] - 0s 1ms/step - loss: 23.3325 Epoch 2/10 16/16 [==============================] - 0s 1ms/step - loss: 23.6406 Epoch 3/10 16/16 [==============================] - 0s 1ms/step - loss: 24.2017 Epoch 4/10 16/16 [==============================] - 0s 1ms/step - loss: 22.9282 Epoch 5/10 16/16 [==============================] - 0s 1ms/step - loss: 23.6037 Epoch 6/10 16/16 [==============================] - 0s 1ms/step - loss: 23.7327 Epoch 7/10 16/16 [==============================] - 0s 1ms/step - loss: 22.9146 Epoch 8/10 16/16 [==============================] - 0s 1ms/step - loss: 23.8316 Epoch 9/10 16/16 [==============================] - 0s 1ms/step - loss: 23.7118 Epoch 10/10 16/16 [==============================] - 0s 1ms/step - loss: 23.2829 . &lt;tensorflow.python.keras.callbacks.History at 0x7f63db666d50&gt; . # 예측값 print(model.predict(독립[0:5])) # 실제값(종속변수 확인) print(종속[0:5]) . [[29.279457] [24.11077 ] [30.636097] [29.275276] [28.885345]] medv 0 24.0 1 21.6 2 34.7 3 33.4 4 36.2 . 예측값 = model.predict(독립) 실제값 = 종속 . 오차값 = (예측값 - 실제값)**2 오차값.head() . medv . 0 28.382128 | . 1 7.256643 | . 2 16.445512 | . 3 18.144550 | . 4 56.123259 | . 오차값.mean() #MSE . medv 23.07116 dtype: float64 . model.get_weights() . [array([[-0.09769897], [ 0.04758811], [-0.01014985], [ 2.6305165 ], [-5.6234183 ], [ 5.012733 ], [-0.00839883], [-1.1512003 ], [ 0.2200571 ], [-0.01184279], [-0.6021571 ], [ 0.01250572], [-0.47408003]], dtype=float32), array([13.713469], dtype=float32)] . 예측값[0] . array([29.327488], dtype=float32) . 독립.iloc[0] . crim 0.00632 zn 18.00000 indus 2.31000 chas 0.00000 nox 0.53800 rm 6.57500 age 65.20000 dis 4.09000 rad 1.00000 tax 296.00000 ptratio 15.30000 b 396.90000 lstat 4.98000 Name: 0, dtype: float64 . &#39;&#39;&#39; crim 0.00632 * -0.09769897 zn 18.00000 * 0.04758811 indus 2.31000 * -0.01014985 chas 0.00000 * 2.6305165 nox 0.53800 * -5.6234183 rm 6.57500 * 5.012733 age 65.20000 * -0.00839883 dis 4.09000 * -1.1512003 rad 1.00000 * 0.2200571 tax 296.00000 * -0.01184279 ptratio 15.30000 * -0.6021571 b 396.90000 * 0.01250572 lstat 4.98000 * -0.47408003 + 13.713469 [array([[-0.09769897], [ 0.04758811], [-0.01014985], [ 2.6305165 ], [-5.6234183 ], [ 5.012733 ], [-0.00839883], [-1.1512003 ], [ 0.2200571 ], [-0.01184279], [-0.6021571 ], [ 0.01250572], [-0.47408003]], dtype=float32), array([13.713469], dtype=float32)] &#39;&#39;&#39; . 0.00632 * -0.09769897 + 18.00000 * 0.04758811 + 2.31000 * -0.01014985 + 0.00000 * 2.6305165 + 0.53800 * -5.6234183 + 6.57500 * 5.012733 + 65.20000 * -0.00839883 + 4.09000 * -1.1512003 + 1.00000 * 0.2200571 + 296.00000 * -0.01184279 + 15.30000 * -0.6021571 + 396.90000 * 0.01250572 + 4.98000 * -0.47408003 + 13.713469 . 29.3274882042096 . CSV &#54028;&#51068; &#49373;&#49457; . 예측값 = model.predict(독립) 예측값 . 예측값 = pd.DataFrame(예측값) 예측값.to_csv(&#39;result.csv&#39;) . &#44256;&#46020;&#54868; &#51089;&#50629; - 1 . X = tf.keras.layers.Input(shape=[13]) # 독립변수의 col H = tf.keras.layers.Dense(200, activation=&#39;swish&#39;)(X) # 노드의 수는 천천히 늘려감! (2 ~ 200) H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 처음에는 주석처리! H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 처음에는 주석처리! H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 처음에는 주석처리! H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 처음에는 주석처리! Y = tf.keras.layers.Dense(1)(H) # 종속변수의 col model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) # MSE(Mean squared error) . model.summary() . Model: &#34;model_3&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_4 (InputLayer) [(None, 13)] 0 _________________________________________________________________ dense_13 (Dense) (None, 200) 2800 _________________________________________________________________ dense_14 (Dense) (None, 5) 1005 _________________________________________________________________ dense_15 (Dense) (None, 5) 30 _________________________________________________________________ dense_16 (Dense) (None, 5) 30 _________________________________________________________________ dense_17 (Dense) (None, 5) 30 _________________________________________________________________ dense_18 (Dense) (None, 1) 6 ================================================================= Total params: 3,901 Trainable params: 3,901 Non-trainable params: 0 _________________________________________________________________ . plot_model(model) . model.fit(독립, 종속, epochs=1000, verbose=0) model.fit(독립, 종속, epochs=10) . Epoch 1/10 16/16 [==============================] - 0s 1ms/step - loss: 7.7405 Epoch 2/10 16/16 [==============================] - 0s 2ms/step - loss: 7.7418 Epoch 3/10 16/16 [==============================] - 0s 2ms/step - loss: 6.9789 Epoch 4/10 16/16 [==============================] - 0s 2ms/step - loss: 10.1850 Epoch 5/10 16/16 [==============================] - 0s 3ms/step - loss: 8.2013 Epoch 6/10 16/16 [==============================] - 0s 2ms/step - loss: 7.9208 Epoch 7/10 16/16 [==============================] - 0s 2ms/step - loss: 7.9824 Epoch 8/10 16/16 [==============================] - 0s 1ms/step - loss: 8.7595 Epoch 9/10 16/16 [==============================] - 0s 2ms/step - loss: 7.8617 Epoch 10/10 16/16 [==============================] - 0s 1ms/step - loss: 7.4242 . &lt;tensorflow.python.keras.callbacks.History at 0x7f63daf7c290&gt; . # 예측값 print(model.predict(독립[0:5])) # 실제값(종속변수 확인) print(종속[0:5]) . [[37.54553 ] [21.55653 ] [32.446022] [36.555557] [33.97718 ]] medv 0 24.0 1 21.6 2 34.7 3 33.4 4 36.2 . &#44256;&#46020;&#54868; &#51089;&#50629; - 2 . 출처 : 이수안컴퓨터연구소, 케라스 보스턴 주택 가격 모델 | 유튜브 영상 : https://youtu.be/utP3gh9DZI8 | . import tensorflow as tf from tensorflow.keras.datasets.boston_housing import load_data from tensorflow.keras.layers import Dense from tensorflow.keras.models import Sequential from tensorflow.keras.optimizers import Adam from tensorflow.keras.utils import plot_model from sklearn.model_selection import train_test_split import numpy as np import pandas as pd . import matplotlib.pyplot as plt plt.style.use(&#39;seaborn-white&#39;) . import random random.randint(1, 10)# 1부터 10까지의 값을 가짐 . 8 . import random random.seed(5) random.randint(1, 10)# 1부터 10까지의 값을 가짐 . 10 . tf.random.set_seed(111) (x_train_full, y_train_full), (x_test, y_test) = load_data(path=&#39;boston_housing.npz&#39;, test_split=0.2, seed=111) . Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz 57344/57026 [==============================] - 0s 0us/step . x_train_full # 집값의 독립변수 . array([[2.87500e-02, 2.80000e+01, 1.50400e+01, ..., 1.82000e+01, 3.96330e+02, 6.21000e+00], [6.14700e-01, 0.00000e+00, 6.20000e+00, ..., 1.74000e+01, 3.96900e+02, 7.60000e+00], [2.76300e-02, 7.50000e+01, 2.95000e+00, ..., 1.83000e+01, 3.95630e+02, 4.32000e+00], ..., [8.15174e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01, 3.96900e+02, 2.08500e+01], [3.11300e-02, 0.00000e+00, 4.39000e+00, ..., 1.88000e+01, 3.85640e+02, 1.05300e+01], [1.10874e+01, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01, 3.18750e+02, 1.50200e+01]]) . y_train_full # 집값의 정답값(종속변수) . array([25. , 30.1, 30.8, 20.5, 48.5, 22.1, 35.1, 15.6, 22.7, 9.6, 25.2, 50. , 24.4, 29. , 13.1, 22.6, 26.2, 21.7, 14.5, 22.5, 11.7, 22. , 23.8, 29.6, 11.9, 18.6, 48.3, 24.4, 23.1, 17.9, 31.1, 5. , 14.6, 24.1, 44.8, 29.6, 7.2, 50. , 23.1, 15.1, 22.8, 27.5, 27.5, 22.9, 21.7, 31. , 28.4, 14. , 50. , 16.7, 20.3, 36.2, 15.2, 20.6, 21.9, 21.2, 19.9, 20.3, 10.4, 19.8, 20.6, 26.6, 22. , 20.1, 19.2, 24.6, 28.2, 36. , 25. , 25. , 28.7, 15.3, 11.3, 14.3, 33.3, 21.4, 23.7, 22.5, 22.2, 27.9, 13.8, 13.9, 9.7, 36.5, 15.4, 20.4, 50. , 29.1, 18.3, 14.9, 12.6, 13.9, 24.4, 16.3, 18.5, 10.2, 19.5, 25. , 15.6, 13.8, 20.9, 22. , 50. , 22.2, 23.4, 17.8, 11.7, 50. , 23.5, 12.3, 18.4, 13.2, 25. , 20.1, 28.7, 19.9, 7.4, 20. , 29.1, 24. , 44. , 12. , 36.4, 16.5, 23. , 7. , 34.7, 23.9, 23.8, 17.6, 16.6, 35.4, 50. , 24.8, 22.8, 17. , 48.8, 31.6, 13.8, 22.2, 32.7, 15.6, 7.2, 21.4, 11.9, 22. , 14.6, 20.2, 21.5, 19.3, 18.4, 24.3, 34.9, 26.5, 10.5, 20.8, 23.2, 10.4, 37.9, 7.2, 33.2, 24.4, 19.4, 18.3, 18.9, 21.4, 15. , 23.7, 15.7, 32.5, 17.2, 32.4, 23.8, 20.7, 31.5, 46. , 20. , 24.3, 10.2, 8.8, 16.1, 27.9, 8.3, 36.2, 26.6, 15.2, 21. , 21.9, 19.9, 13.4, 22. , 18.8, 22. , 19.3, 33.1, 13.6, 30.1, 33.2, 39.8, 22.7, 19.2, 28.4, 19.7, 23.1, 19.5, 5.6, 21.7, 10.9, 29.8, 12.7, 19. , 21. , 16.6, 19.4, 21.7, 21.8, 16. , 25. , 27.5, 24.7, 37.2, 17.2, 13.4, 18.8, 10.9, 13.4, 23. , 18.5, 20. , 28.1, 10.8, 24.7, 23.7, 20.6, 34.9, 20.6, 37.3, 22.9, 22.8, 14.9, 20.1, 35.4, 23.4, 18.9, 50. , 22.2, 37. , 33.1, 42.8, 15. , 23.1, 19.4, 45.4, 12.7, 29. , 21.1, 18.4, 8.5, 26.6, 19.4, 50. , 20.6, 13.1, 19.1, 50. , 24.7, 18.5, 26.4, 19.5, 21.2, 23. , 18.2, 7.5, 17.8, 21.2, 22.8, 17.7, 24.5, 23.6, 23.9, 14.2, 28.6, 15.6, 17.5, 31.6, 24.8, 13.8, 13.4, 22.9, 17.8, 19.6, 19.1, 16.2, 20.6, 16.8, 50. , 18.9, 31.5, 30.5, 23.2, 24.5, 23.1, 33.4, 17.1, 7. , 20.1, 50. , 23.2, 11. , 18. , 23.3, 22.6, 20.8, 12.7, 29.4, 22.6, 11.8, 22.6, 23.1, 21.6, 19.8, 34.6, 21.2, 20.3, 19.9, 18.2, 13.1, 24.5, 34.9, 24.8, 8.4, 17.4, 23.3, 30.3, 19.3, 20. , 50. , 15.4, 29.9, 28.5, 23.3, 21.7, 8.7, 13.3, 20. , 19.4, 11.8, 18.2, 14.3, 28.7, 8.1, 21.5, 15.2, 12.1, 20.3, 14.4, 18.5, 5. , 41.7, 16.2, 14.5, 20.2, 19.4, 23.9, 24.1, 15. , 23.2, 21.8, 17.2, 18.7, 14.8, 43.8, 22.4, 28. , 16.1, 16.5, 24.2, 20.5, 22.6, 12.8, 13.1, 18.7, 8.5, 30.1, 26.4, 14.1, 8.4, 20.1, 21.7, 43.1, 16.8, 22.3, 17.5, 10.5, 6.3, 21.7, 13.5, 36.1, 14.1, 19.8, 18.6, 11.5, 17.5, 16.7]) . x_train_full.shape . (404, 13) . y_train_full.shape . (404,) . # &#39;crim&#39;, &#39;zn&#39;, &#39;indus&#39;, &#39;chas&#39;, &#39;nox&#39;, &#39;rm&#39;, &#39;age&#39;, &#39;dis&#39;, &#39;rad&#39;, &#39;tax&#39;, &#39;ptratio&#39;, &#39;b&#39;, &#39;lstat&#39;, &#39;medv&#39; # x_train_full.shape : &#39;crim&#39;(범죄율), &#39;zn&#39;, &#39;indus&#39;, &#39;chas&#39;, &#39;nox&#39;, &#39;rm&#39;, &#39;age&#39;, &#39;dis&#39;, &#39;rad&#39;, &#39;tax&#39;, &#39;ptratio&#39;, &#39;b&#39;, &#39;lstat&#39; # y_train_full.shape : &#39;medv&#39;(집값, 1000 달러 단위) . (x_test.shape, y_test.shape) . ((102, 13), (102,)) . &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . arr = [[10, 20, 30], [3, 50, 5], [70, 80, 90], [100, 110, 120]] print(&quot;Two Dimension array :&quot;, arr) print(&quot;Mean with no axis :&quot;, np.mean(arr)) print(&quot;Mean with axis along column :&quot;, np.mean(arr, axis=0)) # row 평균을 구함, 값은 col으로 구해짐 print(&quot;Mean with axis aong row :&quot;, np.mean(arr, axis=1)) # col 평균을 구함, 값은 row으로 구해짐 . Two Dimension array : [[10, 20, 30], [3, 50, 5], [70, 80, 90], [100, 110, 120]] Mean with no axis : 57.333333333333336 Mean with axis along column : [45.75 65. 61.25] Mean with axis aong row : [ 20. 19.33333333 80. 110. ] . np.sum(arr) / 12 . 57.333333333333336 . mean = np.mean(x_train_full, axis=0) std = np.std(x_train_full, axis=0) x_train_preprocessed = (x_train_full - mean) / std # 데이터의 스케일을 줄이기 위해 사용하는 것 x_test = (x_test - mean) / std x_train, x_val, y_train, y_val = train_test_split(x_train_preprocessed, y_train_full, test_size=0.3, random_state=111) . x_train.shape, x_val.shape, y_train.shape, y_val.shape . ((282, 13), (122, 13), (282,), (122,)) . &#47784;&#45944; &#44396;&#49457; . 학습 데이터가 매우 적은 경우 모델의 깊이를 깊게 할수록 과대적합(Overfitting)이 일어날 확율이 높음 | . &#39;&#39;&#39; # 히든레이어 모델 준비 X = tf.keras.layers.Input(shape=[13]) # 독립변수의 col H = tf.keras.layers.Dense(200, activation=&#39;swish&#39;)(X) # 노드의 수는 천천히 늘려감! (2 ~ 200) H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 처음에는 주석처리! H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 처음에는 주석처리! H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 처음에는 주석처리! H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 처음에는 주석처리! Y = tf.keras.layers.Dense(1)(H) # 종속변수의 col model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) # MSE(Mean squared error) &#39;&#39;&#39; model = Sequential([Dense(100, activation=&#39;relu&#39;, input_shape=(13, ), name=&#39;dense1&#39;), Dense(64, activation=&#39;relu&#39;, name=&#39;dense2&#39;), Dense(32, activation=&#39;relu&#39;, name=&#39;dense3&#39;), Dense(1, name=&#39;output&#39;)]) . model.summary() . Model: &#34;sequential_1&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense1 (Dense) (None, 100) 1400 _________________________________________________________________ dense2 (Dense) (None, 64) 6464 _________________________________________________________________ dense3 (Dense) (None, 32) 2080 _________________________________________________________________ output (Dense) (None, 1) 33 ================================================================= Total params: 9,977 Trainable params: 9,977 Non-trainable params: 0 _________________________________________________________________ . plot_model(model) . model.compile(loss=&#39;mse&#39;, optimizer=Adam(learning_rate=1e-2), metrics=[&#39;mae&#39;]) # MAE는 절대 평균 오차로 MSE처럼 제곱을 하지 않고 절대값을 씌어 평균을 냄 # MSE와 MAE : https://wooono.tistory.com/99 # Adam은 파라미터마다 다른 크기의 업데이트를 적용하는 방법! # Adam에 대한 보다 상세한 글 : https://hiddenbeginner.github.io/deeplearning/2019/09/22/optimization_algorithms_in_deep_learning.html # 잘 모르겠으면 일단 아담을 사용하라는 글 : https://sacko.tistory.com/42 ## 각각 옵션에 대한 상세한 글 : ## https://wikidocs.net/36033 ## https://onesixx.com/optimizer-loss-metrics/ . history = model.fit(x_train, y_train, epochs=300, validation_data=(x_val, y_val)) . Epoch 1/300 9/9 [==============================] - 1s 21ms/step - loss: 284.5112 - mae: 14.0540 - val_loss: 101.7117 - val_mae: 8.4467 Epoch 2/300 9/9 [==============================] - 0s 5ms/step - loss: 54.0324 - mae: 5.5914 - val_loss: 32.2761 - val_mae: 4.2198 Epoch 3/300 9/9 [==============================] - 0s 4ms/step - loss: 27.8157 - mae: 3.7876 - val_loss: 20.7668 - val_mae: 3.3478 Epoch 4/300 9/9 [==============================] - 0s 4ms/step - loss: 19.2665 - mae: 3.1608 - val_loss: 14.5887 - val_mae: 3.0283 Epoch 5/300 9/9 [==============================] - 0s 4ms/step - loss: 14.9836 - mae: 2.7218 - val_loss: 14.2842 - val_mae: 2.8176 Epoch 6/300 9/9 [==============================] - 0s 4ms/step - loss: 13.3089 - mae: 2.5932 - val_loss: 11.3557 - val_mae: 2.5460 Epoch 7/300 9/9 [==============================] - 0s 4ms/step - loss: 12.1528 - mae: 2.4447 - val_loss: 10.4115 - val_mae: 2.4610 Epoch 8/300 9/9 [==============================] - 0s 4ms/step - loss: 12.1903 - mae: 2.5271 - val_loss: 11.3119 - val_mae: 2.4856 Epoch 9/300 9/9 [==============================] - 0s 4ms/step - loss: 11.3173 - mae: 2.4005 - val_loss: 9.7402 - val_mae: 2.4195 Epoch 10/300 9/9 [==============================] - 0s 5ms/step - loss: 10.5424 - mae: 2.3713 - val_loss: 9.2937 - val_mae: 2.3253 Epoch 11/300 9/9 [==============================] - 0s 4ms/step - loss: 9.8692 - mae: 2.2519 - val_loss: 12.5149 - val_mae: 2.5708 Epoch 12/300 9/9 [==============================] - 0s 7ms/step - loss: 10.3525 - mae: 2.3773 - val_loss: 9.5581 - val_mae: 2.4654 Epoch 13/300 9/9 [==============================] - 0s 4ms/step - loss: 9.0872 - mae: 2.1746 - val_loss: 8.9033 - val_mae: 2.3131 Epoch 14/300 9/9 [==============================] - 0s 5ms/step - loss: 8.8682 - mae: 2.1138 - val_loss: 9.3241 - val_mae: 2.3729 Epoch 15/300 9/9 [==============================] - 0s 5ms/step - loss: 8.5467 - mae: 2.0509 - val_loss: 7.9374 - val_mae: 2.2252 Epoch 16/300 9/9 [==============================] - 0s 4ms/step - loss: 7.8166 - mae: 2.0610 - val_loss: 8.0780 - val_mae: 2.1683 Epoch 17/300 9/9 [==============================] - 0s 4ms/step - loss: 8.1478 - mae: 2.0726 - val_loss: 11.8896 - val_mae: 2.7745 Epoch 18/300 9/9 [==============================] - 0s 5ms/step - loss: 9.4028 - mae: 2.3156 - val_loss: 9.1295 - val_mae: 2.3945 Epoch 19/300 9/9 [==============================] - 0s 5ms/step - loss: 8.3677 - mae: 2.0804 - val_loss: 8.5966 - val_mae: 2.2688 Epoch 20/300 9/9 [==============================] - 0s 5ms/step - loss: 7.5441 - mae: 1.9226 - val_loss: 10.3885 - val_mae: 2.4832 Epoch 21/300 9/9 [==============================] - 0s 5ms/step - loss: 7.4639 - mae: 2.0313 - val_loss: 8.1804 - val_mae: 2.1646 Epoch 22/300 9/9 [==============================] - 0s 5ms/step - loss: 6.8445 - mae: 1.9647 - val_loss: 9.1997 - val_mae: 2.3798 Epoch 23/300 9/9 [==============================] - 0s 5ms/step - loss: 7.1956 - mae: 2.0406 - val_loss: 9.5129 - val_mae: 2.3559 Epoch 24/300 9/9 [==============================] - 0s 4ms/step - loss: 6.0134 - mae: 1.8190 - val_loss: 7.7562 - val_mae: 2.1807 Epoch 25/300 9/9 [==============================] - 0s 4ms/step - loss: 5.9984 - mae: 1.8414 - val_loss: 7.3719 - val_mae: 2.0447 Epoch 26/300 9/9 [==============================] - 0s 7ms/step - loss: 5.9729 - mae: 1.7940 - val_loss: 8.6394 - val_mae: 2.2846 Epoch 27/300 9/9 [==============================] - 0s 4ms/step - loss: 5.9945 - mae: 1.9084 - val_loss: 8.5585 - val_mae: 2.2463 Epoch 28/300 9/9 [==============================] - 0s 6ms/step - loss: 5.3401 - mae: 1.6995 - val_loss: 8.0528 - val_mae: 2.1966 Epoch 29/300 9/9 [==============================] - 0s 5ms/step - loss: 5.1501 - mae: 1.6918 - val_loss: 7.6480 - val_mae: 2.1288 Epoch 30/300 9/9 [==============================] - 0s 4ms/step - loss: 4.7328 - mae: 1.6866 - val_loss: 9.0202 - val_mae: 2.2249 Epoch 31/300 9/9 [==============================] - 0s 5ms/step - loss: 5.6758 - mae: 1.7797 - val_loss: 9.6781 - val_mae: 2.3580 Epoch 32/300 9/9 [==============================] - 0s 5ms/step - loss: 4.5855 - mae: 1.6315 - val_loss: 11.5347 - val_mae: 2.4384 Epoch 33/300 9/9 [==============================] - 0s 5ms/step - loss: 5.0049 - mae: 1.6514 - val_loss: 9.5657 - val_mae: 2.3244 Epoch 34/300 9/9 [==============================] - 0s 4ms/step - loss: 4.7753 - mae: 1.6492 - val_loss: 7.9665 - val_mae: 2.1009 Epoch 35/300 9/9 [==============================] - 0s 5ms/step - loss: 4.4168 - mae: 1.5755 - val_loss: 9.2074 - val_mae: 2.3016 Epoch 36/300 9/9 [==============================] - 0s 4ms/step - loss: 3.9583 - mae: 1.4918 - val_loss: 8.7889 - val_mae: 2.2092 Epoch 37/300 9/9 [==============================] - 0s 6ms/step - loss: 3.7794 - mae: 1.4789 - val_loss: 8.0425 - val_mae: 2.1058 Epoch 38/300 9/9 [==============================] - 0s 4ms/step - loss: 3.8976 - mae: 1.5078 - val_loss: 12.2869 - val_mae: 2.6816 Epoch 39/300 9/9 [==============================] - 0s 4ms/step - loss: 4.3649 - mae: 1.6286 - val_loss: 9.5141 - val_mae: 2.3699 Epoch 40/300 9/9 [==============================] - 0s 4ms/step - loss: 4.0611 - mae: 1.4942 - val_loss: 9.5984 - val_mae: 2.2645 Epoch 41/300 9/9 [==============================] - 0s 4ms/step - loss: 4.4848 - mae: 1.6271 - val_loss: 11.7578 - val_mae: 2.4464 Epoch 42/300 9/9 [==============================] - 0s 7ms/step - loss: 5.7391 - mae: 1.8263 - val_loss: 10.9567 - val_mae: 2.5576 Epoch 43/300 9/9 [==============================] - 0s 4ms/step - loss: 4.8053 - mae: 1.7116 - val_loss: 8.4805 - val_mae: 2.1905 Epoch 44/300 9/9 [==============================] - 0s 4ms/step - loss: 3.7710 - mae: 1.4910 - val_loss: 9.2685 - val_mae: 2.2773 Epoch 45/300 9/9 [==============================] - 0s 4ms/step - loss: 3.0423 - mae: 1.3324 - val_loss: 9.8588 - val_mae: 2.3870 Epoch 46/300 9/9 [==============================] - 0s 4ms/step - loss: 3.1118 - mae: 1.3160 - val_loss: 9.6013 - val_mae: 2.2718 Epoch 47/300 9/9 [==============================] - 0s 4ms/step - loss: 3.3541 - mae: 1.3715 - val_loss: 9.9317 - val_mae: 2.3633 Epoch 48/300 9/9 [==============================] - 0s 4ms/step - loss: 3.5051 - mae: 1.4657 - val_loss: 10.4556 - val_mae: 2.3612 Epoch 49/300 9/9 [==============================] - 0s 5ms/step - loss: 2.8366 - mae: 1.2479 - val_loss: 9.1685 - val_mae: 2.2768 Epoch 50/300 9/9 [==============================] - 0s 5ms/step - loss: 2.9141 - mae: 1.2856 - val_loss: 9.2170 - val_mae: 2.3147 Epoch 51/300 9/9 [==============================] - 0s 4ms/step - loss: 2.9130 - mae: 1.3059 - val_loss: 9.2830 - val_mae: 2.4074 Epoch 52/300 9/9 [==============================] - 0s 4ms/step - loss: 3.6576 - mae: 1.4440 - val_loss: 8.2930 - val_mae: 2.3096 Epoch 53/300 9/9 [==============================] - 0s 8ms/step - loss: 3.7554 - mae: 1.4417 - val_loss: 10.3064 - val_mae: 2.4746 Epoch 54/300 9/9 [==============================] - 0s 4ms/step - loss: 3.9983 - mae: 1.5461 - val_loss: 9.0305 - val_mae: 2.1781 Epoch 55/300 9/9 [==============================] - 0s 4ms/step - loss: 2.4590 - mae: 1.2253 - val_loss: 11.7878 - val_mae: 2.4756 Epoch 56/300 9/9 [==============================] - 0s 4ms/step - loss: 2.4868 - mae: 1.1852 - val_loss: 9.3828 - val_mae: 2.2327 Epoch 57/300 9/9 [==============================] - 0s 5ms/step - loss: 2.8161 - mae: 1.3143 - val_loss: 11.9237 - val_mae: 2.4437 Epoch 58/300 9/9 [==============================] - 0s 4ms/step - loss: 2.8071 - mae: 1.2740 - val_loss: 9.1914 - val_mae: 2.2249 Epoch 59/300 9/9 [==============================] - 0s 4ms/step - loss: 2.2587 - mae: 1.1530 - val_loss: 9.6559 - val_mae: 2.4365 Epoch 60/300 9/9 [==============================] - 0s 4ms/step - loss: 3.4021 - mae: 1.4175 - val_loss: 9.3767 - val_mae: 2.4723 Epoch 61/300 9/9 [==============================] - 0s 6ms/step - loss: 3.5084 - mae: 1.4200 - val_loss: 11.4666 - val_mae: 2.4462 Epoch 62/300 9/9 [==============================] - 0s 4ms/step - loss: 3.5914 - mae: 1.4945 - val_loss: 14.0612 - val_mae: 2.7399 Epoch 63/300 9/9 [==============================] - 0s 4ms/step - loss: 4.1327 - mae: 1.5373 - val_loss: 14.6667 - val_mae: 2.6739 Epoch 64/300 9/9 [==============================] - 0s 5ms/step - loss: 3.3784 - mae: 1.3880 - val_loss: 12.8577 - val_mae: 2.4854 Epoch 65/300 9/9 [==============================] - 0s 5ms/step - loss: 3.1059 - mae: 1.3413 - val_loss: 10.2083 - val_mae: 2.2411 Epoch 66/300 9/9 [==============================] - 0s 5ms/step - loss: 4.4544 - mae: 1.5783 - val_loss: 13.1504 - val_mae: 2.7282 Epoch 67/300 9/9 [==============================] - 0s 4ms/step - loss: 4.4461 - mae: 1.5080 - val_loss: 9.3300 - val_mae: 2.3887 Epoch 68/300 9/9 [==============================] - 0s 4ms/step - loss: 3.4763 - mae: 1.3835 - val_loss: 10.0616 - val_mae: 2.3925 Epoch 69/300 9/9 [==============================] - 0s 4ms/step - loss: 3.3870 - mae: 1.3969 - val_loss: 13.5585 - val_mae: 2.5634 Epoch 70/300 9/9 [==============================] - 0s 4ms/step - loss: 2.6638 - mae: 1.2294 - val_loss: 12.2245 - val_mae: 2.5543 Epoch 71/300 9/9 [==============================] - 0s 4ms/step - loss: 2.8323 - mae: 1.2967 - val_loss: 10.0222 - val_mae: 2.3171 Epoch 72/300 9/9 [==============================] - 0s 4ms/step - loss: 3.7947 - mae: 1.4285 - val_loss: 11.4458 - val_mae: 2.7129 Epoch 73/300 9/9 [==============================] - 0s 4ms/step - loss: 3.4621 - mae: 1.3901 - val_loss: 8.4725 - val_mae: 2.2448 Epoch 74/300 9/9 [==============================] - 0s 4ms/step - loss: 2.6856 - mae: 1.2645 - val_loss: 11.4067 - val_mae: 2.3572 Epoch 75/300 9/9 [==============================] - 0s 4ms/step - loss: 2.1707 - mae: 1.1376 - val_loss: 10.9015 - val_mae: 2.4353 Epoch 76/300 9/9 [==============================] - 0s 5ms/step - loss: 2.1772 - mae: 1.1470 - val_loss: 9.4474 - val_mae: 2.3484 Epoch 77/300 9/9 [==============================] - 0s 5ms/step - loss: 2.1045 - mae: 1.1069 - val_loss: 11.0634 - val_mae: 2.6222 Epoch 78/300 9/9 [==============================] - 0s 4ms/step - loss: 2.5436 - mae: 1.2070 - val_loss: 11.0566 - val_mae: 2.3459 Epoch 79/300 9/9 [==============================] - 0s 5ms/step - loss: 2.5658 - mae: 1.2122 - val_loss: 8.7894 - val_mae: 2.3246 Epoch 80/300 9/9 [==============================] - 0s 4ms/step - loss: 3.2659 - mae: 1.3651 - val_loss: 15.4604 - val_mae: 2.9006 Epoch 81/300 9/9 [==============================] - 0s 4ms/step - loss: 5.8932 - mae: 1.8734 - val_loss: 8.7928 - val_mae: 2.1848 Epoch 82/300 9/9 [==============================] - 0s 4ms/step - loss: 5.0979 - mae: 1.6791 - val_loss: 17.2314 - val_mae: 3.0984 Epoch 83/300 9/9 [==============================] - 0s 4ms/step - loss: 5.3734 - mae: 1.7512 - val_loss: 10.1699 - val_mae: 2.4246 Epoch 84/300 9/9 [==============================] - 0s 4ms/step - loss: 3.1025 - mae: 1.3791 - val_loss: 8.0583 - val_mae: 2.2012 Epoch 85/300 9/9 [==============================] - 0s 5ms/step - loss: 3.0591 - mae: 1.3608 - val_loss: 10.0700 - val_mae: 2.4356 Epoch 86/300 9/9 [==============================] - 0s 4ms/step - loss: 3.1022 - mae: 1.3196 - val_loss: 10.3131 - val_mae: 2.3257 Epoch 87/300 9/9 [==============================] - 0s 5ms/step - loss: 2.7406 - mae: 1.2745 - val_loss: 12.9390 - val_mae: 2.6948 Epoch 88/300 9/9 [==============================] - 0s 4ms/step - loss: 2.4159 - mae: 1.2248 - val_loss: 9.9760 - val_mae: 2.3511 Epoch 89/300 9/9 [==============================] - 0s 4ms/step - loss: 2.2531 - mae: 1.1365 - val_loss: 11.8934 - val_mae: 2.4585 Epoch 90/300 9/9 [==============================] - 0s 4ms/step - loss: 3.0078 - mae: 1.2853 - val_loss: 11.1644 - val_mae: 2.5048 Epoch 91/300 9/9 [==============================] - 0s 4ms/step - loss: 3.5025 - mae: 1.3570 - val_loss: 9.2513 - val_mae: 2.3425 Epoch 92/300 9/9 [==============================] - 0s 4ms/step - loss: 2.7118 - mae: 1.2411 - val_loss: 10.6357 - val_mae: 2.4711 Epoch 93/300 9/9 [==============================] - 0s 6ms/step - loss: 2.1579 - mae: 1.0975 - val_loss: 11.0048 - val_mae: 2.3693 Epoch 94/300 9/9 [==============================] - 0s 4ms/step - loss: 1.8383 - mae: 1.0101 - val_loss: 8.7624 - val_mae: 2.2079 Epoch 95/300 9/9 [==============================] - 0s 4ms/step - loss: 1.9034 - mae: 1.0183 - val_loss: 9.0126 - val_mae: 2.2160 Epoch 96/300 9/9 [==============================] - 0s 4ms/step - loss: 1.8063 - mae: 1.0272 - val_loss: 10.7558 - val_mae: 2.3465 Epoch 97/300 9/9 [==============================] - 0s 4ms/step - loss: 2.0504 - mae: 1.0847 - val_loss: 8.7077 - val_mae: 2.3058 Epoch 98/300 9/9 [==============================] - 0s 4ms/step - loss: 2.1829 - mae: 1.1103 - val_loss: 9.9883 - val_mae: 2.3958 Epoch 99/300 9/9 [==============================] - 0s 5ms/step - loss: 2.7802 - mae: 1.2599 - val_loss: 8.7747 - val_mae: 2.2187 Epoch 100/300 9/9 [==============================] - 0s 5ms/step - loss: 1.9790 - mae: 1.0758 - val_loss: 12.0451 - val_mae: 2.6189 Epoch 101/300 9/9 [==============================] - 0s 4ms/step - loss: 2.4906 - mae: 1.1831 - val_loss: 10.1801 - val_mae: 2.3198 Epoch 102/300 9/9 [==============================] - 0s 5ms/step - loss: 2.3685 - mae: 1.1637 - val_loss: 8.9193 - val_mae: 2.3021 Epoch 103/300 9/9 [==============================] - 0s 7ms/step - loss: 2.6865 - mae: 1.2885 - val_loss: 10.8707 - val_mae: 2.3570 Epoch 104/300 9/9 [==============================] - 0s 4ms/step - loss: 2.3778 - mae: 1.1594 - val_loss: 10.3086 - val_mae: 2.3925 Epoch 105/300 9/9 [==============================] - 0s 5ms/step - loss: 1.9299 - mae: 1.0588 - val_loss: 10.1214 - val_mae: 2.2951 Epoch 106/300 9/9 [==============================] - 0s 5ms/step - loss: 1.9407 - mae: 1.0413 - val_loss: 10.2044 - val_mae: 2.3418 Epoch 107/300 9/9 [==============================] - 0s 5ms/step - loss: 2.2013 - mae: 1.1615 - val_loss: 9.5291 - val_mae: 2.2889 Epoch 108/300 9/9 [==============================] - 0s 5ms/step - loss: 1.5356 - mae: 0.9307 - val_loss: 9.9544 - val_mae: 2.3796 Epoch 109/300 9/9 [==============================] - 0s 5ms/step - loss: 1.5832 - mae: 0.9541 - val_loss: 8.9253 - val_mae: 2.2070 Epoch 110/300 9/9 [==============================] - 0s 5ms/step - loss: 1.4403 - mae: 0.9142 - val_loss: 9.4118 - val_mae: 2.2036 Epoch 111/300 9/9 [==============================] - 0s 4ms/step - loss: 1.2912 - mae: 0.8380 - val_loss: 10.5468 - val_mae: 2.3724 Epoch 112/300 9/9 [==============================] - 0s 4ms/step - loss: 1.5027 - mae: 0.9226 - val_loss: 9.0908 - val_mae: 2.2205 Epoch 113/300 9/9 [==============================] - 0s 5ms/step - loss: 1.2615 - mae: 0.8458 - val_loss: 9.8323 - val_mae: 2.2628 Epoch 114/300 9/9 [==============================] - 0s 4ms/step - loss: 1.3027 - mae: 0.8540 - val_loss: 10.3418 - val_mae: 2.2923 Epoch 115/300 9/9 [==============================] - 0s 4ms/step - loss: 1.3919 - mae: 0.8868 - val_loss: 8.4377 - val_mae: 2.1720 Epoch 116/300 9/9 [==============================] - 0s 5ms/step - loss: 1.4686 - mae: 0.9039 - val_loss: 10.3558 - val_mae: 2.3306 Epoch 117/300 9/9 [==============================] - 0s 4ms/step - loss: 1.3778 - mae: 0.8652 - val_loss: 10.9006 - val_mae: 2.3601 Epoch 118/300 9/9 [==============================] - 0s 5ms/step - loss: 1.2900 - mae: 0.8477 - val_loss: 9.7185 - val_mae: 2.3396 Epoch 119/300 9/9 [==============================] - 0s 4ms/step - loss: 1.5093 - mae: 0.9236 - val_loss: 9.7441 - val_mae: 2.3777 Epoch 120/300 9/9 [==============================] - 0s 5ms/step - loss: 2.1726 - mae: 1.1108 - val_loss: 10.0502 - val_mae: 2.4928 Epoch 121/300 9/9 [==============================] - 0s 5ms/step - loss: 2.2530 - mae: 1.1410 - val_loss: 8.5525 - val_mae: 2.3316 Epoch 122/300 9/9 [==============================] - 0s 4ms/step - loss: 2.3638 - mae: 1.1793 - val_loss: 9.6537 - val_mae: 2.4083 Epoch 123/300 9/9 [==============================] - 0s 5ms/step - loss: 3.1176 - mae: 1.3450 - val_loss: 10.4422 - val_mae: 2.5739 Epoch 124/300 9/9 [==============================] - 0s 5ms/step - loss: 2.4086 - mae: 1.2037 - val_loss: 10.6141 - val_mae: 2.3526 Epoch 125/300 9/9 [==============================] - 0s 4ms/step - loss: 2.1229 - mae: 1.1169 - val_loss: 11.8525 - val_mae: 2.3527 Epoch 126/300 9/9 [==============================] - 0s 4ms/step - loss: 2.2442 - mae: 1.1197 - val_loss: 8.9360 - val_mae: 2.4037 Epoch 127/300 9/9 [==============================] - 0s 4ms/step - loss: 2.5998 - mae: 1.2697 - val_loss: 9.5898 - val_mae: 2.2810 Epoch 128/300 9/9 [==============================] - 0s 4ms/step - loss: 2.2440 - mae: 1.1592 - val_loss: 10.1961 - val_mae: 2.3951 Epoch 129/300 9/9 [==============================] - 0s 4ms/step - loss: 1.9587 - mae: 1.0319 - val_loss: 8.6976 - val_mae: 2.3077 Epoch 130/300 9/9 [==============================] - 0s 5ms/step - loss: 2.2268 - mae: 1.1480 - val_loss: 9.9518 - val_mae: 2.4276 Epoch 131/300 9/9 [==============================] - 0s 5ms/step - loss: 3.0697 - mae: 1.3161 - val_loss: 9.0599 - val_mae: 2.1674 Epoch 132/300 9/9 [==============================] - 0s 4ms/step - loss: 2.1114 - mae: 1.0910 - val_loss: 12.9671 - val_mae: 2.6370 Epoch 133/300 9/9 [==============================] - 0s 4ms/step - loss: 2.5425 - mae: 1.2050 - val_loss: 11.9471 - val_mae: 2.5541 Epoch 134/300 9/9 [==============================] - 0s 4ms/step - loss: 2.7657 - mae: 1.2797 - val_loss: 9.1584 - val_mae: 2.3534 Epoch 135/300 9/9 [==============================] - 0s 4ms/step - loss: 1.7294 - mae: 0.9989 - val_loss: 9.0478 - val_mae: 2.2782 Epoch 136/300 9/9 [==============================] - 0s 4ms/step - loss: 1.3861 - mae: 0.8861 - val_loss: 10.3818 - val_mae: 2.3478 Epoch 137/300 9/9 [==============================] - 0s 4ms/step - loss: 1.2833 - mae: 0.8509 - val_loss: 10.2006 - val_mae: 2.3078 Epoch 138/300 9/9 [==============================] - 0s 5ms/step - loss: 1.4685 - mae: 0.8910 - val_loss: 10.6764 - val_mae: 2.4353 Epoch 139/300 9/9 [==============================] - 0s 5ms/step - loss: 1.7648 - mae: 1.0516 - val_loss: 9.9569 - val_mae: 2.2854 Epoch 140/300 9/9 [==============================] - 0s 5ms/step - loss: 1.5818 - mae: 0.9495 - val_loss: 10.6176 - val_mae: 2.2908 Epoch 141/300 9/9 [==============================] - 0s 4ms/step - loss: 1.3158 - mae: 0.8663 - val_loss: 9.2190 - val_mae: 2.4115 Epoch 142/300 9/9 [==============================] - 0s 4ms/step - loss: 1.8697 - mae: 1.0759 - val_loss: 8.4910 - val_mae: 2.2363 Epoch 143/300 9/9 [==============================] - 0s 4ms/step - loss: 1.3123 - mae: 0.8546 - val_loss: 9.5580 - val_mae: 2.2758 Epoch 144/300 9/9 [==============================] - 0s 5ms/step - loss: 1.4274 - mae: 0.9029 - val_loss: 9.6794 - val_mae: 2.2475 Epoch 145/300 9/9 [==============================] - 0s 5ms/step - loss: 1.4860 - mae: 0.9200 - val_loss: 9.7681 - val_mae: 2.2583 Epoch 146/300 9/9 [==============================] - 0s 5ms/step - loss: 1.4636 - mae: 0.8893 - val_loss: 10.3608 - val_mae: 2.3677 Epoch 147/300 9/9 [==============================] - 0s 4ms/step - loss: 1.2619 - mae: 0.8384 - val_loss: 10.1053 - val_mae: 2.3468 Epoch 148/300 9/9 [==============================] - 0s 4ms/step - loss: 1.3166 - mae: 0.8477 - val_loss: 9.5112 - val_mae: 2.3209 Epoch 149/300 9/9 [==============================] - 0s 4ms/step - loss: 1.3242 - mae: 0.8631 - val_loss: 10.7832 - val_mae: 2.3820 Epoch 150/300 9/9 [==============================] - 0s 4ms/step - loss: 1.5037 - mae: 0.9514 - val_loss: 8.7991 - val_mae: 2.3230 Epoch 151/300 9/9 [==============================] - 0s 6ms/step - loss: 1.4840 - mae: 0.9361 - val_loss: 8.3615 - val_mae: 2.2355 Epoch 152/300 9/9 [==============================] - 0s 5ms/step - loss: 1.4309 - mae: 0.9314 - val_loss: 8.5271 - val_mae: 2.1781 Epoch 153/300 9/9 [==============================] - 0s 5ms/step - loss: 1.2496 - mae: 0.8383 - val_loss: 9.4026 - val_mae: 2.3393 Epoch 154/300 9/9 [==============================] - 0s 4ms/step - loss: 1.5697 - mae: 0.8515 - val_loss: 9.9953 - val_mae: 2.3969 Epoch 155/300 9/9 [==============================] - 0s 7ms/step - loss: 1.5768 - mae: 0.9144 - val_loss: 8.7126 - val_mae: 2.2218 Epoch 156/300 9/9 [==============================] - 0s 6ms/step - loss: 1.4210 - mae: 0.8514 - val_loss: 9.0210 - val_mae: 2.2747 Epoch 157/300 9/9 [==============================] - 0s 5ms/step - loss: 1.4513 - mae: 0.9029 - val_loss: 10.2513 - val_mae: 2.4694 Epoch 158/300 9/9 [==============================] - 0s 4ms/step - loss: 2.1007 - mae: 1.0810 - val_loss: 9.1315 - val_mae: 2.3760 Epoch 159/300 9/9 [==============================] - 0s 5ms/step - loss: 1.7019 - mae: 0.9969 - val_loss: 10.4056 - val_mae: 2.4281 Epoch 160/300 9/9 [==============================] - 0s 5ms/step - loss: 2.0384 - mae: 1.0796 - val_loss: 9.1242 - val_mae: 2.3538 Epoch 161/300 9/9 [==============================] - 0s 4ms/step - loss: 2.5954 - mae: 1.1834 - val_loss: 10.7179 - val_mae: 2.4016 Epoch 162/300 9/9 [==============================] - 0s 4ms/step - loss: 2.3765 - mae: 1.0934 - val_loss: 10.7456 - val_mae: 2.2903 Epoch 163/300 9/9 [==============================] - 0s 4ms/step - loss: 2.2380 - mae: 1.1480 - val_loss: 10.0621 - val_mae: 2.3263 Epoch 164/300 9/9 [==============================] - 0s 6ms/step - loss: 1.7771 - mae: 1.0122 - val_loss: 11.2053 - val_mae: 2.5333 Epoch 165/300 9/9 [==============================] - 0s 5ms/step - loss: 2.2161 - mae: 1.1461 - val_loss: 9.6989 - val_mae: 2.2865 Epoch 166/300 9/9 [==============================] - 0s 5ms/step - loss: 1.8663 - mae: 1.1001 - val_loss: 8.3490 - val_mae: 2.2128 Epoch 167/300 9/9 [==============================] - 0s 5ms/step - loss: 1.5458 - mae: 0.9676 - val_loss: 8.9728 - val_mae: 2.2055 Epoch 168/300 9/9 [==============================] - 0s 5ms/step - loss: 1.0666 - mae: 0.7762 - val_loss: 8.0403 - val_mae: 2.2507 Epoch 169/300 9/9 [==============================] - 0s 5ms/step - loss: 0.9485 - mae: 0.7186 - val_loss: 8.3311 - val_mae: 2.1313 Epoch 170/300 9/9 [==============================] - 0s 5ms/step - loss: 0.8993 - mae: 0.7085 - val_loss: 9.1098 - val_mae: 2.2427 Epoch 171/300 9/9 [==============================] - 0s 5ms/step - loss: 1.0048 - mae: 0.7440 - val_loss: 8.6925 - val_mae: 2.2814 Epoch 172/300 9/9 [==============================] - 0s 5ms/step - loss: 1.1166 - mae: 0.8039 - val_loss: 8.2941 - val_mae: 2.2678 Epoch 173/300 9/9 [==============================] - 0s 5ms/step - loss: 1.0726 - mae: 0.7838 - val_loss: 9.5063 - val_mae: 2.2588 Epoch 174/300 9/9 [==============================] - 0s 4ms/step - loss: 0.8270 - mae: 0.6810 - val_loss: 9.8260 - val_mae: 2.2487 Epoch 175/300 9/9 [==============================] - 0s 5ms/step - loss: 0.8832 - mae: 0.7179 - val_loss: 9.1483 - val_mae: 2.3474 Epoch 176/300 9/9 [==============================] - 0s 5ms/step - loss: 0.8099 - mae: 0.6743 - val_loss: 8.7547 - val_mae: 2.1984 Epoch 177/300 9/9 [==============================] - 0s 4ms/step - loss: 0.8207 - mae: 0.6515 - val_loss: 8.4726 - val_mae: 2.2075 Epoch 178/300 9/9 [==============================] - 0s 4ms/step - loss: 1.3277 - mae: 0.9031 - val_loss: 9.1474 - val_mae: 2.2600 Epoch 179/300 9/9 [==============================] - 0s 5ms/step - loss: 1.7676 - mae: 1.0496 - val_loss: 10.1643 - val_mae: 2.3928 Epoch 180/300 9/9 [==============================] - 0s 4ms/step - loss: 2.3427 - mae: 1.1998 - val_loss: 9.9066 - val_mae: 2.3269 Epoch 181/300 9/9 [==============================] - 0s 4ms/step - loss: 2.4786 - mae: 1.1890 - val_loss: 13.8454 - val_mae: 2.6728 Epoch 182/300 9/9 [==============================] - 0s 5ms/step - loss: 2.4081 - mae: 1.1965 - val_loss: 11.7348 - val_mae: 2.4666 Epoch 183/300 9/9 [==============================] - 0s 4ms/step - loss: 2.5278 - mae: 1.2875 - val_loss: 10.6881 - val_mae: 2.3248 Epoch 184/300 9/9 [==============================] - 0s 5ms/step - loss: 2.4543 - mae: 1.2171 - val_loss: 8.1384 - val_mae: 2.0511 Epoch 185/300 9/9 [==============================] - 0s 5ms/step - loss: 1.7103 - mae: 0.9993 - val_loss: 9.9495 - val_mae: 2.2941 Epoch 186/300 9/9 [==============================] - 0s 5ms/step - loss: 1.4442 - mae: 0.8468 - val_loss: 9.5321 - val_mae: 2.2843 Epoch 187/300 9/9 [==============================] - 0s 4ms/step - loss: 1.3422 - mae: 0.8833 - val_loss: 10.4890 - val_mae: 2.4036 Epoch 188/300 9/9 [==============================] - 0s 4ms/step - loss: 1.3150 - mae: 0.8656 - val_loss: 10.6262 - val_mae: 2.3134 Epoch 189/300 9/9 [==============================] - 0s 5ms/step - loss: 1.4160 - mae: 0.9032 - val_loss: 8.5405 - val_mae: 2.2157 Epoch 190/300 9/9 [==============================] - 0s 5ms/step - loss: 1.9008 - mae: 1.0881 - val_loss: 9.7380 - val_mae: 2.3269 Epoch 191/300 9/9 [==============================] - 0s 4ms/step - loss: 1.9524 - mae: 1.1132 - val_loss: 10.2444 - val_mae: 2.3343 Epoch 192/300 9/9 [==============================] - 0s 4ms/step - loss: 1.6260 - mae: 0.9849 - val_loss: 9.3994 - val_mae: 2.3264 Epoch 193/300 9/9 [==============================] - 0s 5ms/step - loss: 1.0688 - mae: 0.7795 - val_loss: 9.2354 - val_mae: 2.3150 Epoch 194/300 9/9 [==============================] - 0s 5ms/step - loss: 1.0556 - mae: 0.7776 - val_loss: 8.3169 - val_mae: 2.1814 Epoch 195/300 9/9 [==============================] - 0s 5ms/step - loss: 1.1207 - mae: 0.7991 - val_loss: 9.7100 - val_mae: 2.2739 Epoch 196/300 9/9 [==============================] - 0s 5ms/step - loss: 1.1259 - mae: 0.7845 - val_loss: 12.6399 - val_mae: 2.4150 Epoch 197/300 9/9 [==============================] - 0s 5ms/step - loss: 1.1511 - mae: 0.8128 - val_loss: 11.4426 - val_mae: 2.3466 Epoch 198/300 9/9 [==============================] - 0s 5ms/step - loss: 1.2447 - mae: 0.7989 - val_loss: 9.4152 - val_mae: 2.2920 Epoch 199/300 9/9 [==============================] - 0s 4ms/step - loss: 0.8338 - mae: 0.6755 - val_loss: 9.3051 - val_mae: 2.2597 Epoch 200/300 9/9 [==============================] - 0s 5ms/step - loss: 0.9948 - mae: 0.7324 - val_loss: 8.8952 - val_mae: 2.2650 Epoch 201/300 9/9 [==============================] - 0s 4ms/step - loss: 0.7528 - mae: 0.6482 - val_loss: 8.8380 - val_mae: 2.2227 Epoch 202/300 9/9 [==============================] - 0s 5ms/step - loss: 0.7648 - mae: 0.6370 - val_loss: 10.2099 - val_mae: 2.3074 Epoch 203/300 9/9 [==============================] - 0s 7ms/step - loss: 0.8848 - mae: 0.6935 - val_loss: 12.2827 - val_mae: 2.4238 Epoch 204/300 9/9 [==============================] - 0s 5ms/step - loss: 1.0436 - mae: 0.7377 - val_loss: 10.2438 - val_mae: 2.3005 Epoch 205/300 9/9 [==============================] - 0s 5ms/step - loss: 1.1904 - mae: 0.8019 - val_loss: 9.2372 - val_mae: 2.2499 Epoch 206/300 9/9 [==============================] - 0s 5ms/step - loss: 1.1743 - mae: 0.8330 - val_loss: 8.1517 - val_mae: 2.3329 Epoch 207/300 9/9 [==============================] - 0s 5ms/step - loss: 1.0371 - mae: 0.7742 - val_loss: 9.2403 - val_mae: 2.2577 Epoch 208/300 9/9 [==============================] - 0s 5ms/step - loss: 0.9461 - mae: 0.7179 - val_loss: 9.0389 - val_mae: 2.2408 Epoch 209/300 9/9 [==============================] - 0s 6ms/step - loss: 0.9368 - mae: 0.6680 - val_loss: 10.7048 - val_mae: 2.3385 Epoch 210/300 9/9 [==============================] - 0s 5ms/step - loss: 1.2368 - mae: 0.8708 - val_loss: 12.0716 - val_mae: 2.4437 Epoch 211/300 9/9 [==============================] - 0s 5ms/step - loss: 1.3079 - mae: 0.8882 - val_loss: 9.2968 - val_mae: 2.3130 Epoch 212/300 9/9 [==============================] - 0s 4ms/step - loss: 1.1586 - mae: 0.8214 - val_loss: 9.3256 - val_mae: 2.2696 Epoch 213/300 9/9 [==============================] - 0s 6ms/step - loss: 1.0216 - mae: 0.7334 - val_loss: 9.2118 - val_mae: 2.3230 Epoch 214/300 9/9 [==============================] - 0s 4ms/step - loss: 0.7468 - mae: 0.6578 - val_loss: 9.5151 - val_mae: 2.3314 Epoch 215/300 9/9 [==============================] - 0s 5ms/step - loss: 0.8789 - mae: 0.7021 - val_loss: 8.7394 - val_mae: 2.1720 Epoch 216/300 9/9 [==============================] - 0s 5ms/step - loss: 0.7111 - mae: 0.6178 - val_loss: 11.1819 - val_mae: 2.3482 Epoch 217/300 9/9 [==============================] - 0s 5ms/step - loss: 0.6275 - mae: 0.5830 - val_loss: 10.1497 - val_mae: 2.3064 Epoch 218/300 9/9 [==============================] - 0s 5ms/step - loss: 0.5705 - mae: 0.5437 - val_loss: 8.4889 - val_mae: 2.2265 Epoch 219/300 9/9 [==============================] - 0s 5ms/step - loss: 0.5365 - mae: 0.5205 - val_loss: 9.8475 - val_mae: 2.2844 Epoch 220/300 9/9 [==============================] - 0s 5ms/step - loss: 0.7341 - mae: 0.6250 - val_loss: 8.4437 - val_mae: 2.2381 Epoch 221/300 9/9 [==============================] - 0s 4ms/step - loss: 0.9226 - mae: 0.6906 - val_loss: 10.5048 - val_mae: 2.4157 Epoch 222/300 9/9 [==============================] - 0s 4ms/step - loss: 1.3694 - mae: 0.8195 - val_loss: 9.6705 - val_mae: 2.3631 Epoch 223/300 9/9 [==============================] - 0s 7ms/step - loss: 1.0285 - mae: 0.7815 - val_loss: 7.8171 - val_mae: 2.1289 Epoch 224/300 9/9 [==============================] - 0s 5ms/step - loss: 1.1003 - mae: 0.7315 - val_loss: 10.0517 - val_mae: 2.4437 Epoch 225/300 9/9 [==============================] - 0s 5ms/step - loss: 0.7908 - mae: 0.6714 - val_loss: 10.8995 - val_mae: 2.3941 Epoch 226/300 9/9 [==============================] - 0s 5ms/step - loss: 0.8159 - mae: 0.6343 - val_loss: 9.7545 - val_mae: 2.3603 Epoch 227/300 9/9 [==============================] - 0s 7ms/step - loss: 0.8158 - mae: 0.6759 - val_loss: 8.7914 - val_mae: 2.2676 Epoch 228/300 9/9 [==============================] - 0s 5ms/step - loss: 0.7480 - mae: 0.6625 - val_loss: 9.2566 - val_mae: 2.3250 Epoch 229/300 9/9 [==============================] - 0s 5ms/step - loss: 0.7026 - mae: 0.6191 - val_loss: 8.9425 - val_mae: 2.2408 Epoch 230/300 9/9 [==============================] - 0s 4ms/step - loss: 0.6249 - mae: 0.5773 - val_loss: 10.0514 - val_mae: 2.3363 Epoch 231/300 9/9 [==============================] - 0s 5ms/step - loss: 0.6351 - mae: 0.5736 - val_loss: 11.9069 - val_mae: 2.4519 Epoch 232/300 9/9 [==============================] - 0s 5ms/step - loss: 0.9321 - mae: 0.7543 - val_loss: 10.4653 - val_mae: 2.3294 Epoch 233/300 9/9 [==============================] - 0s 5ms/step - loss: 1.0245 - mae: 0.7797 - val_loss: 10.1195 - val_mae: 2.3041 Epoch 234/300 9/9 [==============================] - 0s 5ms/step - loss: 0.6885 - mae: 0.6225 - val_loss: 10.9759 - val_mae: 2.4265 Epoch 235/300 9/9 [==============================] - 0s 5ms/step - loss: 0.7106 - mae: 0.6502 - val_loss: 11.7651 - val_mae: 2.4692 Epoch 236/300 9/9 [==============================] - 0s 5ms/step - loss: 0.9171 - mae: 0.7488 - val_loss: 11.5120 - val_mae: 2.3870 Epoch 237/300 9/9 [==============================] - 0s 5ms/step - loss: 0.9904 - mae: 0.7531 - val_loss: 10.7283 - val_mae: 2.3640 Epoch 238/300 9/9 [==============================] - 0s 4ms/step - loss: 0.8144 - mae: 0.6991 - val_loss: 9.9591 - val_mae: 2.3440 Epoch 239/300 9/9 [==============================] - 0s 5ms/step - loss: 0.6549 - mae: 0.6044 - val_loss: 9.0811 - val_mae: 2.2441 Epoch 240/300 9/9 [==============================] - 0s 5ms/step - loss: 0.7284 - mae: 0.6381 - val_loss: 11.3871 - val_mae: 2.4817 Epoch 241/300 9/9 [==============================] - 0s 5ms/step - loss: 1.0762 - mae: 0.7693 - val_loss: 11.1542 - val_mae: 2.4379 Epoch 242/300 9/9 [==============================] - 0s 5ms/step - loss: 1.0528 - mae: 0.7532 - val_loss: 9.5840 - val_mae: 2.2619 Epoch 243/300 9/9 [==============================] - 0s 6ms/step - loss: 1.0288 - mae: 0.7926 - val_loss: 12.7300 - val_mae: 2.5774 Epoch 244/300 9/9 [==============================] - 0s 5ms/step - loss: 1.3034 - mae: 0.8801 - val_loss: 13.4818 - val_mae: 2.5218 Epoch 245/300 9/9 [==============================] - 0s 5ms/step - loss: 1.4451 - mae: 0.9204 - val_loss: 10.6946 - val_mae: 2.3779 Epoch 246/300 9/9 [==============================] - 0s 5ms/step - loss: 0.9316 - mae: 0.7591 - val_loss: 11.1190 - val_mae: 2.3469 Epoch 247/300 9/9 [==============================] - 0s 6ms/step - loss: 0.8024 - mae: 0.6910 - val_loss: 9.8753 - val_mae: 2.3424 Epoch 248/300 9/9 [==============================] - 0s 5ms/step - loss: 0.6277 - mae: 0.6147 - val_loss: 10.4548 - val_mae: 2.4303 Epoch 249/300 9/9 [==============================] - 0s 5ms/step - loss: 0.6574 - mae: 0.5853 - val_loss: 10.2268 - val_mae: 2.3086 Epoch 250/300 9/9 [==============================] - 0s 4ms/step - loss: 0.7134 - mae: 0.6378 - val_loss: 11.5265 - val_mae: 2.3930 Epoch 251/300 9/9 [==============================] - 0s 5ms/step - loss: 0.6883 - mae: 0.6153 - val_loss: 10.1113 - val_mae: 2.3587 Epoch 252/300 9/9 [==============================] - 0s 5ms/step - loss: 0.6121 - mae: 0.5958 - val_loss: 9.2886 - val_mae: 2.2743 Epoch 253/300 9/9 [==============================] - 0s 5ms/step - loss: 0.6460 - mae: 0.5794 - val_loss: 10.9439 - val_mae: 2.4021 Epoch 254/300 9/9 [==============================] - 0s 4ms/step - loss: 1.2858 - mae: 0.9116 - val_loss: 15.3294 - val_mae: 2.7171 Epoch 255/300 9/9 [==============================] - 0s 5ms/step - loss: 5.0198 - mae: 1.6387 - val_loss: 15.7793 - val_mae: 2.7841 Epoch 256/300 9/9 [==============================] - 0s 5ms/step - loss: 4.0174 - mae: 1.6131 - val_loss: 12.8497 - val_mae: 2.4906 Epoch 257/300 9/9 [==============================] - 0s 5ms/step - loss: 3.5874 - mae: 1.4847 - val_loss: 10.9274 - val_mae: 2.4845 Epoch 258/300 9/9 [==============================] - 0s 5ms/step - loss: 2.3178 - mae: 1.1446 - val_loss: 12.7039 - val_mae: 2.6382 Epoch 259/300 9/9 [==============================] - 0s 5ms/step - loss: 2.7830 - mae: 1.2762 - val_loss: 10.2091 - val_mae: 2.5211 Epoch 260/300 9/9 [==============================] - 0s 4ms/step - loss: 2.9140 - mae: 1.3299 - val_loss: 12.8336 - val_mae: 2.4322 Epoch 261/300 9/9 [==============================] - 0s 4ms/step - loss: 2.1975 - mae: 1.1135 - val_loss: 12.9531 - val_mae: 2.4280 Epoch 262/300 9/9 [==============================] - 0s 5ms/step - loss: 2.2864 - mae: 1.1076 - val_loss: 12.6443 - val_mae: 2.4199 Epoch 263/300 9/9 [==============================] - 0s 5ms/step - loss: 1.6013 - mae: 0.9466 - val_loss: 11.7617 - val_mae: 2.4558 Epoch 264/300 9/9 [==============================] - 0s 6ms/step - loss: 1.5413 - mae: 0.9820 - val_loss: 9.0542 - val_mae: 2.2073 Epoch 265/300 9/9 [==============================] - 0s 5ms/step - loss: 1.7211 - mae: 0.9825 - val_loss: 7.8031 - val_mae: 2.2912 Epoch 266/300 9/9 [==============================] - 0s 5ms/step - loss: 1.7452 - mae: 0.9013 - val_loss: 14.6236 - val_mae: 2.6603 Epoch 267/300 9/9 [==============================] - 0s 4ms/step - loss: 1.2725 - mae: 0.8188 - val_loss: 8.4640 - val_mae: 2.1808 Epoch 268/300 9/9 [==============================] - 0s 6ms/step - loss: 1.5279 - mae: 0.8467 - val_loss: 16.4770 - val_mae: 2.6503 Epoch 269/300 9/9 [==============================] - 0s 5ms/step - loss: 1.8114 - mae: 0.9564 - val_loss: 9.9901 - val_mae: 2.3290 Epoch 270/300 9/9 [==============================] - 0s 5ms/step - loss: 1.1704 - mae: 0.7997 - val_loss: 10.1141 - val_mae: 2.3869 Epoch 271/300 9/9 [==============================] - 0s 5ms/step - loss: 0.8594 - mae: 0.7048 - val_loss: 9.0247 - val_mae: 2.2829 Epoch 272/300 9/9 [==============================] - 0s 5ms/step - loss: 0.7056 - mae: 0.6288 - val_loss: 10.5115 - val_mae: 2.3431 Epoch 273/300 9/9 [==============================] - 0s 5ms/step - loss: 0.5610 - mae: 0.5303 - val_loss: 10.2686 - val_mae: 2.3462 Epoch 274/300 9/9 [==============================] - 0s 5ms/step - loss: 0.4554 - mae: 0.4985 - val_loss: 11.5764 - val_mae: 2.4010 Epoch 275/300 9/9 [==============================] - 0s 5ms/step - loss: 0.4324 - mae: 0.4670 - val_loss: 11.1157 - val_mae: 2.3915 Epoch 276/300 9/9 [==============================] - 0s 4ms/step - loss: 0.4436 - mae: 0.4767 - val_loss: 10.5370 - val_mae: 2.3335 Epoch 277/300 9/9 [==============================] - 0s 5ms/step - loss: 0.4064 - mae: 0.4313 - val_loss: 10.1817 - val_mae: 2.3414 Epoch 278/300 9/9 [==============================] - 0s 5ms/step - loss: 0.4329 - mae: 0.4821 - val_loss: 10.7567 - val_mae: 2.3778 Epoch 279/300 9/9 [==============================] - 0s 5ms/step - loss: 0.4314 - mae: 0.4633 - val_loss: 10.7639 - val_mae: 2.4035 Epoch 280/300 9/9 [==============================] - 0s 5ms/step - loss: 0.4351 - mae: 0.4843 - val_loss: 10.7459 - val_mae: 2.4060 Epoch 281/300 9/9 [==============================] - 0s 5ms/step - loss: 0.5301 - mae: 0.5268 - val_loss: 10.6510 - val_mae: 2.4131 Epoch 282/300 9/9 [==============================] - 0s 5ms/step - loss: 0.5348 - mae: 0.5351 - val_loss: 10.4999 - val_mae: 2.3904 Epoch 283/300 9/9 [==============================] - 0s 5ms/step - loss: 0.5098 - mae: 0.5193 - val_loss: 11.7025 - val_mae: 2.4170 Epoch 284/300 9/9 [==============================] - 0s 6ms/step - loss: 0.5033 - mae: 0.5359 - val_loss: 9.6724 - val_mae: 2.3019 Epoch 285/300 9/9 [==============================] - 0s 7ms/step - loss: 0.3557 - mae: 0.4400 - val_loss: 10.7177 - val_mae: 2.4252 Epoch 286/300 9/9 [==============================] - 0s 5ms/step - loss: 0.4347 - mae: 0.4871 - val_loss: 10.0554 - val_mae: 2.3571 Epoch 287/300 9/9 [==============================] - 0s 7ms/step - loss: 0.4490 - mae: 0.4666 - val_loss: 10.4033 - val_mae: 2.3652 Epoch 288/300 9/9 [==============================] - 0s 5ms/step - loss: 0.4716 - mae: 0.4994 - val_loss: 11.1858 - val_mae: 2.4118 Epoch 289/300 9/9 [==============================] - 0s 5ms/step - loss: 0.6891 - mae: 0.6014 - val_loss: 11.1075 - val_mae: 2.3193 Epoch 290/300 9/9 [==============================] - 0s 5ms/step - loss: 0.4984 - mae: 0.5201 - val_loss: 10.4326 - val_mae: 2.3350 Epoch 291/300 9/9 [==============================] - 0s 7ms/step - loss: 0.3945 - mae: 0.4692 - val_loss: 9.9435 - val_mae: 2.3339 Epoch 292/300 9/9 [==============================] - 0s 5ms/step - loss: 0.3879 - mae: 0.4472 - val_loss: 10.2581 - val_mae: 2.3418 Epoch 293/300 9/9 [==============================] - 0s 5ms/step - loss: 0.4337 - mae: 0.4703 - val_loss: 9.9980 - val_mae: 2.3395 Epoch 294/300 9/9 [==============================] - 0s 5ms/step - loss: 0.3705 - mae: 0.4370 - val_loss: 10.7709 - val_mae: 2.3609 Epoch 295/300 9/9 [==============================] - 0s 4ms/step - loss: 0.3976 - mae: 0.4482 - val_loss: 10.6427 - val_mae: 2.3920 Epoch 296/300 9/9 [==============================] - 0s 6ms/step - loss: 0.4513 - mae: 0.4976 - val_loss: 11.4199 - val_mae: 2.4365 Epoch 297/300 9/9 [==============================] - 0s 5ms/step - loss: 0.3964 - mae: 0.4550 - val_loss: 10.5426 - val_mae: 2.3301 Epoch 298/300 9/9 [==============================] - 0s 5ms/step - loss: 0.3931 - mae: 0.4445 - val_loss: 11.3062 - val_mae: 2.4102 Epoch 299/300 9/9 [==============================] - 0s 5ms/step - loss: 0.3621 - mae: 0.4354 - val_loss: 11.0344 - val_mae: 2.3798 Epoch 300/300 9/9 [==============================] - 0s 5ms/step - loss: 0.2954 - mae: 0.3820 - val_loss: 10.5709 - val_mae: 2.3950 . &#47784;&#45944; &#54217;&#44032; . model.evaluate(x_test, y_test) . 4/4 [==============================] - 0s 3ms/step - loss: 11.6894 - mae: 2.3793 . [11.689364433288574, 2.3793373107910156] . history.history.keys() . dict_keys([&#39;loss&#39;, &#39;mae&#39;, &#39;val_loss&#39;, &#39;val_mae&#39;]) . history_dict = history.history loss = history_dict[&#39;loss&#39;] val_loss = history_dict[&#39;val_loss&#39;] epochs = range(1, len(loss) + 1) fig = plt.figure(figsize=(12, 6)) ax1 = fig.add_subplot(1, 2, 1) ax1.plot(epochs, loss, color=&#39;blue&#39;, label=&#39;train_loss&#39;) ax1.plot(epochs, val_loss, color=&#39;red&#39;, label=&#39;val_loss&#39;) ax1.set_title(&#39;Train and Validation Loss&#39;) ax1.set_xlabel(&#39;Epochs&#39;) ax1.set_ylabel(&#39;Loss&#39;) ax1.grid() ax1.legend() mae = history_dict[&#39;mae&#39;] val_mae = history_dict[&#39;val_mae&#39;] ax2 = fig.add_subplot(1, 2, 2) ax2.plot(epochs, mae, color=&#39;blue&#39;, label=&#39;train_mae&#39;) ax2.plot(epochs, val_mae, color=&#39;red&#39;, label=&#39;val_mae&#39;) ax2.set_title(&#39;Train and Validation MAE&#39;) ax2.set_xlabel(&#39;Epochs&#39;) ax2.set_ylabel(&#39;MAE&#39;) ax2.grid() ax2.legend() plt.show() .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/tensorflow/machine%20learning/2021/09/20/_07_28_%EB%B3%B4%EC%8A%A4%ED%84%B4_%EC%A7%91%EA%B0%92_%EC%98%88%EC%B8%A1(TensorFlow).html",
            "relUrl": "/tensorflow/machine%20learning/2021/09/20/_07_28_%EB%B3%B4%EC%8A%A4%ED%84%B4_%EC%A7%91%EA%B0%92_%EC%98%88%EC%B8%A1(TensorFlow).html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "셀레니움을 활용한 크롤링",
            "content": "공식문서 | 참고문헌 | . !pip install Selenium !apt-get update # to update ubuntu to correctly run apt install !apt install chromium-chromedriver . from selenium import webdriver chrome_options = webdriver.ChromeOptions() chrome_options.add_argument(&#39;--headless&#39;) #내부 창을 띄울 수 없으므로 설정 chrome_options.add_argument(&#39;--no-sandbox&#39;) chrome_options.add_argument(&#39;--disable-dev-shm-usage&#39;) driver = webdriver.Chrome(&#39;chromedriver&#39;,chrome_options=chrome_options) driver.get(&quot;페이지URL&quot;) print(driver.title) html = driver.page_source . html . from bs4 import BeautifulSoup soup = BeautifulSoup(html, &#39;html.parser&#39;) data = soup.select(&#39;수정필요&#39;) # 클래스 &#39;.&#39; , 아이디 &#39;#&#39; . &#39;&#39;&#39; # 로그인 소스코드 id = driver.find_element_by_id(&quot;html에 있는 id 창의 ID&quot;) pw = driver.find_element_by_id(&quot;html에 있는 pw 창의 ID&quot;) id.send_keys(&quot;여러분아이디&quot;) pw.send_keys(&quot;여러분패스워드&quot;) pw.send_keys(Keys.ENTER) con = driver.find_element_by_id(&quot;html에 있는 클릭할 ID&quot;) con.click() # 구글에 접속했을 경우 # 검색 입력 부분에 커서를 올리고 # 검색 입력 부분에 다양한 명령을 내리기 위해 elem 변수에 할당한다 elem = driver.find_element_by_name(&quot;q&quot;) # 입력 부분에 default로 값이 있을 수 있어 비운다 elem.clear() # 검색어를 입력한다 elem.send_keys(&quot;Selenium&quot;) # 검색을 실행한다 elem.submit() &#39;&#39;&#39; .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/crawling/selenium/2021/09/20/_07_21_%EC%85%80%EB%A0%88%EB%8B%88%EC%9B%80%EC%9D%84_%ED%99%9C%EC%9A%A9%ED%95%9C_%ED%81%AC%EB%A1%A4%EB%A7%81.html",
            "relUrl": "/crawling/selenium/2021/09/20/_07_21_%EC%85%80%EB%A0%88%EB%8B%88%EC%9B%80%EC%9D%84_%ED%99%9C%EC%9A%A9%ED%95%9C_%ED%81%AC%EB%A1%A4%EB%A7%81.html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "2021년 여름방학 특강 크롤링 데이터 저장하기",
            "content": "&#53356;&#47204;&#47553; &#44592;&#48376; &#53076;&#46300; . import requests from bs4 import BeautifulSoup url = &#39;수정필요&#39; response = requests.get(url) response.encoding = &#39;utf-8&#39; html = response.text soup = BeautifulSoup(html, &#39;html.parser&#39;) datagroup = soup.select(&#39;수정필요&#39;) # 클래스 &#39;.&#39; , 아이디 &#39;#&#39; for no, data in enumerate(datagroup, 1): print(no, data.text) . import requests from bs4 import BeautifulSoup url = &#39;https://ridibooks.com/category/bestsellers/2200&#39; response = requests.get(url) response.encoding = &#39;utf-8&#39; html = response.text soup = BeautifulSoup(html, &#39;html.parser&#39;) datagroup = soup.select(&#39;.title_text&#39;) # 클래스 &#39;.&#39; , 아이디 &#39;#&#39; for no, data in enumerate(datagroup, 1): print(no, data.text.strip()) . 1 한 권으로 읽는 컴퓨터 구조와 프로그래밍 2 개발자에서 아키텍트로 3 시드 마이어 4 컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커 5 오브젝트 6 풀스택 서버리스 7 업무에 바로 쓰는 SQL 튜닝 8 웹소설 써서 먹고삽니다 9 메타버스, 이미 시작된 미래 10 파이썬으로 살펴보는 아키텍처 패턴 11 그림으로 이해하는 AWS 구조와 기술 12 개정판 | 리팩터링 (2판) 13 데이터 스토리 14 러닝 리액트(2판) 15 일잘러의 비밀, 구글 스프레드시트 제대로 파헤치기 16 눈치껏 못 배웁니다, 일센스 17 스프링 부트와 AWS로 혼자 구현하는 웹 서비스 18 로블록스 게임 제작 무작정 따라하기 19 Do it! 점프 투 파이썬 -전면 개정판 20 UX/UI의 10가지 심리학 법칙 . &#51060;&#48120;&#51648; &#53356;&#47204;&#47553; &#45936;&#51060;&#53552; &#51200;&#51109;&#54616;&#44592; . import shutil # 고수준의 파일연산 라이브러리 import requests # request를 보낼 수 있는 라이브러리 url = &#39;https://img.ridicdn.net/cover/194000109/xxlarge#1&#39; r = requests.get(url, stream=True) with open(&#39;sample.jpg&#39;, &#39;wb&#39;) as f: r.raw.decode_content = True shutil.copyfileobj(r.raw, f) . import requests from bs4 import BeautifulSoup r = requests.get(&#39;https://img.ridicdn.net/cover/194000109/xxlarge#1&#39;, stream=True) if r.status_code == 200: with open(&#39;test.jpg&#39;, &#39;wb&#39;) as f: for data in r.iter_content(1024): f.write(data) . &#53356;&#47204;&#47553; &#45936;&#51060;&#53552; &#54856;&#54168;&#51060;&#51648;&#47196; &#51200;&#51109;&#54616;&#44592; . import requests from bs4 import BeautifulSoup url = &#39;https://ridibooks.com/category/bestsellers/2200&#39; response = requests.get(url) response.encoding = &#39;utf-8&#39; html = response.text soup = BeautifulSoup(html, &#39;html.parser&#39;) datagroup = soup.select(&#39;.thumbnail&#39;) # 클래스 &#39;.&#39; , 아이디 &#39;#&#39; for data in datagroup: print(&#39;https:&#39; + data[&#39;data-src&#39;][:-7] + &#39;xxlarge#1&#39;) . https://img.ridicdn.net/cover/194000109/xxlarge#1 https://img.ridicdn.net/cover/3649000021/xxlarge#1 https://img.ridicdn.net/cover/443000917/xxlarge#1 https://img.ridicdn.net/cover/194000106/xxlarge#1 https://img.ridicdn.net/cover/754031863/xxlarge#1 https://img.ridicdn.net/cover/4489000001/xxlarge#1 https://img.ridicdn.net/cover/443000912/xxlarge#1 https://img.ridicdn.net/cover/754031846/xxlarge#1 https://img.ridicdn.net/cover/222002588/xxlarge#1 https://img.ridicdn.net/cover/2777000044/xxlarge#1 https://img.ridicdn.net/cover/1160000024/xxlarge#1 https://img.ridicdn.net/cover/1370000008/xxlarge#1 https://img.ridicdn.net/cover/1160000029/xxlarge#1 https://img.ridicdn.net/cover/443000859/xxlarge#1 https://img.ridicdn.net/cover/3903000015/xxlarge#1 https://img.ridicdn.net/cover/754026976/xxlarge#1 https://img.ridicdn.net/cover/194000105/xxlarge#1 https://img.ridicdn.net/cover/3780000117/xxlarge#1 https://img.ridicdn.net/cover/443000914/xxlarge#1 https://img.ridicdn.net/cover/443000907/xxlarge#1 . &#39;https:&#39; + datagroup[0][&#39;data-src&#39;] . &#39;https://img.ridicdn.net/cover/194000109/large#1&#39; . import requests from bs4 import BeautifulSoup import pandas as pd url = &#39;https://ridibooks.com/category/bestsellers/2200&#39; response = requests.get(url) response.encoding = &#39;utf-8&#39; html = response.text soup = BeautifulSoup(html, &#39;html.parser&#39;) 책순위 = [] 책제목 = [] 책이미지 = [] 책제목크롤링 = soup.select(&#39;.title_text&#39;) for no, data in enumerate(책제목크롤링, 1): 책순위.append(no) 책제목.append(data.text.strip()) 책이미지크롤링 = soup.select(&#39;.thumbnail&#39;) for data in 책이미지크롤링: 책이미지.append(&#39;https:&#39; + data[&#39;data-src&#39;][:-7] + &#39;xxlarge#1&#39;) 데이터 = { &#39;책순위&#39;:책순위, &#39;책제목&#39;:책제목, &#39;책이미지&#39;:책이미지 } . 데이터 = pd.DataFrame(데이터) 데이터 . 책순위 책제목 책이미지 . 0 1 | 시드 마이어 | https://img.ridicdn.net/cover/194000109/xxlarge#1 | . 1 2 | 한 권으로 읽는 컴퓨터 구조와 프로그래밍 | https://img.ridicdn.net/cover/3649000021/xxlar... | . 2 3 | 개발자에서 아키텍트로 | https://img.ridicdn.net/cover/443000917/xxlarge#1 | . 3 4 | Node.js 디자인 패턴 바이블 | https://img.ridicdn.net/cover/194000106/xxlarge#1 | . 4 5 | 컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커 | https://img.ridicdn.net/cover/754031863/xxlarge#1 | . 5 6 | 비전공자를 위한 이해할 수 있는 IT 지식 | https://img.ridicdn.net/cover/4489000001/xxlar... | . 6 7 | 파이썬으로 살펴보는 아키텍처 패턴 | https://img.ridicdn.net/cover/443000912/xxlarge#1 | . 7 8 | Let&#39;s Get IT 자바스크립트 프로그래밍 | https://img.ridicdn.net/cover/754031846/xxlarge#1 | . 8 9 | 눈치껏 못 배웁니다, 일센스 | https://img.ridicdn.net/cover/222002588/xxlarge#1 | . 9 10 | 메타버스, 이미 시작된 미래 | https://img.ridicdn.net/cover/2777000044/xxlar... | . 10 11 | 모던 자바스크립트 Deep Dive | https://img.ridicdn.net/cover/1160000024/xxlar... | . 11 12 | 비전공자도 배워서 바로 쓰는 비즈니스 데이터 분석 입문 | https://img.ridicdn.net/cover/1370000008/xxlar... | . 12 13 | 개정판 | 시작하세요! 도커/쿠버네티스 | https://img.ridicdn.net/cover/1160000029/xxlar... | . 13 14 | 혼자 공부하는 머신러닝+딥러닝 | https://img.ridicdn.net/cover/443000859/xxlarge#1 | . 14 15 | 스프링 부트와 AWS로 혼자 구현하는 웹 서비스 | https://img.ridicdn.net/cover/3903000015/xxlar... | . 15 16 | 개정판 | 리액트를 다루는 기술 | https://img.ridicdn.net/cover/754026976/xxlarge#1 | . 16 17 | 다재다능 코틀린 프로그래밍 | https://img.ridicdn.net/cover/194000105/xxlarge#1 | . 17 18 | Vue.js 프로젝트 투입 일주일 전 | https://img.ridicdn.net/cover/3780000117/xxlar... | . 18 19 | NGINX 쿡북 | https://img.ridicdn.net/cover/443000914/xxlarge#1 | . 19 20 | 일잘러의 비밀, 구글 스프레드시트 제대로 파헤치기 | https://img.ridicdn.net/cover/443000907/xxlarge#1 | . def 이미지양식변환(path): return &#39;&lt;img src=&quot;&#39;+ path + &#39;&quot; width=&quot;100px&quot; &gt;&#39; 데이터.to_html(&#39;index.html&#39;, escape=False, formatters=dict(책이미지=이미지양식변환)) . s = &#39;&#39; for i, j, k in zip(책순위, 책제목, 책이미지): s += f&#39;&lt;tr&gt; &lt;td&gt;{i}&lt;/td&gt; &lt;td&gt;{j}&lt;/td&gt; &lt;td&gt;&lt;img src={k}&gt;&lt;/td&gt; &lt;/tr&gt;&#39; s = &#39;&lt;table&gt;&#39; + s + &#39;&lt;/table&gt;&#39; with open(&quot;노동.html&quot;, &quot;w&quot;) as f: f.write(s) . &#53356;&#47204;&#47553; &#51060;&#48120;&#51648; &#45936;&#51060;&#53552; &#54028;&#51068;&#47196; &#51200;&#51109;&#54616;&#44592; . import requests from bs4 import BeautifulSoup import shutil # 고수준의 파일연산 라이브러리 url = &#39;https://ridibooks.com/category/bestsellers/2200&#39; response = requests.get(url) response.encoding = &#39;utf-8&#39; html = response.text soup = BeautifulSoup(html, &#39;html.parser&#39;) datagroup = soup.select(&#39;.thumbnail&#39;) # 클래스 &#39;.&#39; , 아이디 &#39;#&#39; for data in datagroup: print(&#39;https:&#39; + data[&#39;data-src&#39;][:-7] + &#39;xxlarge#1&#39;) &#39;&#39;&#39; url = &#39;https://img.ridicdn.net/cover/194000109/xxlarge#1&#39; r = requests.get(url, stream=True) with open(&#39;sample.jpg&#39;, &#39;wb&#39;) as f: r.raw.decode_content = True shutil.copyfileobj(r.raw, f) &#39;&#39;&#39; . https://img.ridicdn.net/cover/3649000021/xxlarge#1 https://img.ridicdn.net/cover/443000917/xxlarge#1 https://img.ridicdn.net/cover/194000109/xxlarge#1 https://img.ridicdn.net/cover/754031863/xxlarge#1 https://img.ridicdn.net/cover/1160000027/xxlarge#1 https://img.ridicdn.net/cover/443000925/xxlarge#1 https://img.ridicdn.net/cover/443000922/xxlarge#1 https://img.ridicdn.net/cover/754031183/xxlarge#1 https://img.ridicdn.net/cover/2777000044/xxlarge#1 https://img.ridicdn.net/cover/443000912/xxlarge#1 https://img.ridicdn.net/cover/754031919/xxlarge#1 https://img.ridicdn.net/cover/443000786/xxlarge#1 https://img.ridicdn.net/cover/443000924/xxlarge#1 https://img.ridicdn.net/cover/443000923/xxlarge#1 https://img.ridicdn.net/cover/443000907/xxlarge#1 https://img.ridicdn.net/cover/222002588/xxlarge#1 https://img.ridicdn.net/cover/3903000015/xxlarge#1 https://img.ridicdn.net/cover/754031983/xxlarge#1 https://img.ridicdn.net/cover/754026225/xxlarge#1 https://img.ridicdn.net/cover/3649000017/xxlarge#1 . import requests from bs4 import BeautifulSoup import shutil # 고수준의 파일연산 라이브러리 url = &#39;https://ridibooks.com/category/bestsellers/2200&#39; response = requests.get(url) response.encoding = &#39;utf-8&#39; html = response.text soup = BeautifulSoup(html, &#39;html.parser&#39;) datagroup = soup.select(&#39;.thumbnail&#39;) # 클래스 &#39;.&#39; , 아이디 &#39;#&#39; filename = 0 for data in datagroup: url = &#39;https:&#39; + data[&#39;data-src&#39;][:-7] + &#39;xxlarge#1&#39; r = requests.get(url, stream=True) #성산일출봉 폴더에 다운로드 받아 저장합니다. with open(&#39;성산일출봉/&#39; + str(filename) + &#39;.jpg&#39;, &#39;wb&#39;) as f: r.raw.decode_content = True shutil.copyfileobj(r.raw, f) filename += 1 .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/crawling/2021/09/20/_07_19_%ED%81%AC%EB%A1%A4%EB%A7%81_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%A0%80%EC%9E%A5%ED%95%98%EA%B8%B0(DataFrame,_img).html",
            "relUrl": "/crawling/2021/09/20/_07_19_%ED%81%AC%EB%A1%A4%EB%A7%81_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%A0%80%EC%9E%A5%ED%95%98%EA%B8%B0(DataFrame,_img).html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "캐글 입문",
            "content": "&#45936;&#51060;&#53552; &#49440;&#53469;(&#47196;&#46300;) &#48143; &#44208;&#52769;&#52824; &#52376;&#47532; . import matplotlib.pyplot as plt import pandas as pd import seaborn as sns # 작업파일과 다운받은 파일이 다른위치에 있을경우 &#39;train.csv&#39;를 수정해주셔야합니다! train = pd.read_csv(&#39;train.csv&#39;, index_col=&#39;PassengerId&#39;) test = pd.read_csv(&#39;test.csv&#39;, index_col=&#39;PassengerId&#39;) train.head() #train.tail()을 하게 되면, 마지막 데이터를 확인합니다. . Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . PassengerId . 1 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 2 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 3 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 4 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 5 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | . train.shape, test.shape . ((891, 11), (418, 10)) . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 891 entries, 1 to 891 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 Survived 891 non-null int64 1 Pclass 891 non-null int64 2 Name 891 non-null object 3 Sex 891 non-null object 4 Age 714 non-null float64 5 SibSp 891 non-null int64 6 Parch 891 non-null int64 7 Ticket 891 non-null object 8 Fare 891 non-null float64 9 Cabin 204 non-null object 10 Embarked 889 non-null object dtypes: float64(2), int64(4), object(5) memory usage: 83.5+ KB . test.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 418 entries, 892 to 1309 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 Pclass 418 non-null int64 1 Name 418 non-null object 2 Sex 418 non-null object 3 Age 332 non-null float64 4 SibSp 418 non-null int64 5 Parch 418 non-null int64 6 Ticket 418 non-null object 7 Fare 417 non-null float64 8 Cabin 91 non-null object 9 Embarked 418 non-null object dtypes: float64(2), int64(3), object(5) memory usage: 35.9+ KB . train.isnull() train True + True + True True + True + False train.isnull().sum() . Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 . sex_mean = train.groupby(&#39;Sex&#39;)[&#39;Age&#39;].mean() sex_mean . Sex female 27.915709 male 30.726645 Name: Age, dtype: float64 . train.loc[(train[&quot;Sex&quot;] == &#39;female&#39;) &amp; (train[&quot;Age&quot;].isnull()), &quot;Age&quot;] = int(sex_mean[0]) train.loc[(train[&quot;Sex&quot;] == &#39;male&#39;) &amp; (train[&quot;Age&quot;].isnull()), &quot;Age&quot;] = int(sex_mean[1]) train[&#39;Age&#39;] = train[&#39;Age&#39;].apply(lambda x:round(x)) train.head() . Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . PassengerId . 1 0 | 3 | Braund, Mr. Owen Harris | male | 22 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 2 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 3 1 | 3 | Heikkinen, Miss. Laina | female | 26 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 4 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 5 0 | 3 | Allen, Mr. William Henry | male | 35 | 0 | 0 | 373450 | 8.0500 | NaN | S | . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 891 entries, 1 to 891 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 Survived 891 non-null int64 1 Pclass 891 non-null int64 2 Name 891 non-null object 3 Sex 891 non-null object 4 Age 891 non-null int64 5 SibSp 891 non-null int64 6 Parch 891 non-null int64 7 Ticket 891 non-null object 8 Fare 891 non-null float64 9 Cabin 204 non-null object 10 Embarked 889 non-null object dtypes: float64(1), int64(5), object(5) memory usage: 83.5+ KB . train.Cabin.value_counts() . G6 4 B96 B98 4 C23 C25 C27 4 E101 3 D 3 .. E68 1 B71 1 D45 1 C7 1 A31 1 Name: Cabin, Length: 147, dtype: int64 . train.Sex.value_counts() . male 577 female 314 Name: Sex, dtype: int64 . train.Pclass.value_counts() . 3 491 1 216 2 184 Name: Pclass, dtype: int64 . train[&#39;Cabin&#39;] = train[&#39;Cabin&#39;].fillna(&#39;N&#39;) #결측치를 &#39;N&#39;으로 채우라는 명령 train[&#39;Cabin&#39;] = train[&#39;Cabin&#39;].apply(lambda x:x[0]) #해당 값을 0번째 값으로만 채우라는 명령 train.head(20) #제대로 반영이 되었는지 20개만 출력을 해봅니다. . Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . PassengerId . 1 0 | 3 | Braund, Mr. Owen Harris | male | 22 | 1 | 0 | A/5 21171 | 7.2500 | N | S | . 2 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38 | 1 | 0 | PC 17599 | 71.2833 | C | C | . 3 1 | 3 | Heikkinen, Miss. Laina | female | 26 | 0 | 0 | STON/O2. 3101282 | 7.9250 | N | S | . 4 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35 | 1 | 0 | 113803 | 53.1000 | C | S | . 5 0 | 3 | Allen, Mr. William Henry | male | 35 | 0 | 0 | 373450 | 8.0500 | N | S | . 6 0 | 3 | Moran, Mr. James | male | 30 | 0 | 0 | 330877 | 8.4583 | N | Q | . 7 0 | 1 | McCarthy, Mr. Timothy J | male | 54 | 0 | 0 | 17463 | 51.8625 | E | S | . 8 0 | 3 | Palsson, Master. Gosta Leonard | male | 2 | 3 | 1 | 349909 | 21.0750 | N | S | . 9 1 | 3 | Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) | female | 27 | 0 | 2 | 347742 | 11.1333 | N | S | . 10 1 | 2 | Nasser, Mrs. Nicholas (Adele Achem) | female | 14 | 1 | 0 | 237736 | 30.0708 | N | C | . 11 1 | 3 | Sandstrom, Miss. Marguerite Rut | female | 4 | 1 | 1 | PP 9549 | 16.7000 | G | S | . 12 1 | 1 | Bonnell, Miss. Elizabeth | female | 58 | 0 | 0 | 113783 | 26.5500 | C | S | . 13 0 | 3 | Saundercock, Mr. William Henry | male | 20 | 0 | 0 | A/5. 2151 | 8.0500 | N | S | . 14 0 | 3 | Andersson, Mr. Anders Johan | male | 39 | 1 | 5 | 347082 | 31.2750 | N | S | . 15 0 | 3 | Vestrom, Miss. Hulda Amanda Adolfina | female | 14 | 0 | 0 | 350406 | 7.8542 | N | S | . 16 1 | 2 | Hewlett, Mrs. (Mary D Kingcome) | female | 55 | 0 | 0 | 248706 | 16.0000 | N | S | . 17 0 | 3 | Rice, Master. Eugene | male | 2 | 4 | 1 | 382652 | 29.1250 | N | Q | . 18 1 | 2 | Williams, Mr. Charles Eugene | male | 30 | 0 | 0 | 244373 | 13.0000 | N | S | . 19 0 | 3 | Vander Planke, Mrs. Julius (Emelia Maria Vande... | female | 31 | 1 | 0 | 345763 | 18.0000 | N | S | . 20 1 | 3 | Masselmani, Mrs. Fatima | female | 27 | 0 | 0 | 2649 | 7.2250 | N | C | . def 함수(x): return x[0] 함수(&#39;hello world&#39;) . &#39;h&#39; . def 제곱(x): return x**2 list(map(제곱, [1, 2, 3, 4, 5, 6])) . [1, 4, 9, 16, 25, 36] . list(map(lambda x:x**2, [1, 2, 3, 4, 5, 6])) . [1, 4, 9, 16, 25, 36] . train[&#39;Embarked&#39;].value_counts() . S 644 C 168 Q 77 Name: Embarked, dtype: int64 . train[&#39;Embarked&#39;].isnull().sum() . 2 . train[&#39;Embarked&#39;] = train[&#39;Embarked&#39;].fillna(&#39;S&#39;) . train[&#39;Survived&#39;].value_counts() . 0 549 1 342 Name: Survived, dtype: int64 . train[&quot;hojun&quot;] = 100 train . Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked hojun . PassengerId . 1 0 | 3 | Braund, Mr. Owen Harris | male | 22 | 1 | 0 | A/5 21171 | 7.2500 | N | S | 100 | . 2 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38 | 1 | 0 | PC 17599 | 71.2833 | C | C | 100 | . 3 1 | 3 | Heikkinen, Miss. Laina | female | 26 | 0 | 0 | STON/O2. 3101282 | 7.9250 | N | S | 100 | . 4 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35 | 1 | 0 | 113803 | 53.1000 | C | S | 100 | . 5 0 | 3 | Allen, Mr. William Henry | male | 35 | 0 | 0 | 373450 | 8.0500 | N | S | 100 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 887 0 | 2 | Montvila, Rev. Juozas | male | 27 | 0 | 0 | 211536 | 13.0000 | N | S | 100 | . 888 1 | 1 | Graham, Miss. Margaret Edith | female | 19 | 0 | 0 | 112053 | 30.0000 | B | S | 100 | . 889 0 | 3 | Johnston, Miss. Catherine Helen &quot;Carrie&quot; | female | 27 | 1 | 2 | W./C. 6607 | 23.4500 | N | S | 100 | . 890 1 | 1 | Behr, Mr. Karl Howell | male | 26 | 0 | 0 | 111369 | 30.0000 | C | C | 100 | . 891 0 | 3 | Dooley, Mr. Patrick | male | 32 | 0 | 0 | 370376 | 7.7500 | N | Q | 100 | . 891 rows × 12 columns . train[&quot;Survived_label&quot;] = train[&quot;Survived&quot;].replace(0, &quot;Dead&quot;).replace(1, &quot;Survived&quot;) train[[&#39;Survived&#39;,&#39;Survived_label&#39;]].head() . Survived Survived_label . PassengerId . 1 0 | Dead | . 2 1 | Survived | . 3 1 | Survived | . 4 1 | Survived | . 5 0 | Dead | . train[&#39;Survived_label&#39;].value_counts() . Dead 549 Survived 342 Name: Survived_label, dtype: int64 . temp = train[&#39;Survived_label&#39;].value_counts() survival_rate = temp[1]/(temp[0] + temp[1])*100 print(f&quot;생존율은 {survival_rate:.1f}% 입니다.&quot;) . 생존율은 38.4% 입니다. . &#49884;&#44033;&#54868; . train[&#39;Survived&#39;].plot(kind=&#39;hist&#39;, bins=3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fbcf60c0790&gt; . train[&#39;Survived_label&#39;].value_counts().plot(kind=&#39;bar&#39;, rot=&#39;45&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fbcf570ac50&gt; . train[&#39;Survived_label&#39;].value_counts().plot(kind=&#39;pie&#39;, autopct=&#39;%1.2f%%&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fbcf5243750&gt; . import matplotlib.pyplot as plt import pandas as pd import seaborn as sns . f,ax=plt.subplots(1,2,figsize=(12,6)) train[&#39;Survived_label&#39;].value_counts().plot.pie(explode=[0,0.1],autopct=&#39;%1.2f%%&#39;,ax=ax[0]) ax[0].set_title(&#39;Survived&#39;) ax[0].set_ylabel(&#39;&#39;) sns.countplot(&#39;Survived_label&#39;,data=train,ax=ax[1]) ax[1].set_title(&#39;Survived&#39;) plt.show() . /usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. FutureWarning . &#45936;&#51060;&#53552; &#48516;&#49437; . sns.countplot(data=train, x=&quot;Sex&quot;, hue=&quot;Survived_label&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fbcf521bd50&gt; . sns.countplot(data=train, x=&quot;Pclass&quot;, hue=&quot;Survived_label&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fbcf461c4d0&gt; . train[&#39;Age&#39;].hist(bins=20,figsize=(10,5),grid=False,edgecolor=&#39;black&#39;,color=&#39;yellowgreen&#39;); . def 함수(x=10, y=20): return x + y 함수(100, y=200) . 300 . sns.countplot(data=train, x=&quot;SibSp&quot;, hue=&quot;Survived_label&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fbcf461cad0&gt; . sns.countplot(data=train, x=&quot;Parch&quot;, hue=&quot;Survived_label&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fbcf45a4f50&gt; . &#47672;&#49888;&#47084;&#45789; . &#47672;&#49888;&#47084;&#45789; &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . import matplotlib.pyplot as plt import pandas as pd import seaborn as sns train = pd.read_csv(&#39;train.csv&#39;) test = pd.read_csv(&#39;test.csv&#39;) . train.corr() . PassengerId Survived Pclass Age SibSp Parch Fare . PassengerId 1.000000 | -0.005007 | -0.035144 | 0.036847 | -0.057527 | -0.001652 | 0.012658 | . Survived -0.005007 | 1.000000 | -0.338481 | -0.077221 | -0.035322 | 0.081629 | 0.257307 | . Pclass -0.035144 | -0.338481 | 1.000000 | -0.369226 | 0.083081 | 0.018443 | -0.549500 | . Age 0.036847 | -0.077221 | -0.369226 | 1.000000 | -0.308247 | -0.189119 | 0.096067 | . SibSp -0.057527 | -0.035322 | 0.083081 | -0.308247 | 1.000000 | 0.414838 | 0.159651 | . Parch -0.001652 | 0.081629 | 0.018443 | -0.189119 | 0.414838 | 1.000000 | 0.216225 | . Fare 0.012658 | 0.257307 | -0.549500 | 0.096067 | 0.159651 | 0.216225 | 1.000000 | . train[&#39;Title&#39;] = train[&#39;Name&#39;].str.extract(&#39; ([A-Za-z]+) .&#39;, expand=False) train[&#39;Title&#39;] = train[&#39;Title&#39;].replace([&#39;Lady&#39;, &#39;Countess&#39;,&#39;Capt&#39;, &#39;Col&#39;,&#39;Don&#39;, &#39;Dr&#39;, &#39;Major&#39;, &#39;Rev&#39;, &#39;Sir&#39;, &#39;Jonkheer&#39;, &#39;Dona&#39;, &#39;Mlle&#39;, &#39;Ms&#39;, &#39;Mme&#39;], &#39;Other&#39;) train[&#39;Title&#39;] = train[&#39;Title&#39;].replace(&#39;Mlle&#39;, &#39;Miss&#39;) train[&#39;Title&#39;] = train[&#39;Title&#39;].replace(&#39;Ms&#39;, &#39;Miss&#39;) train[&#39;Title&#39;] = train[&#39;Title&#39;].replace(&#39;Mme&#39;, &#39;Mrs&#39;) . train[&#39;Title&#39;].value_counts() . Mr 517 Miss 182 Mrs 125 Master 40 Other 27 Name: Title, dtype: int64 . train[&#39;Title_label&#39;] = train[&#39;Title&#39;].astype(&#39;category&#39;).cat.codes train[[&#39;Title&#39;,&#39;Title_label&#39;]] . Title Title_label . 0 Mr | 2 | . 1 Mrs | 3 | . 2 Miss | 1 | . 3 Mrs | 3 | . 4 Mr | 2 | . ... ... | ... | . 886 Other | 4 | . 887 Miss | 1 | . 888 Miss | 1 | . 889 Mr | 2 | . 890 Mr | 2 | . 891 rows × 2 columns . test[&#39;Title&#39;] = test[&#39;Name&#39;].str.extract(&#39; ([A-Za-z]+) .&#39;, expand=False) test[&#39;Title&#39;] = test[&#39;Title&#39;].replace([&#39;Lady&#39;, &#39;Countess&#39;,&#39;Capt&#39;, &#39;Col&#39;,&#39;Don&#39;, &#39;Dr&#39;, &#39;Major&#39;, &#39;Rev&#39;, &#39;Sir&#39;, &#39;Jonkheer&#39;, &#39;Dona&#39;, &#39;Mlle&#39;, &#39;Ms&#39;, &#39;Mme&#39;], &#39;Other&#39;) test[&#39;Title&#39;] = test[&#39;Title&#39;].replace(&#39;Mlle&#39;, &#39;Miss&#39;) test[&#39;Title&#39;] = test[&#39;Title&#39;].replace(&#39;Ms&#39;, &#39;Miss&#39;) test[&#39;Title&#39;] = test[&#39;Title&#39;].replace(&#39;Mme&#39;, &#39;Mrs&#39;) test[&#39;Title&#39;].value_counts() . Mr 240 Miss 78 Mrs 72 Master 21 Other 7 Name: Title, dtype: int64 . test[&#39;Title_label&#39;] = train[&#39;Title&#39;].astype(&#39;category&#39;).cat.codes test[[&#39;Title&#39;,&#39;Title_label&#39;]] . Title Title_label . 0 Mr | 2 | . 1 Mrs | 3 | . 2 Mr | 1 | . 3 Mr | 3 | . 4 Mrs | 2 | . ... ... | ... | . 413 Mr | 2 | . 414 Other | 2 | . 415 Mr | 3 | . 416 Mr | 3 | . 417 Master | 1 | . 418 rows × 2 columns . 전체데이터 = [train, test] . for 데이터 in 전체데이터: 데이터[&#39;Title&#39;] = 데이터[&#39;Name&#39;].str.extract(&#39; ([A-Za-z]+) .&#39;, expand=False) . mapping_data = {&quot;Mr&quot;: 0, &quot;Miss&quot;: 1, &quot;Mrs&quot;: 2, &quot;Master&quot;: 3, &quot;Dr&quot;: 3, &quot;Rev&quot;: 3, &quot;Col&quot;: 3, &quot;Major&quot;: 3, &quot;Mlle&quot;: 3,&quot;Countess&quot;: 3, &quot;Ms&quot;: 3, &quot;Lady&quot;: 3, &quot;Jonkheer&quot;: 3, &quot;Don&quot;: 3, &quot;Dona&quot; : 3, &quot;Mme&quot;: 3,&quot;Capt&quot;: 3,&quot;Sir&quot;: 3 } for 데이터 in 전체데이터: 데이터[&#39;Title&#39;] = 데이터[&#39;Title&#39;].map(mapping_data) . train.drop(&#39;Name&#39;, axis=1, inplace=True) test.drop(&#39;Name&#39;, axis=1, inplace=True) . train.drop(&#39;Title&#39;, axis=1, inplace=True) test.drop(&#39;Title&#39;, axis=1, inplace=True) . train test . PassengerId Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Title_label . 0 892 | 3 | male | 34.5 | 0 | 0 | 330911 | 7.8292 | NaN | Q | 2 | . 1 893 | 3 | female | 47.0 | 1 | 0 | 363272 | 7.0000 | NaN | S | 3 | . 2 894 | 2 | male | 62.0 | 0 | 0 | 240276 | 9.6875 | NaN | Q | 1 | . 3 895 | 3 | male | 27.0 | 0 | 0 | 315154 | 8.6625 | NaN | S | 3 | . 4 896 | 3 | female | 22.0 | 1 | 1 | 3101298 | 12.2875 | NaN | S | 2 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 413 1305 | 3 | male | NaN | 0 | 0 | A.5. 3236 | 8.0500 | NaN | S | 2 | . 414 1306 | 1 | female | 39.0 | 0 | 0 | PC 17758 | 108.9000 | C105 | C | 2 | . 415 1307 | 3 | male | 38.5 | 0 | 0 | SOTON/O.Q. 3101262 | 7.2500 | NaN | S | 3 | . 416 1308 | 3 | male | NaN | 0 | 0 | 359309 | 8.0500 | NaN | S | 3 | . 417 1309 | 3 | male | NaN | 1 | 1 | 2668 | 22.3583 | NaN | C | 1 | . 418 rows × 11 columns . train[&quot;Age&quot;].fillna(train.groupby(&quot;Sex&quot;)[&quot;Age&quot;].transform(&quot;median&quot;), inplace=True) test[&quot;Age&quot;].fillna(test.groupby(&quot;Sex&quot;)[&quot;Age&quot;].transform(&quot;median&quot;), inplace=True) . for 데이터 in 전체데이터: 데이터.loc[ 데이터[&#39;Age&#39;] &lt;= 16, &#39;Age&#39;] = 0 데이터.loc[(데이터[&#39;Age&#39;] &gt; 16) &amp; (데이터[&#39;Age&#39;] &lt;= 26), &#39;Age&#39;] = 1 데이터.loc[(데이터[&#39;Age&#39;] &gt; 26) &amp; (데이터[&#39;Age&#39;] &lt;= 36), &#39;Age&#39;] = 2 데이터.loc[(데이터[&#39;Age&#39;] &gt; 36) &amp; (데이터[&#39;Age&#39;] &lt;= 62), &#39;Age&#39;] = 3 데이터.loc[ 데이터[&#39;Age&#39;] &gt; 62, &#39;Age&#39;] = 4 . train.head() . PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Title_label . 0 1 | 0 | 3 | male | 1.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | 2 | . 1 2 | 1 | 1 | female | 3.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | 3 | . 2 3 | 1 | 3 | female | 1.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | 1 | . 3 4 | 1 | 1 | female | 2.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | 3 | . 4 5 | 0 | 3 | male | 2.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | 2 | . for 데이터 in 전체데이터: 데이터[&#39;Fare_bin&#39;] = pd.qcut(train[&#39;Fare&#39;], 5) 데이터[&#39;Fare_label&#39;] = 데이터[&#39;Fare_bin&#39;].astype(&#39;category&#39;).cat.codes . for 데이터 in 전체데이터: 데이터.drop(&#39;Fare&#39;, axis=1, inplace=True) 데이터.drop(&#39;Fare_bin&#39;, axis=1, inplace=True) . train[&quot;FamilySize&quot;] = train[&quot;SibSp&quot;] + train[&quot;Parch&quot;] + 1 test[&quot;FamilySize&quot;] = test[&quot;SibSp&quot;] + test[&quot;Parch&quot;] + 1 . mapping_data = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4} for 데이터 in 전체데이터: 데이터[&#39;FamilySize&#39;] = 데이터[&#39;FamilySize&#39;].map(mapping_data) . for 데이터 in 전체데이터: 데이터[&#39;Embarked&#39;] = 데이터[&#39;Embarked&#39;].fillna(&#39;S&#39;) . mapping_data = {&quot;S&quot;: 0, &quot;C&quot;: 1, &quot;Q&quot;: 2} for 데이터 in 전체데이터: 데이터[&#39;Embarked&#39;] = 데이터[&#39;Embarked&#39;].map(mapping_data) . train[&#39;Sex&#39;] = train[&#39;Sex&#39;].astype(&#39;category&#39;).cat.codes . test[&#39;Sex&#39;] = test[&#39;Sex&#39;].astype(&#39;category&#39;).cat.codes . train . PassengerId Survived Pclass Sex Age SibSp Parch Ticket Cabin Embarked Title_label Fare_label FamilySize . 0 1 | 0 | 3 | 1 | 1.0 | 1 | 0 | A/5 21171 | NaN | 0 | 2 | 0 | 0.4 | . 1 2 | 1 | 1 | 0 | 3.0 | 1 | 0 | PC 17599 | C85 | 1 | 3 | 4 | 0.4 | . 2 3 | 1 | 3 | 0 | 1.0 | 0 | 0 | STON/O2. 3101282 | NaN | 0 | 1 | 1 | 0.0 | . 3 4 | 1 | 1 | 0 | 2.0 | 1 | 0 | 113803 | C123 | 0 | 3 | 4 | 0.4 | . 4 5 | 0 | 3 | 1 | 2.0 | 0 | 0 | 373450 | NaN | 0 | 2 | 1 | 0.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 886 887 | 0 | 2 | 1 | 2.0 | 0 | 0 | 211536 | NaN | 0 | 4 | 2 | 0.0 | . 887 888 | 1 | 1 | 0 | 1.0 | 0 | 0 | 112053 | B42 | 0 | 1 | 3 | 0.0 | . 888 889 | 0 | 3 | 0 | 2.0 | 1 | 2 | W./C. 6607 | NaN | 0 | 1 | 3 | 1.2 | . 889 890 | 1 | 1 | 1 | 1.0 | 0 | 0 | 111369 | C148 | 1 | 2 | 3 | 0.0 | . 890 891 | 0 | 3 | 1 | 2.0 | 0 | 0 | 370376 | NaN | 2 | 2 | 0 | 0.0 | . 891 rows × 13 columns . for 데이터 in 전체데이터: 데이터.drop(&#39;Ticket&#39;, axis=1, inplace=True) 데이터.drop(&#39;Cabin&#39;, axis=1, inplace=True) 데이터.drop(&#39;PassengerId&#39;, axis=1, inplace=True) . train.head() . Survived Pclass Sex Age SibSp Parch Embarked Title_label Fare_label FamilySize . 0 0 | 3 | 1 | 1.0 | 1 | 0 | 0 | 2 | 0 | 0.4 | . 1 1 | 1 | 0 | 3.0 | 1 | 0 | 1 | 3 | 4 | 0.4 | . 2 1 | 3 | 0 | 1.0 | 0 | 0 | 0 | 1 | 1 | 0.0 | . 3 1 | 1 | 0 | 2.0 | 1 | 0 | 0 | 3 | 4 | 0.4 | . 4 0 | 3 | 1 | 2.0 | 0 | 0 | 0 | 2 | 1 | 0.0 | . train.corr() . Survived Pclass Sex Age SibSp Parch Embarked Title_label Fare_label FamilySize . Survived 1.000000 | -0.338481 | -0.543351 | -0.072077 | -0.035322 | 0.081629 | 0.106811 | -0.052471 | 0.317783 | 0.016639 | . Pclass -0.338481 | 1.000000 | 0.131900 | -0.286667 | 0.083081 | 0.018443 | 0.045702 | -0.195910 | -0.705206 | 0.065997 | . Sex -0.543351 | 0.131900 | 1.000000 | 0.084630 | -0.114631 | -0.245489 | -0.116569 | 0.040484 | -0.244943 | -0.200988 | . Age -0.072077 | -0.286667 | 0.084630 | 1.000000 | -0.228235 | -0.165474 | 0.034334 | 0.447788 | 0.087896 | -0.238659 | . SibSp -0.035322 | 0.083081 | -0.114631 | -0.228235 | 1.000000 | 0.414838 | -0.059961 | -0.213887 | 0.354974 | 0.890712 | . Parch 0.081629 | 0.018443 | -0.245489 | -0.165474 | 0.414838 | 1.000000 | -0.078665 | -0.122792 | 0.351317 | 0.783111 | . Embarked 0.106811 | 0.045702 | -0.116569 | 0.034334 | -0.059961 | -0.078665 | 1.000000 | -0.081928 | -0.089125 | -0.080281 | . Title_label -0.052471 | -0.195910 | 0.040484 | 0.447788 | -0.213887 | -0.122792 | -0.081928 | 1.000000 | 0.060707 | -0.207530 | . Fare_label 0.317783 | -0.705206 | -0.244943 | 0.087896 | 0.354974 | 0.351317 | -0.089125 | 0.060707 | 1.000000 | 0.418125 | . FamilySize 0.016639 | 0.065997 | -0.200988 | -0.238659 | 0.890712 | 0.783111 | -0.080281 | -0.207530 | 0.418125 | 1.000000 | . plt.figure(figsize=(15,15)) sns.heatmap(data=train.corr(), annot=True, fmt=&#39;.2f&#39;, linewidths=.5, cmap=&#39;Blues&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fbcf44006d0&gt; . train.head() test.head() . Pclass Sex Age SibSp Parch Embarked Title_label Fare_label FamilySize . 0 3 | 1 | 2.0 | 0 | 0 | 2 | 2 | 0 | 0.0 | . 1 3 | 0 | 3.0 | 1 | 0 | 0 | 3 | 4 | 0.4 | . 2 2 | 1 | 3.0 | 0 | 0 | 2 | 1 | 1 | 0.0 | . 3 3 | 1 | 2.0 | 0 | 0 | 0 | 3 | 4 | 0.0 | . 4 3 | 0 | 1.0 | 1 | 1 | 0 | 2 | 1 | 0.8 | . from sklearn.neighbors import KNeighborsClassifier from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.naive_bayes import GaussianNB from sklearn.svm import SVC import numpy as np . train_data = train.drop(&#39;Survived&#39;, axis=1) target = train[&#39;Survived&#39;] train_data.shape, target.shape . ((891, 9), (891,)) . train_data target . 0 0 1 1 2 1 3 1 4 0 .. 886 0 887 1 888 0 889 1 890 0 Name: Survived, Length: 891, dtype: int64 . from sklearn.model_selection import KFold from sklearn.model_selection import cross_val_score k_fold = KFold(n_splits=10, shuffle=True, random_state=0) . clf = KNeighborsClassifier(n_neighbors = 13) scoring = &#39;accuracy&#39; score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) . round(np.mean(score)*100, 2) . 81.03 . score . array([0.82222222, 0.74157303, 0.84269663, 0.7752809 , 0.85393258, 0.82022472, 0.79775281, 0.75280899, 0.85393258, 0.84269663]) . clf = DecisionTreeClassifier() scoring = &#39;accuracy&#39; score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) . round(np.mean(score)*100, 2) . 79.8 . clf = RandomForestClassifier(n_estimators=13) scoring = &#39;accuracy&#39; score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) . round(np.mean(score)*100, 2) . 80.81 . clf = GaussianNB() scoring = &#39;accuracy&#39; score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) . round(np.mean(score)*100, 2) . 78.9 . clf = SVC() scoring = &#39;accuracy&#39; score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring) . round(np.mean(score)*100,2) . 82.83 . &#50696;&#52769;&#54620; &#44050;&#51012; &#52880;&#44544;&#50640; &#51228;&#52636; . clf = SVC() clf.fit(train_data, target) test_data = test.copy() prediction = clf.predict(test_data) prediction . array([0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]) .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D/2021/09/20/_07_14_%EC%BA%90%EA%B8%80%EC%9E%85%EB%AC%B8.html",
            "relUrl": "/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D/2021/09/20/_07_14_%EC%BA%90%EA%B8%80%EC%9E%85%EB%AC%B8.html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "데이터 시각화 기초 문법 노트북",
            "content": "출처 : 데이터 사이언스 스쿨 (데이터 시각화) | . &#54620;&#44544;&#54256;&#53944; . !sudo apt install -y fonts-nanum* !sudo fc-cache -fv !rm ~/.cache/matplotlib -rf . import matplotlib.pyplot as plt plt.rc(&#39;font&#39;, family=&#39;NanumBarunGothic&#39;) . plt.title(&#39;한글 제목&#39;) plt.plot([10, 20, 30, 40], [1, 4, 9, 16]) plt.xlabel(&quot;엑스축 라벨&quot;) plt.ylabel(&quot;와이축 라벨&quot;) plt.show() . &#49884;&#44033;&#54868; &#44592;&#48376; &#47928;&#48277; (matplotlib) . import numpy as np import pandas as pd t = np.arange(0., 5., 0.2) plt.title(&quot;라인 플롯에서 여러개의 선 그리기&quot;) plt.plot(t, t, &#39;r--&#39;, t, 0.5 * t**2, &#39;bs:&#39;, t, 0.2 * t**3, &#39;g^-&#39;) plt.show() . X = np.linspace(-np.pi, np.pi, 256) C, S = np.cos(X), np.sin(X) plt.title(&quot;legend를 표시한 플롯&quot;) plt.plot(X, C, ls=&quot;--&quot;, label=&quot;cosine&quot;) plt.plot(X, S, ls=&quot;:&quot;, label=&quot;sine&quot;) plt.legend(loc=4) #범례 1, 2, 3, 4로 변경해 보세요. plt.show() . /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . X = np.linspace(-np.pi, np.pi, 256) C, S = np.cos(X), np.sin(X) plt.plot(X, C, label=&quot;cosine&quot;) plt.xlabel(&quot;time&quot;) plt.ylabel(&quot;amplitude&quot;) plt.title(&quot;Cosine Plot&quot;) plt.show() . /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . &#54540;&#47215;&#51032; &#51333;&#47448; . import matplotlib as mpl import matplotlib.pylab as plt y = [2, 3, 1] x = np.arange(len(y)) xlabel = [&#39;가&#39;, &#39;나&#39;, &#39;다&#39;] plt.title(&quot;Bar Chart&quot;) plt.bar(x, y) #barh plt.xticks(x, xlabel) plt.yticks(sorted(y)) plt.xlabel(&quot;가나다&quot;) plt.ylabel(&quot;빈도 수&quot;) plt.show() . plt.axis(&#39;equal&#39;) labels = [&#39;개구리&#39;, &#39;돼지&#39;, &#39;개&#39;, &#39;통나무&#39;] sizes = [15, 30, 45, 10] colors = [&#39;yellowgreen&#39;, &#39;gold&#39;, &#39;lightskyblue&#39;, &#39;lightcoral&#39;] explode = (0, 0.1, 0, 0) plt.title(&quot;Pie Chart&quot;) plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct=&#39;%1.1f%%&#39;, shadow=True, startangle=90) plt.axis(&#39;equal&#39;) plt.show() . data = [np.random.randint(1, 7) for i in range(100)] data . data = [] for i in range(100): data.append(np.random.randint(1, 7)) . np.random.seed(0) data = [np.random.randint(1, 7) for i in range(100000)] plt.title(&quot;Histogram&quot;) arrays, bins, patches = plt.hist(data, bins=11) plt.show() . np.random.seed(0) X = np.random.normal(0, 1, 100) Y = np.random.normal(0, 1, 100) plt.title(&quot;Scatter Plot&quot;) plt.scatter(X, Y) plt.show() . /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . N = 30 np.random.seed(0) x = np.random.rand(N) y1 = np.random.rand(N) y2 = np.random.rand(N) y3 = np.pi * (15 * np.random.rand(N))**2 plt.title(&quot;Bubble Chart&quot;) plt.scatter(x, y1, c=y2, s=y3) plt.show() . from sklearn.datasets import load_digits digits = load_digits() X = digits.images[0] X . array([[ 0., 0., 5., 13., 9., 1., 0., 0.], [ 0., 0., 13., 15., 10., 15., 5., 0.], [ 0., 3., 15., 2., 0., 11., 8., 0.], [ 0., 4., 12., 0., 0., 8., 8., 0.], [ 0., 5., 8., 0., 0., 9., 8., 0.], [ 0., 4., 11., 0., 1., 12., 7., 0.], [ 0., 2., 14., 5., 10., 12., 0., 0.], [ 0., 0., 6., 13., 10., 0., 0., 0.]]) . plt.title(&quot;mnist digits; 0&quot;) plt.imshow(X, interpolation=&#39;nearest&#39;, cmap=plt.cm.bone_r) plt.xticks([]) plt.yticks([]) plt.grid(False) plt.subplots_adjust(left=0.35, right=0.65, bottom=0.35, top=0.65) plt.show() . &#51060;&#48120;&#51648; &#48516;&#49437; . import numpy as np from skimage import io import matplotlib.pyplot as plt . jeju = io.imread(&#39;jeju.jpg&#39;) . type(jeju) . numpy.ndarray . jeju.shape . (1440, 1920, 3) . jeju . plt.imshow(jeju) . &lt;matplotlib.image.AxesImage at 0x7f05f69d1550&gt; . l = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] l[::-1] l[::2] . [1, 3, 5, 7, 9] . plt.imshow(jeju[::-1]) . &lt;matplotlib.image.AxesImage at 0x7f05f3f003d0&gt; . l = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] data = np.array(l) data[data &gt; 5] data[:, 2] data[2, :] data[:, ::-1] . array([[3, 2, 1], [6, 5, 4], [9, 8, 7]]) . plt.imshow(jeju[:, ::-1]) . &lt;matplotlib.image.AxesImage at 0x7f05f2e86190&gt; . plt.imshow(jeju[800:1200, 700:1150]) . &lt;matplotlib.image.AxesImage at 0x7f05f2a818d0&gt; . plt.imshow(jeju[::5, ::5]) plt.imshow(jeju[::10, ::10]) plt.imshow(jeju[::50, ::50]) . &lt;matplotlib.image.AxesImage at 0x7f05f2956c10&gt; . &#49884;&#44033;&#54868; &#44592;&#48376; &#47928;&#48277; (Seaborn) . import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns . df = sns.load_dataset(&quot;titanic&quot;) df . survived pclass sex age sibsp parch fare embarked class who adult_male deck embark_town alive alone . 0 0 | 3 | male | 22.0 | 1 | 0 | 7.2500 | S | Third | man | True | NaN | Southampton | no | False | . 1 1 | 1 | female | 38.0 | 1 | 0 | 71.2833 | C | First | woman | False | C | Cherbourg | yes | False | . 2 1 | 3 | female | 26.0 | 0 | 0 | 7.9250 | S | Third | woman | False | NaN | Southampton | yes | True | . 3 1 | 1 | female | 35.0 | 1 | 0 | 53.1000 | S | First | woman | False | C | Southampton | yes | False | . 4 0 | 3 | male | 35.0 | 0 | 0 | 8.0500 | S | Third | man | True | NaN | Southampton | no | True | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 886 0 | 2 | male | 27.0 | 0 | 0 | 13.0000 | S | Second | man | True | NaN | Southampton | no | True | . 887 1 | 1 | female | 19.0 | 0 | 0 | 30.0000 | S | First | woman | False | B | Southampton | yes | True | . 888 0 | 3 | female | NaN | 1 | 2 | 23.4500 | S | Third | woman | False | NaN | Southampton | no | False | . 889 1 | 1 | male | 26.0 | 0 | 0 | 30.0000 | C | First | man | True | C | Cherbourg | yes | True | . 890 0 | 3 | male | 32.0 | 0 | 0 | 7.7500 | Q | Third | man | True | NaN | Queenstown | no | True | . 891 rows × 15 columns . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 15 columns): # Column Non-Null Count Dtype -- -- 0 survived 891 non-null int64 1 pclass 891 non-null int64 2 sex 891 non-null object 3 age 714 non-null float64 4 sibsp 891 non-null int64 5 parch 891 non-null int64 6 fare 891 non-null float64 7 embarked 889 non-null object 8 class 891 non-null category 9 who 891 non-null object 10 adult_male 891 non-null bool 11 deck 203 non-null category 12 embark_town 889 non-null object 13 alive 891 non-null object 14 alone 891 non-null bool dtypes: bool(2), category(2), float64(2), int64(4), object(5) memory usage: 80.6+ KB . sns.countplot(x=&quot;class&quot;, data=df) plt.title(&quot;타이타닉호의 각 클래스별, 승객 수&quot;) plt.show() . sns.countplot(x=&quot;alive&quot;, data=df) plt.title(&quot;타이타닉호의 각 클래스별, 승객 수&quot;) plt.show() . sns.jointplot(x=&quot;fare&quot;, y=&quot;alive&quot;, data=df) plt.suptitle(&quot;test&quot;, y=1.02) plt.show() . sns.jointplot(x=&quot;pclass&quot;, y=&quot;survived&quot;, data=df, kind=&quot;kde&quot;) plt.suptitle(&quot;Kernel Density Plot&quot;, y=1.02) plt.show() . /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0.0, flags=flags) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 8722 missing from current font. font.set_text(s, 0, flags=flags) . sns.pairplot(df) plt.title(&quot;Pair Plot&quot;) plt.show() . &lt;string&gt;:6: RuntimeWarning: Converting input from bool to &lt;class &#39;numpy.uint8&#39;&gt; for compatibility. &lt;string&gt;:6: RuntimeWarning: Converting input from bool to &lt;class &#39;numpy.uint8&#39;&gt; for compatibility. &lt;string&gt;:6: RuntimeWarning: Converting input from bool to &lt;class &#39;numpy.uint8&#39;&gt; for compatibility. &lt;string&gt;:6: RuntimeWarning: Converting input from bool to &lt;class &#39;numpy.uint8&#39;&gt; for compatibility. . sns.barplot(x=&quot;pclass&quot;, y=&quot;fare&quot;, data=df) plt.title(&quot;&quot;) plt.show() . sns.violinplot(x=&quot;pclass&quot;, y=&quot;fare&quot;, data=df) plt.title(&quot;등급별 운임 분포&quot;) plt.show() .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/matplotlib/seaborn/plotly/2021/09/20/_07_12_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D_%EC%8B%9C%EA%B0%81%ED%99%94.html",
            "relUrl": "/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/matplotlib/seaborn/plotly/2021/09/20/_07_12_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D_%EC%8B%9C%EA%B0%81%ED%99%94.html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "데이터 분석 pandas 기초 문법 노트북",
            "content": "import pandas as pd data = pd.read_html(&#39;https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%EC%9D%B8%EA%B5%AC&#39;) . 인구수 = data[1] 사망자수 = 인구수[[&#39;사망자수(명)&#39;]] 사망자수 . 사망자수(명) . 0 359042 | . 1 337948 | . 2 353818 | . 3 357701 | . 4 414366 | . ... ... | . 91 280827 | . 92 285534 | . 93 298820 | . 94 295132 | . 95 305100 | . 96 rows × 1 columns . 사망자수.sum()[0] . 28518711 . format(사망자수.sum()[0], &#39;,&#39;) . &#39;28,518,711&#39; . pandas &#44277;&#49885;&#54856;&#54168;&#51060;&#51648; tutorial . What kind of data does pandas handle? . import pandas as pd . 출처 : 공식 홈페이지 | . # DataFrame은 python의 dict로 만들 수 있습니다. # 그러나 실제 데이터는 대부분 csv로 되어있어, dict로 다루실일이 많이 없을거에요. df = pd.DataFrame( { &quot;Name&quot;: [ &quot;Braund, Mr. Owen Harris&quot;, &quot;Allen, Mr. William Henry&quot;, &quot;Bonnell, Miss. Elizabeth&quot;, ], &quot;Age&quot;: [22, 35, 58], &quot;Sex&quot;: [&quot;male&quot;, &quot;male&quot;, &quot;female&quot;], } ) . df . Name Age Sex . 0 Braund, Mr. Owen Harris | 22 | male | . 1 Allen, Mr. William Henry | 35 | male | . 2 Bonnell, Miss. Elizabeth | 58 | female | . 시리즈는 데이터프레임에서 하나의 컬럼입니다. | . . df[&quot;Age&quot;] . 0 22 1 35 2 58 Name: Age, dtype: int64 . type(df[&quot;Age&quot;]) . pandas.core.series.Series . df[[&quot;Age&quot;]] . Age . 0 22 | . 1 35 | . 2 58 | . type(df[[&#39;Age&#39;]]) . pandas.core.frame.DataFrame . Do something with a DataFrame or Series . df[&quot;Age&quot;].max() . 58 . df[&quot;Age&quot;].min() . 22 . df[&quot;Age&quot;].mean() . 38.333333333333336 . df[&quot;Age&quot;].var() . 332.3333333333333 . df[&quot;Age&quot;].std() . 18.230011885167087 . df.dtypes . Name object Age int64 Sex object dtype: object . df.describe() . Age . count 3.000000 | . mean 38.333333 | . std 18.230012 | . min 22.000000 | . 25% 28.500000 | . 50% 35.000000 | . 75% 46.500000 | . max 58.000000 | . How do I read and write tabular data? . . titanic = pd.read_csv(&quot;train.csv&quot;) . titanic . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 886 887 | 0 | 2 | Montvila, Rev. Juozas | male | 27.0 | 0 | 0 | 211536 | 13.0000 | NaN | S | . 887 888 | 1 | 1 | Graham, Miss. Margaret Edith | female | 19.0 | 0 | 0 | 112053 | 30.0000 | B42 | S | . 888 889 | 0 | 3 | Johnston, Miss. Catherine Helen &quot;Carrie&quot; | female | NaN | 1 | 2 | W./C. 6607 | 23.4500 | NaN | S | . 889 890 | 1 | 1 | Behr, Mr. Karl Howell | male | 26.0 | 0 | 0 | 111369 | 30.0000 | C148 | C | . 890 891 | 0 | 3 | Dooley, Mr. Patrick | male | 32.0 | 0 | 0 | 370376 | 7.7500 | NaN | Q | . 891 rows × 12 columns . titanic.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | . titanic.tail() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 886 887 | 0 | 2 | Montvila, Rev. Juozas | male | 27.0 | 0 | 0 | 211536 | 13.00 | NaN | S | . 887 888 | 1 | 1 | Graham, Miss. Margaret Edith | female | 19.0 | 0 | 0 | 112053 | 30.00 | B42 | S | . 888 889 | 0 | 3 | Johnston, Miss. Catherine Helen &quot;Carrie&quot; | female | NaN | 1 | 2 | W./C. 6607 | 23.45 | NaN | S | . 889 890 | 1 | 1 | Behr, Mr. Karl Howell | male | 26.0 | 0 | 0 | 111369 | 30.00 | C148 | C | . 890 891 | 0 | 3 | Dooley, Mr. Patrick | male | 32.0 | 0 | 0 | 370376 | 7.75 | NaN | Q | . titanic.dtypes . PassengerId int64 Survived int64 Pclass int64 Name object Sex object Age float64 SibSp int64 Parch int64 Ticket object Fare float64 Cabin object Embarked object dtype: object . titanic.to_excel(&quot;titanic.xlsx&quot;, sheet_name=&quot;passengers&quot;, index=False) . titanic_read_excel = pd.read_excel(&quot;titanic.xlsx&quot;, sheet_name=&quot;passengers&quot;) titanic_read_excel . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 886 887 | 0 | 2 | Montvila, Rev. Juozas | male | 27.0 | 0 | 0 | 211536 | 13.0000 | NaN | S | . 887 888 | 1 | 1 | Graham, Miss. Margaret Edith | female | 19.0 | 0 | 0 | 112053 | 30.0000 | B42 | S | . 888 889 | 0 | 3 | Johnston, Miss. Catherine Helen &quot;Carrie&quot; | female | NaN | 1 | 2 | W./C. 6607 | 23.4500 | NaN | S | . 889 890 | 1 | 1 | Behr, Mr. Karl Howell | male | 26.0 | 0 | 0 | 111369 | 30.0000 | C148 | C | . 890 891 | 0 | 3 | Dooley, Mr. Patrick | male | 32.0 | 0 | 0 | 370376 | 7.7500 | NaN | Q | . 891 rows × 12 columns . titanic.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB . How do I select a subset of a DataFrame? . How do I select specific columns from a DataFrame? . . titanic[&quot;Age&quot;].shape . (891,) . titanic[&quot;Sex&quot;].shape . (891,) . titanic[[&quot;Age&quot;, &quot;Sex&quot;]] # 괄호가 하나가 안되는 이유는 DataFrame이기 때문 . Age Sex . 0 22.0 | male | . 1 38.0 | female | . 2 26.0 | female | . 3 35.0 | female | . 4 35.0 | male | . ... ... | ... | . 886 27.0 | male | . 887 19.0 | female | . 888 NaN | female | . 889 26.0 | male | . 890 32.0 | male | . 891 rows × 2 columns . type(titanic[[&quot;Age&quot;, &quot;Sex&quot;]]) . pandas.core.frame.DataFrame . titanic[[&quot;Age&quot;, &quot;Sex&quot;]].shape . (891, 2) . How do I filter specific rows from a DataFrame? . . above_35 = titanic[titanic[&quot;Age&quot;] &gt; 35] above_35.head(10) . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 6 7 | 0 | 1 | McCarthy, Mr. Timothy J | male | 54.0 | 0 | 0 | 17463 | 51.8625 | E46 | S | . 11 12 | 1 | 1 | Bonnell, Miss. Elizabeth | female | 58.0 | 0 | 0 | 113783 | 26.5500 | C103 | S | . 13 14 | 0 | 3 | Andersson, Mr. Anders Johan | male | 39.0 | 1 | 5 | 347082 | 31.2750 | NaN | S | . 15 16 | 1 | 2 | Hewlett, Mrs. (Mary D Kingcome) | female | 55.0 | 0 | 0 | 248706 | 16.0000 | NaN | S | . 25 26 | 1 | 3 | Asplund, Mrs. Carl Oscar (Selma Augusta Emilia... | female | 38.0 | 1 | 5 | 347077 | 31.3875 | NaN | S | . 30 31 | 0 | 1 | Uruchurtu, Don. Manuel E | male | 40.0 | 0 | 0 | PC 17601 | 27.7208 | NaN | C | . 33 34 | 0 | 2 | Wheadon, Mr. Edward H | male | 66.0 | 0 | 0 | C.A. 24579 | 10.5000 | NaN | S | . 35 36 | 0 | 1 | Holverson, Mr. Alexander Oskar | male | 42.0 | 1 | 0 | 113789 | 52.0000 | NaN | S | . 40 41 | 0 | 3 | Ahlin, Mrs. Johan (Johanna Persdotter Larsson) | female | 40.0 | 1 | 0 | 7546 | 9.4750 | NaN | S | . titanic[&quot;Age&quot;] &gt; 35 (titanic[&quot;Age&quot;] &gt; 35).sum() . 217 . above_35.shape . (217, 12) . # | : or(둘 중 하나), &amp; : and(둘 다) class_23 = titanic[(titanic[&quot;Pclass&quot;] == 2) | (titanic[&quot;Pclass&quot;] == 3)] . titanic.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB . age_no_na = titanic[titanic[&quot;Age&quot;].notna()] age_no_na.shape . (714, 12) . How do I select specific rows and columns from a DataFrame? . . adult_names = titanic.loc[titanic[&quot;Age&quot;] &gt; 35, &quot;Name&quot;] adult_names . 1 Cumings, Mrs. John Bradley (Florence Briggs Th... 6 McCarthy, Mr. Timothy J 11 Bonnell, Miss. Elizabeth 13 Andersson, Mr. Anders Johan 15 Hewlett, Mrs. (Mary D Kingcome) ... 865 Bystrom, Mrs. (Karolina) 871 Beckwith, Mrs. Richard Leonard (Sallie Monypeny) 873 Vander Cruyssen, Mr. Victor 879 Potter, Mrs. Thomas Jr (Lily Alexenia Wilson) 885 Rice, Mrs. William (Margaret Norton) Name: Name, Length: 217, dtype: object . titanic.iloc[9:25, 2:5] . Pclass Name Sex . 9 2 | Nasser, Mrs. Nicholas (Adele Achem) | female | . 10 3 | Sandstrom, Miss. Marguerite Rut | female | . 11 1 | Bonnell, Miss. Elizabeth | female | . 12 3 | Saundercock, Mr. William Henry | male | . 13 3 | Andersson, Mr. Anders Johan | male | . 14 3 | Vestrom, Miss. Hulda Amanda Adolfina | female | . 15 2 | Hewlett, Mrs. (Mary D Kingcome) | female | . 16 3 | Rice, Master. Eugene | male | . 17 2 | Williams, Mr. Charles Eugene | male | . 18 3 | Vander Planke, Mrs. Julius (Emelia Maria Vande... | female | . 19 3 | Masselmani, Mrs. Fatima | female | . 20 2 | Fynney, Mr. Joseph J | male | . 21 2 | Beesley, Mr. Lawrence | male | . 22 3 | McGowan, Miss. Anna &quot;Annie&quot; | female | . 23 1 | Sloper, Mr. William Thompson | male | . 24 3 | Palsson, Miss. Torborg Danira | female | . &#53356;&#47204;&#47553; &#45936;&#51060;&#53552;&#47196; &#50937;&#54168;&#51060;&#51648; &#47564;&#46308;&#44592; . import pandas as pd data = pd.read_html(&#39;https://ridibooks.com/category/bestsellers/2200&#39;) data . import requests from bs4 import BeautifulSoup url = &#39;https://ridibooks.com/category/bestsellers/2200&#39; #수정 response = requests.get(url) response.encoding = &#39;utf-8&#39; html = response.text soup = BeautifulSoup(html, &#39;html.parser&#39;) bookservices = soup.select(&#39;.title_text&#39;) #수정 for no, book in enumerate(bookservices, 1): print(no, book.text.strip()) . 1 시드 마이어 2 한 권으로 읽는 컴퓨터 구조와 프로그래밍 3 개발자에서 아키텍트로 4 컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커 5 비전공자를 위한 이해할 수 있는 IT 지식 6 오브젝트 7 Node.js 디자인 패턴 바이블 8 눈치껏 못 배웁니다, 일센스 9 개정판 | 시작하세요! 도커/쿠버네티스 10 다재다능 코틀린 프로그래밍 11 파이썬으로 살펴보는 아키텍처 패턴 12 혼자 공부하는 머신러닝+딥러닝 13 비전공자도 배워서 바로 쓰는 비즈니스 데이터 분석 입문 14 Let&#39;s Get IT 자바스크립트 프로그래밍 15 개정판 | 리액트를 다루는 기술 16 메타버스, 이미 시작된 미래 17 IT 좀 아는 사람 18 이것이 취업을 위한 코딩 테스트다 with 파이썬 19 모던 자바스크립트 Deep Dive 20 NGINX 쿡북 . import requests from bs4 import BeautifulSoup url = &#39;https://ridibooks.com/category/bestsellers/2200&#39; #수정 response = requests.get(url) response.encoding = &#39;utf-8&#39; html = response.text soup = BeautifulSoup(html, &#39;html.parser&#39;) bookservices = soup.select(&#39;.thumbnail&#39;) #수정 for no, book in enumerate(bookservices, 1): print(no, book[&#39;alt&#39;], &#39;https:&#39; + book[&#39;data-src&#39;]) . 1 시드 마이어 https://img.ridicdn.net/cover/194000109/large#1 2 한 권으로 읽는 컴퓨터 구조와 프로그래밍 https://img.ridicdn.net/cover/3649000021/large#1 3 개발자에서 아키텍트로 https://img.ridicdn.net/cover/443000917/large#1 4 컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커 https://img.ridicdn.net/cover/754031863/large#1 5 비전공자를 위한 이해할 수 있는 IT 지식 https://img.ridicdn.net/cover/4489000001/large#1 6 오브젝트 https://img.ridicdn.net/cover/1160000027/large#1 7 Node.js 디자인 패턴 바이블 https://img.ridicdn.net/cover/194000106/large#1 8 눈치껏 못 배웁니다, 일센스 https://img.ridicdn.net/cover/222002588/large#1 9 개정판 | 시작하세요! 도커/쿠버네티스 https://img.ridicdn.net/cover/1160000029/large#1 10 다재다능 코틀린 프로그래밍 https://img.ridicdn.net/cover/194000105/large#1 11 파이썬으로 살펴보는 아키텍처 패턴 https://img.ridicdn.net/cover/443000912/large#1 12 혼자 공부하는 머신러닝+딥러닝 https://img.ridicdn.net/cover/443000859/large#1 13 비전공자도 배워서 바로 쓰는 비즈니스 데이터 분석 입문 https://img.ridicdn.net/cover/1370000008/large#1 14 Let&#39;s Get IT 자바스크립트 프로그래밍 https://img.ridicdn.net/cover/754031846/large#1 15 개정판 | 리액트를 다루는 기술 https://img.ridicdn.net/cover/754026976/large#1 16 메타버스, 이미 시작된 미래 https://img.ridicdn.net/cover/2777000044/large#1 17 IT 좀 아는 사람 https://img.ridicdn.net/cover/1046000113/large#1 18 이것이 취업을 위한 코딩 테스트다 with 파이썬 https://img.ridicdn.net/cover/443000825/large#1 19 모던 자바스크립트 Deep Dive https://img.ridicdn.net/cover/1160000024/large#1 20 NGINX 쿡북 https://img.ridicdn.net/cover/443000914/large#1 . import requests from bs4 import BeautifulSoup url = &#39;https://search.naver.com/search.naver?where=nexearch&amp;sm=top_hty&amp;fbm=1&amp;ie=utf8&amp;query=%EB%B0%95%EC%8A%A4%EC%98%A4%ED%94%BC%EC%8A%A4&#39; #수정 response = requests.get(url) response.encoding = &#39;utf-8&#39; html = response.text soup = BeautifulSoup(html, &#39;html.parser&#39;) bookservices = soup.select(&#39;.name&#39;) #수정 for no, book in enumerate(bookservices, 1): print(no, book.text.strip()) . 1 발신제한 2 크루엘라 3 콰이어트 플레이스 2 4 미드나이트 5 킬러의 보디가드 2 6 루카 7 컨저링 3: 악마가 시켰다 8 인 더 하이츠 9 괴기맨숀 10 꽃다발 같은 사랑을 했다 11 체르노빌 1986 12 빛나는 순간 13 랑종 14 블라이스 스피릿 15 분노의 질주: 더 얼티메이트 16 극장판 귀멸의 칼날: 무한열... 17 다크 앤드 위키드 18 매직아치 19 시카다 3301 20 아이윌 송 21 우리는 매일매일 22 메이드 인 루프탑 23 여고괴담 여섯번째 이야기 :... 24 학교 가는 길 25 이보다 더 좋을 순 없다 26 크레센도 27 파리의 연인 28 샤먼 로드 29 트립 투 그리스 30 사랑하고 사랑받고 차고 차이고 31 극장판 귀멸의 칼날: 무한열... 32 루카 33 학교 가는 길 34 크루엘라 35 분노의 질주: 더 얼티메이트 36 콰이어트 플레이스 2 37 미드나이트 38 사랑하고 사랑받고 차고 차이고 39 체르노빌 1986 40 컨저링 3: 악마가 시켰다 41 발신제한 42 킬러의 보디가드 2 43 인 더 하이츠 44 여고괴담 여섯번째 이야기 :... 45 그냥 길가는 나그네 46 네잎클로버 27 15 47 삼공 . import requests from bs4 import BeautifulSoup url = &#39;https://ridibooks.com/category/bestsellers/2200&#39; #수정 response = requests.get(url) response.encoding = &#39;utf-8&#39; html = response.text soup = BeautifulSoup(html, &#39;html.parser&#39;) 책순위 = [] 책이름 = [] 책이미지 = [] bookservices = soup.select(&#39;.thumbnail&#39;) #수정 for no, book in enumerate(bookservices, 1): 책순위.append(no) 책이름.append(book[&#39;alt&#39;]) 책이미지.append(&#39;https:&#39; + book[&#39;data-src&#39;]) . df = pd.DataFrame({ &#39;책순위&#39; : 책순위, &#39;책이름&#39; : 책이름, &#39;책이미지&#39; : 책이미지 }) df . 책순위 책이름 책이미지 . 0 1 | 시드 마이어 | https://img.ridicdn.net/cover/194000109/large#1 | . 1 2 | 한 권으로 읽는 컴퓨터 구조와 프로그래밍 | https://img.ridicdn.net/cover/3649000021/large#1 | . 2 3 | 개발자에서 아키텍트로 | https://img.ridicdn.net/cover/443000917/large#1 | . 3 4 | 컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커 | https://img.ridicdn.net/cover/754031863/large#1 | . 4 5 | 비전공자를 위한 이해할 수 있는 IT 지식 | https://img.ridicdn.net/cover/4489000001/large#1 | . 5 6 | 오브젝트 | https://img.ridicdn.net/cover/1160000027/large#1 | . 6 7 | Node.js 디자인 패턴 바이블 | https://img.ridicdn.net/cover/194000106/large#1 | . 7 8 | 눈치껏 못 배웁니다, 일센스 | https://img.ridicdn.net/cover/222002588/large#1 | . 8 9 | 개정판 | 시작하세요! 도커/쿠버네티스 | https://img.ridicdn.net/cover/1160000029/large#1 | . 9 10 | 다재다능 코틀린 프로그래밍 | https://img.ridicdn.net/cover/194000105/large#1 | . 10 11 | 파이썬으로 살펴보는 아키텍처 패턴 | https://img.ridicdn.net/cover/443000912/large#1 | . 11 12 | 혼자 공부하는 머신러닝+딥러닝 | https://img.ridicdn.net/cover/443000859/large#1 | . 12 13 | 비전공자도 배워서 바로 쓰는 비즈니스 데이터 분석 입문 | https://img.ridicdn.net/cover/1370000008/large#1 | . 13 14 | Let&#39;s Get IT 자바스크립트 프로그래밍 | https://img.ridicdn.net/cover/754031846/large#1 | . 14 15 | 개정판 | 리액트를 다루는 기술 | https://img.ridicdn.net/cover/754026976/large#1 | . 15 16 | 메타버스, 이미 시작된 미래 | https://img.ridicdn.net/cover/2777000044/large#1 | . 16 17 | IT 좀 아는 사람 | https://img.ridicdn.net/cover/1046000113/large#1 | . 17 18 | 이것이 취업을 위한 코딩 테스트다 with 파이썬 | https://img.ridicdn.net/cover/443000825/large#1 | . 18 19 | 모던 자바스크립트 Deep Dive | https://img.ridicdn.net/cover/1160000024/large#1 | . 19 20 | NGINX 쿡북 | https://img.ridicdn.net/cover/443000914/large#1 | . df.to_html(&#39;index.html&#39;) . def 이미지변환(path): return f&#39;&lt;img src=&quot;{path}&quot; width=&quot;60&quot; &gt;&#39; df.to_html(&#39;index.html&#39;, escape=False, formatters=dict(책이미지=이미지변환)) . How to create plots in pandas? . . import numpy as np import pandas as pd import matplotlib.pyplot as plt . df = pd.read_csv(&#39;train.csv&#39;) df[[&#39;SibSp&#39;, &#39;Parch&#39;]].plot() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fab280e5050&gt; . df.columns . Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;], dtype=&#39;object&#39;) . df.plot.scatter(x=&quot;Age&quot;, y=&quot;Fare&quot;, alpha=0.5) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fab28749c90&gt; . df[[&#39;Age&#39;]].plot.box() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fab283c1050&gt; . How to create new columns derived from existing columns? . . df[&#39;Family&#39;] = 1 + df[&#39;SibSp&#39;] + df[&#39;Parch&#39;] df . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked Family . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | 2 | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | 2 | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | 1 | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | 2 | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | 1 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 886 887 | 0 | 2 | Montvila, Rev. Juozas | male | 27.0 | 0 | 0 | 211536 | 13.0000 | NaN | S | 1 | . 887 888 | 1 | 1 | Graham, Miss. Margaret Edith | female | 19.0 | 0 | 0 | 112053 | 30.0000 | B42 | S | 1 | . 888 889 | 0 | 3 | Johnston, Miss. Catherine Helen &quot;Carrie&quot; | female | NaN | 1 | 2 | W./C. 6607 | 23.4500 | NaN | S | 4 | . 889 890 | 1 | 1 | Behr, Mr. Karl Howell | male | 26.0 | 0 | 0 | 111369 | 30.0000 | C148 | C | 1 | . 890 891 | 0 | 3 | Dooley, Mr. Patrick | male | 32.0 | 0 | 0 | 370376 | 7.7500 | NaN | Q | 1 | . 891 rows × 13 columns . How to calculate summary statistics? . Aggregating statistics . . import pandas as pd . df = pd.read_csv(&#39;train.csv&#39;) df.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | . df[&quot;Age&quot;].mean() # 평균 . 29.69911764705882 . df[[&quot;Age&quot;, &quot;Fare&quot;]].median() # 중앙값 . Age 28.0000 Fare 14.4542 dtype: float64 . df[[&quot;Age&quot;, &quot;Fare&quot;]].describe() # 일반 통계치 . Age Fare . count 714.000000 | 891.000000 | . mean 29.699118 | 32.204208 | . std 14.526497 | 49.693429 | . min 0.420000 | 0.000000 | . 25% 20.125000 | 7.910400 | . 50% 28.000000 | 14.454200 | . 75% 38.000000 | 31.000000 | . max 80.000000 | 512.329200 | . Aggregating statistics grouped by category . . df[[&quot;Sex&quot;, &quot;Age&quot;]].groupby(&quot;Sex&quot;).mean() . Age . Sex . female 27.915709 | . male 30.726645 | . df.groupby(&quot;Sex&quot;).mean() . PassengerId Survived Pclass Age SibSp Parch Fare . Sex . female 431.028662 | 0.742038 | 2.159236 | 27.915709 | 0.694268 | 0.649682 | 44.479818 | . male 454.147314 | 0.188908 | 2.389948 | 30.726645 | 0.429809 | 0.235702 | 25.523893 | . df.groupby(&quot;Sex&quot;)[&quot;Age&quot;].mean() . Sex female 27.915709 male 30.726645 Name: Age, dtype: float64 . . df.groupby([&quot;Sex&quot;, &quot;Pclass&quot;])[&quot;Fare&quot;].mean() . Sex Pclass female 1 106.125798 2 21.970121 3 16.118810 male 1 67.226127 2 19.741782 3 12.661633 Name: Fare, dtype: float64 . Count number of records by category . . df[&quot;Pclass&quot;].value_counts() . 3 491 1 216 2 184 Name: Pclass, dtype: int64 . df[&quot;Sex&quot;].value_counts() . male 577 female 314 Name: Sex, dtype: int64 . How to reshape the layout of tables? . Sort table rows . # sorted(리스트) - 리스트 안에 값을 변경하지 않고 return 값만 정렬 df.sort_values(by=&quot;Age&quot;).head() # 원본을 변경하지 않고 정렬 df.sort_values(by=[&#39;Pclass&#39;, &#39;Age&#39;], ascending=False).head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 803 804 | 1 | 3 | Thomas, Master. Assad Alexander | male | 0.42 | 0 | 1 | 2625 | 8.5167 | NaN | C | . 755 756 | 1 | 2 | Hamalainen, Master. Viljo | male | 0.67 | 1 | 1 | 250649 | 14.5000 | NaN | S | . 644 645 | 1 | 3 | Baclini, Miss. Eugenie | female | 0.75 | 2 | 1 | 2666 | 19.2583 | NaN | C | . 469 470 | 1 | 3 | Baclini, Miss. Helene Barbara | female | 0.75 | 2 | 1 | 2666 | 19.2583 | NaN | C | . 78 79 | 1 | 2 | Caldwell, Master. Alden Gates | male | 0.83 | 0 | 2 | 248738 | 29.0000 | NaN | S | . Long to wide table format . 여성 = df[df[&quot;Sex&quot;] == &quot;female&quot;] 여성.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 8 9 | 1 | 3 | Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) | female | 27.0 | 0 | 2 | 347742 | 11.1333 | NaN | S | . 9 10 | 1 | 2 | Nasser, Mrs. Nicholas (Adele Achem) | female | 14.0 | 1 | 0 | 237736 | 30.0708 | NaN | C | . 여성.sort_index().groupby([&quot;Age&quot;]).head(5) # 정렬하는 방법은 sort_values와 sort_index가 있습니다. 여성.sort_index(ascending=False).groupby([&quot;Age&quot;]).head(5) 여성[::-1] 여성[:] . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 8 9 | 1 | 3 | Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) | female | 27.0 | 0 | 2 | 347742 | 11.1333 | NaN | S | . 9 10 | 1 | 2 | Nasser, Mrs. Nicholas (Adele Achem) | female | 14.0 | 1 | 0 | 237736 | 30.0708 | NaN | C | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 880 881 | 1 | 2 | Shelley, Mrs. William (Imanita Parrish Hall) | female | 25.0 | 0 | 1 | 230433 | 26.0000 | NaN | S | . 882 883 | 0 | 3 | Dahlberg, Miss. Gerda Ulrika | female | 22.0 | 0 | 0 | 7552 | 10.5167 | NaN | S | . 885 886 | 0 | 3 | Rice, Mrs. William (Margaret Norton) | female | 39.0 | 0 | 5 | 382652 | 29.1250 | NaN | Q | . 887 888 | 1 | 1 | Graham, Miss. Margaret Edith | female | 19.0 | 0 | 0 | 112053 | 30.0000 | B42 | S | . 888 889 | 0 | 3 | Johnston, Miss. Catherine Helen &quot;Carrie&quot; | female | NaN | 1 | 2 | W./C. 6607 | 23.4500 | NaN | S | . 314 rows × 12 columns . 여성.pivot(index=&quot;PassengerId&quot;, columns=&quot;Pclass&quot;, values=&quot;Fare&quot;) # 데이터 재구조화 . Pclass 1 2 3 . PassengerId . 2 71.2833 | NaN | NaN | . 3 NaN | NaN | 7.9250 | . 4 53.1000 | NaN | NaN | . 9 NaN | NaN | 11.1333 | . 10 NaN | 30.0708 | NaN | . ... ... | ... | ... | . 881 NaN | 26.0000 | NaN | . 883 NaN | NaN | 10.5167 | . 886 NaN | NaN | 29.1250 | . 888 30.0000 | NaN | NaN | . 889 NaN | NaN | 23.4500 | . 314 rows × 3 columns . How to combine data from multiple tables? . Concatenating objects . . data = { &#39;수학&#39; : [90, 80], &#39;영어&#39; : [70, 60] } data2 = { &#39;언어&#39; : [20, 70], &#39;과학&#39; : [30, 60] } data3 = { &#39;수학&#39; : [100, 90], &#39;영어&#39; : [85, 65] } . data = pd.DataFrame(data) data2 = pd.DataFrame(data2) data3 = pd.DataFrame(data3) . data data2 . 언어 과학 . 0 20 | 30 | . 1 70 | 60 | . pd.concat([data, data2], axis=0) . 수학 영어 언어 과학 . 0 90.0 | 70.0 | NaN | NaN | . 1 80.0 | 60.0 | NaN | NaN | . 0 NaN | NaN | 20.0 | 30.0 | . 1 NaN | NaN | 70.0 | 60.0 | . # data[&#39;언어&#39;] = data2[&#39;언어&#39;] # data[&#39;과학&#39;] = data2[&#39;과학&#39;] # data[[&#39;언어&#39;, &#39;과학&#39;]] = data2[[&#39;언어&#39;, &#39;과학&#39;]] . data . 수학 영어 언어 과학 . 0 90 | 70 | 20 | 30 | . 1 80 | 60 | 70 | 60 | . pd.concat([data, data2], axis=1) . 수학 영어 언어 과학 . 0 90 | 70 | 20 | 30 | . 1 80 | 60 | 70 | 60 | . pd.concat([data, data3], axis=1) . 수학 영어 수학 영어 . 0 90 | 70 | 100 | 85 | . 1 80 | 60 | 90 | 65 | . pd.concat([data, data3], axis=0) . 수학 영어 . 0 90 | 70 | . 1 80 | 60 | . 0 100 | 85 | . 1 90 | 65 | . Join tables using a common identifier . . data = { &#39;이름&#39; : [&#39;영희&#39;, &#39;철수&#39;, &#39;호준&#39;], &#39;수학&#39; : [70, 60, 90] } data2 = { &#39;이름&#39; : [&#39;영희&#39;, &#39;호준&#39;], &#39;과학&#39; : [50, 70], &#39;언어&#39; : [90, 60] } . data = pd.DataFrame(data) data2 = pd.DataFrame(data2) . data . 이름 수학 . 0 영희 | 70 | . 1 철수 | 60 | . 2 호준 | 90 | . merge = pd.merge(data, data2, how=&quot;left&quot;, on=&quot;이름&quot;) merge . 이름 수학 과학 언어 . 0 영희 | 70 | 50.0 | 90.0 | . 1 철수 | 60 | NaN | NaN | . 2 호준 | 90 | 70.0 | 60.0 | . pandas datetime . df = pd.DataFrame({&#39;year&#39;: [2021, 2021], &#39;month&#39;: [7, 7], &#39;day&#39;: [9, 10]}) . df . year month day . 0 2021 | 7 | 9 | . 1 2021 | 7 | 10 | . data = pd.to_datetime(df) data . 0 2021-07-09 1 2021-07-10 dtype: datetime64[ns] . data.dt.year . 0 2021 1 2021 dtype: int64 . data.dt.month . 0 7 1 7 dtype: int64 . data.dt.day . 0 9 1 10 dtype: int64 . data.dt.weekday . 0 4 1 5 dtype: int64 . data.dt.day_name() #Series에서는 day_name(), weekday_name() - 버전업 되면서 삭제됨 . 0 Friday 1 Saturday dtype: object . pd.to_datetime(&#39;now&#39;) # UTC 시간 . Timestamp(&#39;2021-07-09 06:19:21.943875&#39;) . How to manipulate textual data? . df = pd.read_csv(&#39;train.csv&#39;) df.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | . df[&quot;Name&quot;].str.lower() df[&quot;Name&quot;].str.split(&quot;,&quot;) df[&quot;Name&quot;].str.contains(&quot;Mr&quot;) df[&quot;Name&quot;].str.contains(&quot;Mr&quot;).value_counts() df[df[&quot;Name&quot;].str.contains(&quot;Mr&quot;)] . df[&quot;Sex&quot;].replace({&quot;male&quot;: 1, &quot;female&quot;: 0}) . 0 1 1 0 2 0 3 0 4 1 .. 886 1 887 0 888 0 889 1 890 1 Name: Sex, Length: 891, dtype: int64 . &#52280;&#51312;&#47928;&#54732; . 판다스 공식 홈페이지 | .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/pandas/2021/09/20/_07_07_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D_pandas.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/pandas/2021/09/20/_07_07_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D_pandas.html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "데이터 분석 numpy 기초 문법 노트북",
            "content": "리스트 = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] 리스트[0][0] 리스트[0] 리스트[2][0] 리스트 * 2 . [[2, 4, 6], [8, 10, 12], [14, 16, 18]] . import numpy as np 리스트 = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] 리스트 = np.array(리스트) 리스트 * 2 리스트 + 100 . array([[101, 102, 103], [104, 105, 106], [107, 108, 109]]) . a = np.arange(15).reshape(3, 5) a . array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]]) . a = np.arange(20).reshape(4, 5) a . array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]]) . a = np.arange(20).reshape(2, 2, 5) a[0][1][2] . 7 . a = np.arange(15).reshape(3, 5) a a.shape a.ndim a.dtype.name a.itemsize a.size # flat한 데이터 사이즈 type(a) . numpy.ndarray . np.zeros((3, 4)) . array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]) . np.ones((2, 3), dtype=np.int16) . array([[1, 1, 1], [1, 1, 1]], dtype=int16) . np.empty((2, 3)) . array([[4.68254482e-310, 0.00000000e+000, 0.00000000e+000], [0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]) . np.arange(0, 2, 0.3) . array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8]) . np.linspace(0.5, 10, 20) . array([ 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5, 8. , 8.5, 9. , 9.5, 10. ]) . 리스트 = [[10, 2, 3], [4, 5, 6], [7, 8, 9]] a = np.array(리스트) # a.sum(), sum(리스트) # sum(리스트)는 애러납니다. a.min(), min(리스트) a.max(), max(리스트) #2개는 출력하는 결과도 다릅니다. . b = np.arange(12).reshape(3, 4) b . array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) . b.sum(axis=0) # col기준으로 row끼리 더한 것(세로) b.sum(axis=1) # row기준으로 col끼리 더한 것(가로) b.sum() # flat하게 모두 더한 것 . 66 . b.ravel() . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) . b.T # 잘써요! # b.transpose() 잘 안써요! . array([[ 0, 4, 8], [ 1, 5, 9], [ 2, 6, 10], [ 3, 7, 11]]) . a = np.array([[1, 2], [3, 4]]) b = np.floor([[5, 6], [7, 8]]) np.vstack((a, b)) np.hstack((a, b)) . array([[1., 2., 5., 6.], [3., 4., 7., 8.]]) . a = np.arange(12).reshape(3, 4) b = a &gt; 4 b . array([[False, False, False, False], [False, True, True, True], [ True, True, True, True]]) . b.sum() . 7 .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/numpy/2021/09/20/_07_05_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D_numpy.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/numpy/2021/09/20/_07_05_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D_numpy.html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "2021년 여름방학 무료특강 손에 잡히는 딥러닝",
            "content": "&#44536;&#47000;&#54532;&#51032; &#54620;&#44544; &#54256;&#53944; . !sudo apt install -y fonts-nanum* !sudo fc-cache -fv !rm ~/.cache/matplotlib -rf . Reading package lists... Done Building dependency tree Reading state information... Done Note, selecting &#39;fonts-nanum-eco&#39; for glob &#39;fonts-nanum*&#39; Note, selecting &#39;fonts-nanum&#39; for glob &#39;fonts-nanum*&#39; Note, selecting &#39;fonts-nanum-gothic-light&#39; for glob &#39;fonts-nanum*&#39; Note, selecting &#39;fonts-nanum-coding&#39; for glob &#39;fonts-nanum*&#39; Note, selecting &#39;fonts-nanum-extra&#39; for glob &#39;fonts-nanum*&#39; fonts-nanum is already the newest version (20170925-1). fonts-nanum-coding is already the newest version (2.5-1). fonts-nanum-eco is already the newest version (1.000-6). fonts-nanum-extra is already the newest version (20170925-1). 0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded. /usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs /usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs /usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs /usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs /usr/share/fonts/truetype/nanum: caching, new cache contents: 31 fonts, 0 dirs /usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs /root/.local/share/fonts: skipping, no such directory /root/.fonts: skipping, no such directory /var/cache/fontconfig: cleaning cache directory /root/.cache/fontconfig: not cleaning non-existent cache directory /root/.fontconfig: not cleaning non-existent cache directory fc-cache: succeeded . import matplotlib.pyplot as plt plt.rc(&#39;font&#39;, family=&#39;NanumBarunGothic&#39;) . &#45936;&#51060;&#53552; &#49373;&#49457; . import pandas as pd import numpy as np . 주가 = [ np.random.randint(10, 50) + i*2 for i in range(100) ] . import matplotlib.pyplot as plt plt.plot(np.arange(1, 101), 주가) plt.show() . &#46373;&#47084;&#45789; . 독립 = pd.DataFrame(np.arange(1, 101)) 종속 = pd.DataFrame(주가) 독립.shape, 종속.shape . ((100, 1), (100, 1)) . import tensorflow as tf . X = tf.keras.layers.Input(shape=[1]) # 독립변수의 col Y = tf.keras.layers.Dense(1)(X) # 종속변수의 col model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) # MSE(Mean squared error) . model.fit(독립, 종속, epochs=10000, verbose=0) model.fit(독립, 종속, epochs=10) . Epoch 1/10 4/4 [==============================] - 0s 3ms/step - loss: 118.4112 Epoch 2/10 4/4 [==============================] - 0s 3ms/step - loss: 118.4161 Epoch 3/10 4/4 [==============================] - 0s 2ms/step - loss: 118.6262 Epoch 4/10 4/4 [==============================] - 0s 3ms/step - loss: 118.4688 Epoch 5/10 4/4 [==============================] - 0s 3ms/step - loss: 118.4280 Epoch 6/10 4/4 [==============================] - 0s 3ms/step - loss: 118.4940 Epoch 7/10 4/4 [==============================] - 0s 3ms/step - loss: 118.4082 Epoch 8/10 4/4 [==============================] - 0s 5ms/step - loss: 118.4647 Epoch 9/10 4/4 [==============================] - 0s 3ms/step - loss: 118.3927 Epoch 10/10 4/4 [==============================] - 0s 3ms/step - loss: 118.3953 . &lt;tensorflow.python.keras.callbacks.History at 0x7f9ca8374110&gt; . model.predict([50]) model.predict([40]) . array([[104.776886]], dtype=float32) . model.predict(독립) . array([[ 25.306517], [ 27.344217], [ 29.38192 ], [ 31.41962 ], [ 33.45732 ], [ 35.495026], [ 37.532726], [ 39.570427], [ 41.60813 ], [ 43.645832], [ 45.683533], [ 47.721237], [ 49.758938], [ 51.79664 ], [ 53.834343], [ 55.872044], [ 57.909744], [ 59.94745 ], [ 61.98515 ], [ 64.02285 ], [ 66.060555], [ 68.09825 ], [ 70.135956], [ 72.17366 ], [ 74.211365], [ 76.24906 ], [ 78.28676 ], [ 80.32446 ], [ 82.36217 ], [ 84.39987 ], [ 86.43758 ], [ 88.47527 ], [ 90.51298 ], [ 92.550674], [ 94.58838 ], [ 96.62608 ], [ 98.66378 ], [100.701485], [102.73919 ], [104.776886], [106.81459 ], [108.852295], [110.88999 ], [112.9277 ], [114.9654 ], [117.0031 ], [119.0408 ], [121.07851 ], [123.1162 ], [125.15391 ], [127.191605], [129.22931 ], [131.26701 ], [133.30472 ], [135.3424 ], [137.38013 ], [139.41782 ], [141.45552 ], [143.49323 ], [145.53091 ], [147.56863 ], [149.60632 ], [151.64403 ], [153.68173 ], [155.71944 ], [157.75714 ], [159.79483 ], [161.83253 ], [163.87024 ], [165.90794 ], [167.94565 ], [169.98335 ], [172.02104 ], [174.05875 ], [176.09645 ], [178.13416 ], [180.17186 ], [182.20956 ], [184.24725 ], [186.28496 ], [188.32266 ], [190.36037 ], [192.39807 ], [194.43578 ], [196.47346 ], [198.51117 ], [200.54887 ], [202.58658 ], [204.62428 ], [206.66199 ], [208.69968 ], [210.73738 ], [212.77509 ], [214.81279 ], [216.8505 ], [218.8882 ], [220.92589 ], [222.9636 ], [225.0013 ], [227.039 ]], dtype=float32) . model.get_weights() . [array([[2.0377018]], dtype=float32), array([23.268814], dtype=float32)] . 2.072317 * 50 + 22.033388 . 125.649238 . model.predict([50]) . array([[125.15391]], dtype=float32) . plt.plot(np.arange(1, 101), 주가) plt.plot(np.arange(1, 101), 2.07 * np.arange(1, 101) + 22.03) plt.show() . 오차값 = 종속 - model.predict(독립) 오차값 . 0 . 0 3.693483 | . 1 13.655783 | . 2 8.618080 | . 3 -10.419621 | . 4 -1.457321 | . ... ... | . 95 5.111801 | . 96 3.074112 | . 97 7.036407 | . 98 -12.001297 | . 99 12.960999 | . 100 rows × 1 columns . 오차값의제곱 = 오차값 ** 2 오차값의제곱 . 0 . 0 13.641819 | . 1 186.480401 | . 2 74.271305 | . 3 108.568492 | . 4 2.123785 | . ... ... | . 95 26.130511 | . 96 9.450164 | . 97 49.511030 | . 98 144.031130 | . 99 167.987483 | . 100 rows × 1 columns . (오차값의제곱.sum())/100 ## MSE . 0 118.389643 dtype: float64 . &#52572;&#49548; &#51228;&#44273;&#48277; . y = ax + b | 참고자료 : https://ko.wikipedia.org/wiki/%EC%B5%9C%EC%86%8C%EC%A0%9C%EA%B3%B1%EB%B2%95 | 구하고자 하는 방정식은 y = ax + b이다. 상수 a, b값을 안다면, a, b는 다음으로 계산할 수 있다. | a : $${ displaystyle a={ frac {n Sigma XY- Sigma X Sigma Y}{n Sigma X^{2}- Sigma X Sigma X}}}$$ . | b : $${ displaystyle b={ frac { Sigma X^{2} Sigma Y- Sigma X Sigma XY}{n Sigma X^{2}- Sigma X Sigma X}}}$$ . | . 두수의곱 = 독립*종속 int(100 * 두수의곱.sum()) . 80715800 . int(독립.sum() * 종속.sum()) . 64054200 . int(100 * (독립 ** 2).sum()) . 33835000 . int(독립.sum() * 독립.sum()) . 25502500 . 분자 = int(100 * 두수의곱.sum()) - int(독립.sum() * 종속.sum()) 분모 = int(100 * (독립 ** 2).sum()) - int(독립.sum() * 독립.sum()) . 분자 / 분모 . 1.9995919591959197 . model.get_weights() . [array([[2.0377018]], dtype=float32), array([23.268814], dtype=float32)] . ${ displaystyle b={ frac { Sigma X^{2} Sigma Y- Sigma X Sigma XY}{n Sigma X^{2}- Sigma X Sigma X}}}$ . 분자 = ((독립**2).sum() * 종속.sum()) - (독립.sum() * (독립*종속).sum()) 분모 = (100 * (독립**2).sum()) - (독립.sum() * 독립.sum()) . 분자 / 분모 . 0 25.860606 dtype: float64 . &#45800;&#49692;&#45936;&#51060;&#53552;&#51032; &#55176;&#46304;&#47112;&#51060;&#50612; . 매출액 = [2, 5, 10, 20, 40, 80] 광고액 = [1, 2, 4, 6, 8, 10] 순익 = [1, 1.5, 3, 10, 20, 60] . plt.plot(np.arange(1, 7), 매출액, label=&#39;매출액&#39;) plt.plot(np.arange(1, 7), 광고액, label=&#39;광고액&#39;) plt.plot(np.arange(1, 7), 순익, label=&#39;순익&#39;) plt.legend() plt.show() . 독립 = pd.DataFrame({ &#39;매출액&#39; : 매출액, &#39;광고액&#39; : 광고액 }) 종속 = pd.DataFrame({ &#39;순익&#39; : 순익 }) 독립.shape, 종속.shape . ((6, 2), (6, 1)) . 독립 . 매출액 광고액 . 0 2 | 1 | . 1 5 | 2 | . 2 10 | 4 | . 3 20 | 6 | . 4 40 | 8 | . 5 80 | 10 | . X = tf.keras.layers.Input(shape=[2]) # 독립변수의 col ## 1. 히든 레이어의 노드(뉴런) 수는 2개부터 5개까지 점차 늘려보고 그래프를 확인해보세요. H = tf.keras.layers.Dense(2, activation=&#39;swish&#39;)(X) ## 2. 히든 레이어의 수를 2개, 3개로 점차 늘려보고 그래프를 확인해보세요. # H = tf.keras.layers.Dense(2, activation=&#39;swish&#39;)(H) Y = tf.keras.layers.Dense(1)(H) # 종속변수의 col model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) # MSE(Mean squared error) . model.fit(독립, 종속, epochs=10000, verbose=0) model.fit(독립, 종속, epochs=10) . Epoch 1/10 1/1 [==============================] - 0s 5ms/step - loss: 36.9067 Epoch 2/10 1/1 [==============================] - 0s 7ms/step - loss: 36.8933 Epoch 3/10 1/1 [==============================] - 0s 5ms/step - loss: 36.8940 Epoch 4/10 1/1 [==============================] - 0s 6ms/step - loss: 36.8806 Epoch 5/10 1/1 [==============================] - 0s 5ms/step - loss: 36.8812 Epoch 6/10 1/1 [==============================] - 0s 5ms/step - loss: 36.8679 Epoch 7/10 1/1 [==============================] - 0s 6ms/step - loss: 36.8685 Epoch 8/10 1/1 [==============================] - 0s 5ms/step - loss: 36.8551 Epoch 9/10 1/1 [==============================] - 0s 6ms/step - loss: 36.8558 Epoch 10/10 1/1 [==============================] - 0s 6ms/step - loss: 36.8424 . &lt;tensorflow.python.keras.callbacks.History at 0x7f9c9f410a10&gt; . model.get_weights() . [array([[ 0.03463789, -0.05114527], [-0.4278318 , 0.17921998]], dtype=float32), array([0.23633954, 1.2595593 ], dtype=float32), array([[-29.92225 ], [-29.651735]], dtype=float32), array([29.98308], dtype=float32)] . model.predict([[10, 4]]) . array([[2.9516315]], dtype=float32) . model.predict(독립) . array([[ 0.31713486], [ 3.0344315 ], [ 2.9516315 ], [ 7.3105507 ], [25.017687 ], [46.368225 ]], dtype=float32) . 종속 . 순익 . 0 1.0 | . 1 1.5 | . 2 3.0 | . 3 10.0 | . 4 20.0 | . 5 60.0 | . plt.plot(np.arange(1, 7), model.predict(독립), label=&#39;예측값&#39;) plt.plot(np.arange(1, 7), 종속, label=&#39;실제값&#39;) plt.legend() plt.show() . &#48373;&#51105; &#45936;&#51060;&#53552;&#51032; &#55176;&#46304;&#47112;&#51060;&#50612; . 그럼 주가는 잘 맞출까? (곡선 형태) | . import numpy as np import pandas as pd import matplotlib.pyplot as plt 광고액 = [ np.random.randint(10, 50) + np.log(i*5) * 50 for i in range(1, 101) ] 계절성 = [ np.sin(i/3)*100 + i*3 + j*2 for i, j in zip(np.arange(1, 101), 광고액) ] 매출액 = [i**(np.log(np.log(i))) + j for i, j in zip(np.arange(1, 101), 계절성) ] plt.plot(np.arange(1, 101), 광고액, label=&#39;a&#39;) plt.plot(np.arange(1, 101), 계절성, label=&#39;b&#39;) plt.plot(np.arange(1, 101), 매출액, label=&#39;c&#39;) plt.legend() plt.show() . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log import sys . 독립 = pd.DataFrame({ &#39;계절성&#39; : 계절성, &#39;광고액&#39; : 광고액 }) 종속 = pd.DataFrame({ &#39;매출액&#39; : 매출액 }) 독립.shape, 종속.shape . ((100, 2), (100, 1)) . import tensorflow as tf #모델 준비 X = tf.keras.layers.Input(shape=[2]) # 독립변수의 col H = tf.keras.layers.Dense(200, activation=&#39;swish&#39;)(X) # 노드의 수는 천천히 늘려감! (2 ~ 200) # H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 처음에는 주석처리! Y = tf.keras.layers.Dense(1)(H) # 종속변수의 col model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) # MSE(Mean squared error) . model.fit(독립, 종속, epochs=10000, verbose=0) model.fit(독립, 종속, epochs=10) . Epoch 1/10 4/4 [==============================] - 0s 3ms/step - loss: 31030.5703 Epoch 2/10 4/4 [==============================] - 0s 5ms/step - loss: 32710.4570 Epoch 3/10 4/4 [==============================] - 0s 3ms/step - loss: 31348.4434 Epoch 4/10 4/4 [==============================] - 0s 3ms/step - loss: 41892.3516 Epoch 5/10 4/4 [==============================] - 0s 3ms/step - loss: 37597.6719 Epoch 6/10 4/4 [==============================] - 0s 3ms/step - loss: 35604.6719 Epoch 7/10 4/4 [==============================] - 0s 3ms/step - loss: 33204.0156 Epoch 8/10 4/4 [==============================] - 0s 3ms/step - loss: 36819.3398 Epoch 9/10 4/4 [==============================] - 0s 5ms/step - loss: 43219.9883 Epoch 10/10 4/4 [==============================] - 0s 3ms/step - loss: 31084.8828 . &lt;tensorflow.python.keras.callbacks.History at 0x7f9c92f4c490&gt; . plt.plot(np.arange(1, 101), model.predict(독립), label=&#39;예측값&#39;) plt.plot(np.arange(1, 101), 종속, label=&#39;실제값&#39;) plt.legend() plt.show() . plt.plot(np.arange(1, 101), model.predict(독립), label=&#39;예측값&#39;) plt.plot(np.arange(1, 101), 종속, label=&#39;실제값&#39;) plt.legend() plt.show() . import tensorflow as tf #모델 준비 X = tf.keras.layers.Input(shape=[2]) # 독립변수의 col H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(X) # 노드의 수는 천천히 늘려감! (2 ~ 5) H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 천천히 늘려감! (2 ~ 5) H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 천천히 늘려감! (2 ~ 5) H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 천천히 늘려감! (2 ~ 5) H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 천천히 늘려감! (2 ~ 5) Y = tf.keras.layers.Dense(1)(H) # 종속변수의 col model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) # MSE(Mean squared error) . model.fit(독립, 종속, epochs=10000, verbose=0) model.fit(독립, 종속, epochs=10) . Epoch 1/10 4/4 [==============================] - 0s 4ms/step - loss: 17272.0957 Epoch 2/10 4/4 [==============================] - 0s 4ms/step - loss: 43156.6562 Epoch 3/10 4/4 [==============================] - 0s 3ms/step - loss: 16989.7070 Epoch 4/10 4/4 [==============================] - 0s 5ms/step - loss: 17889.2598 Epoch 5/10 4/4 [==============================] - 0s 3ms/step - loss: 17336.5117 Epoch 6/10 4/4 [==============================] - 0s 6ms/step - loss: 21185.4141 Epoch 7/10 4/4 [==============================] - 0s 5ms/step - loss: 16363.0391 Epoch 8/10 4/4 [==============================] - 0s 3ms/step - loss: 23066.0176 Epoch 9/10 4/4 [==============================] - 0s 3ms/step - loss: 22610.3809 Epoch 10/10 4/4 [==============================] - 0s 3ms/step - loss: 29358.0098 . &lt;tensorflow.python.keras.callbacks.History at 0x7f9c98ca82d0&gt; . plt.plot(np.arange(1, 101), model.predict(독립), label=&#39;예측값&#39;) plt.plot(np.arange(1, 101), 종속, label=&#39;실제값&#39;) plt.legend() plt.show() . import tensorflow as tf #모델 준비 X = tf.keras.layers.Input(shape=[2]) # 독립변수의 col H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(X) # 노드의 수는 천천히 늘려감! (2 ~ 5) for _ in range(10): H = tf.keras.layers.Dense(5, activation=&#39;swish&#39;)(H) # 천천히 늘려감! (2 ~ 5) Y = tf.keras.layers.Dense(1)(H) # 종속변수의 col model = tf.keras.models.Model(X, Y) model.compile(loss=&#39;mse&#39;) # MSE(Mean squared error) . model.fit(독립, 종속, epochs=10000, verbose=0) model.fit(독립, 종속, epochs=10) . Epoch 1/10 4/4 [==============================] - 0s 4ms/step - loss: 23658.7246 Epoch 2/10 4/4 [==============================] - 0s 3ms/step - loss: 23833.8301 Epoch 3/10 4/4 [==============================] - 0s 4ms/step - loss: 31947.2129 Epoch 4/10 4/4 [==============================] - 0s 4ms/step - loss: 25460.2480 Epoch 5/10 4/4 [==============================] - 0s 4ms/step - loss: 24909.1680 Epoch 6/10 4/4 [==============================] - 0s 4ms/step - loss: 24867.2402 Epoch 7/10 4/4 [==============================] - 0s 3ms/step - loss: 23354.0352 Epoch 8/10 4/4 [==============================] - 0s 3ms/step - loss: 26266.6719 Epoch 9/10 4/4 [==============================] - 0s 3ms/step - loss: 23356.0391 Epoch 10/10 4/4 [==============================] - 0s 3ms/step - loss: 24691.1309 . &lt;tensorflow.python.keras.callbacks.History at 0x7f9c93809fd0&gt; . plt.plot(np.arange(1, 101), model.predict(독립), label=&#39;예측값&#39;) plt.plot(np.arange(1, 101), 종속, label=&#39;실제값&#39;) plt.legend() plt.show() . 히든레이어는 1개 ~ 4개를 쌓아보고 정확도 측정하는 것이 보통. | 노드는 100개 ~ 200개를 쌓아보고 정확도 측정. | CNN이나 RNN 으로 넘어가기 전 좀 더 단순한 데이터로 신경망에 대해 학습할 것을 권함. | .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/tensorflow/deep%20learning/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80/2021/09/20/_06_30_(%EC%B5%9C%EC%A2%85_%EC%88%98%EC%A0%95)_%EC%86%90%EC%97%90_%EC%9E%A1%ED%9E%88%EB%8A%94_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B0%95%EC%9D%98%EC%9E%90%EB%A3%8C.html",
            "relUrl": "/tensorflow/deep%20learning/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80/2021/09/20/_06_30_(%EC%B5%9C%EC%A2%85_%EC%88%98%EC%A0%95)_%EC%86%90%EC%97%90_%EC%9E%A1%ED%9E%88%EB%8A%94_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B0%95%EC%9D%98%EC%9E%90%EB%A3%8C.html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/deep%20learning/2020/06/28/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4-%ED%85%8C%EC%8A%A4%ED%8A%B8.html",
            "relUrl": "/deep%20learning/2020/06/28/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4-%ED%85%8C%EC%8A%A4%ED%8A%B8.html",
            "date": " • Jun 28, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://paullabkorea.github.io/jupyternotebookblog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Us",
          "content": "기술의 교육 기회를 누구나 차등없이 받을 수 있게 대중화, 보편화, 시스템화 하는 것 . 우리는 교육 특권의 대중화, 고급 IT 기술의 상용화를 도모합니다. 또한 지역적 특성을 극복하고 ICT 지식에 대한 갈급함을 해소할 수 있도록 노력하고 있는 ICT 연구 및 (코딩)교육 기관이며 다양한 사회 공헌 활동을 하고 있습니다. . About us . Paul Lab . 바울랩은 제주도에 위치한 ICT 연구 및 (코딩)교육 기관으로 연구원, 학원, 출판사를 함께 운영하고 있습니다. . 진취적인 청년들이 경제적으로도 여유를 가지며 하고 싶은 연구를 할 수 있는 ‘연구의 場’, 연구의 경험과 결과를 열정과 책임으로 교육하는 ‘교육의 場’, 이로 인한 이익과 지식을 사회를 위하여 나누는 ‘나눔의 場’으로 회사와 학생, 사회의 상생을 도모합니다. . WeNiv(위니브) . 위니브는 “기술의 교육 기회를 누구나 차등 없이 받을 수 있게 대중화, 보편화, 시스템화 하는 것”에 설립 취지를 가지고 있습니다. . 지역 기반 ICT 대안 교육 플랫폼, 유료와 무료 ICT 영상 콘텐츠를 제작하며, 지역 교육 기회의 불평등, 접근성의 한계 등 기존 교육의 한계를 극복하기 위한 다양한 시도를 하고 있습니다. . 또한 지역 혁신을 위한 사회 공헌 활동을 지속적으로 진행 중에 있으며 대표적으로 “선선하다 프로젝트”, “We 드림(We Dream)” 프로젝트를 제주에서 진행 중에 있습 니다. . 선선하다 프로젝트는 각 학교 ICT 분야를 선도하고 있는 학생을 초청하여 무료로 ICT 교육, 교재 지원, 동영상 강의 지원을 통해, 학생이 학생을 가르치도록 독려하는 비영리 프로젝트이며 We드림은 가정 형편이 어려우신 분들을 위해 매년 100명을 선발하여 온라인 강좌를 제공하는 프로젝트입니다. . 제주코딩베이스캠프 . 제주코딩베이스캠프는 제주에서 가장 큰 ICT 교육 행사로 카카오, 구름, 제주산학 융합원 등 기업 및 지자체와 함께 진행하고 있습니다. 13기까지 진행된 이 행사는 경쟁률 10:1에 약 400여 명이 참여하였고 도내뿐만 아니라 도외에서도 주목받고 있는 무료 캠프입니다. . 또한 인프런, Edwith, 구름, 유튜브, 에듀캐스트 등의 교육 플랫폼에서 35개의 동영상 강좌를 제공하고 있으며 21년 2월 총 30,000명 이상의 수강생이 제주코딩베이스캠프의 강좌를 수강하고 있습니다. . 수료증 제도를 통한 나노디그리 시스템이 도입되어 있고, 수료를 한 학생에게는 취업 매칭, 콘텐츠 공동제작의 기회를 제공하고 있습니다. . 교육 커리큘럼과 수료증 제도 . .",
          "url": "https://paullabkorea.github.io/jupyternotebookblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  

  

  
      ,"page5": {
          "title": "sample",
          "content": "테스트 . 테스트 페이지입니다. . 잘 작동하는지 봅니다. | 잘 작동하는지 봅니다. | 잘 작동하는지 봅니다. | 잘 작동하는지 봅니다. | LaTex . $f(x)$ .",
          "url": "https://paullabkorea.github.io/jupyternotebookblog/sample/",
          "relUrl": "/sample/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page13": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://paullabkorea.github.io/jupyternotebookblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}